<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.411">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="dcterms.date" content="2023-10-10">
<title>Dissertation - 5&nbsp; IGAS Project</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./HTW.html" rel="next">
<link href="./Introduction.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./IGAS.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">IGAS Project</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Dissertation</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Title Page</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./plan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">plan</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./outline.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Dissertation Outline</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./IGAS.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">IGAS Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./HTW.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">HTW Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Discussion</span></span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract"><span class="header-section-number">6</span> Abstract</a></li>
  <li>
<a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">7</span> Introduction</a>
  <ul class="collapse">
<li><a href="#similarity-and-instance-based-approaches-to-transfer-of-learning" id="toc-similarity-and-instance-based-approaches-to-transfer-of-learning" class="nav-link" data-scroll-target="#similarity-and-instance-based-approaches-to-transfer-of-learning"><span class="header-section-number">7.1</span> Similarity and instance-based approaches to transfer of learning</a></li>
  <li><a href="#the-effect-of-training-variability-on-transfer" id="toc-the-effect-of-training-variability-on-transfer" class="nav-link" data-scroll-target="#the-effect-of-training-variability-on-transfer"><span class="header-section-number">7.2</span> The effect of training variability on transfer</a></li>
  <li><a href="#issues-with-previous-research" id="toc-issues-with-previous-research" class="nav-link" data-scroll-target="#issues-with-previous-research"><span class="header-section-number">7.3</span> Issues with Previous Research</a></li>
  </ul>
</li>
  <li>
<a href="#experiment-1" id="toc-experiment-1" class="nav-link" data-scroll-target="#experiment-1"><span class="header-section-number">8</span> Experiment 1</a>
  <ul class="collapse">
<li>
<a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods"><span class="header-section-number">8.1</span> Methods</a>
  <ul class="collapse">
<li><a href="#sample-size-estimation" id="toc-sample-size-estimation" class="nav-link" data-scroll-target="#sample-size-estimation"><span class="header-section-number">8.1.1</span> Sample Size Estimation</a></li>
  <li><a href="#participants" id="toc-participants" class="nav-link" data-scroll-target="#participants"><span class="header-section-number">8.1.2</span> Participants</a></li>
  <li><a href="#task" id="toc-task" class="nav-link" data-scroll-target="#task"><span class="header-section-number">8.1.3</span> Task</a></li>
  </ul>
</li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">8.2</span> Results</a></li>
  <li><a href="#data-processing-and-statistical-packages" id="toc-data-processing-and-statistical-packages" class="nav-link" data-scroll-target="#data-processing-and-statistical-packages"><span class="header-section-number">8.3</span> Data Processing and Statistical Packages</a></li>
  <li><a href="#training-phase" id="toc-training-phase" class="nav-link" data-scroll-target="#training-phase"><span class="header-section-number">8.4</span> Training Phase</a></li>
  <li><a href="#testing-phase" id="toc-testing-phase" class="nav-link" data-scroll-target="#testing-phase"><span class="header-section-number">8.5</span> Testing Phase</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion"><span class="header-section-number">8.6</span> Discussion</a></li>
  </ul>
</li>
  <li>
<a href="#experiment-2" id="toc-experiment-2" class="nav-link" data-scroll-target="#experiment-2"><span class="header-section-number">9</span> Experiment 2</a>
  <ul class="collapse">
<li>
<a href="#methods-1" id="toc-methods-1" class="nav-link" data-scroll-target="#methods-1"><span class="header-section-number">9.1</span> Methods</a>
  <ul class="collapse">
<li><a href="#participants-1" id="toc-participants-1" class="nav-link" data-scroll-target="#participants-1"><span class="header-section-number">9.1.1</span> Participants</a></li>
  <li><a href="#task-and-procedure" id="toc-task-and-procedure" class="nav-link" data-scroll-target="#task-and-procedure"><span class="header-section-number">9.1.2</span> Task and Procedure</a></li>
  </ul>
</li>
  <li>
<a href="#results-1" id="toc-results-1" class="nav-link" data-scroll-target="#results-1"><span class="header-section-number">9.2</span> Results</a>
  <ul class="collapse">
<li><a href="#data-processing-and-statistical-packages-1" id="toc-data-processing-and-statistical-packages-1" class="nav-link" data-scroll-target="#data-processing-and-statistical-packages-1"><span class="header-section-number">9.2.1</span> Data Processing and Statistical Packages</a></li>
  <li><a href="#training-phase-1" id="toc-training-phase-1" class="nav-link" data-scroll-target="#training-phase-1"><span class="header-section-number">9.2.2</span> Training Phase</a></li>
  <li><a href="#testing-phase-1" id="toc-testing-phase-1" class="nav-link" data-scroll-target="#testing-phase-1"><span class="header-section-number">9.2.3</span> Testing Phase</a></li>
  </ul>
</li>
  <li><a href="#discussion-1" id="toc-discussion-1" class="nav-link" data-scroll-target="#discussion-1"><span class="header-section-number">9.3</span> Discussion</a></li>
  </ul>
</li>
  <li>
<a href="#computational-model" id="toc-computational-model" class="nav-link" data-scroll-target="#computational-model"><span class="header-section-number">10</span> Computational Model</a>
  <ul class="collapse">
<li><a href="#fitting-model-parameters-separately-by-group" id="toc-fitting-model-parameters-separately-by-group" class="nav-link" data-scroll-target="#fitting-model-parameters-separately-by-group"><span class="header-section-number">10.1</span> Fitting model parameters separately by group</a></li>
  </ul>
</li>
  <li>
<a href="#general-discussion" id="toc-general-discussion" class="nav-link" data-scroll-target="#general-discussion"><span class="header-section-number">11</span> General Discussion</a>
  <ul class="collapse">
<li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations"><span class="header-section-number">11.1</span> Limitations</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">11.2</span> Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">11.3</span> References</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">
<span class="chapter-number">5</span>&nbsp; <span class="chapter-title">IGAS Project</span>
</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 10, 2023</p>
    </div>
  </div>
  
    
  </div>
  


</header><p><a href="Assets/Gorman_Goldstone_2022_Instance-based_model_varied_practice.pdf" target="_blank">Pdf of the journal article</a><br><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010028522000299" target="_blank">Link to online version of journal article</a></p>
<section id="abstract" class="level1" data-number="6"><h1 data-number="6">
<span class="header-section-number">6</span> Abstract</h1>
<p>Exposing learners to variability during training has been demonstrated to improve performance in subsequent transfer testing. Such variability benefits are often accounted for by assuming that learners are developing some general task schema or structure. However much of this research has neglected to account for differences in similarity between varied and constant training conditions. In a between-groups manipulation, we trained participants on a simple projectile launching task, with either varied or constant conditions. We replicate previous findings showing a transfer advantage of varied over constant training. Furthermore, we show that a standard similarity model is insufficient to account for the benefits of variation, but, if the model is adjusted to assume that varied learners are tuned towards a broader generalization gradient, then a similarity-based model is sufficient to explain the observed benefits of variation. Our results therefore suggest that some variability benefits can be accommodated within instance-based models without positing the learning of some schemata or structure.</p>
</section><section id="introduction" class="level1" data-number="7"><h1 data-number="7">
<span class="header-section-number">7</span> Introduction</h1>
<p>The past century of research on human learning has produced ample evidence that although learners can improve at almost any task, such improvements are often specific to the trained task, with unreliable or even nonexistent transfer to novel tasks or conditions <span class="citation" data-cites="barnettWhenWhereWe2002 dettermanCaseProsecutionTransfer1993">(<a href="#ref-barnettWhenWhereWe2002" role="doc-biblioref">Barnett &amp; Ceci, 2002</a>; <a href="#ref-dettermanCaseProsecutionTransfer1993" role="doc-biblioref">Detterman, 1993</a>)</span>. Such transfer challenges are of noteworthy practical relevance, given that educators, trainers, and rehabilitators typically intend for their students to be able to apply what they have learned to new situations. It is therefore important to better understand the factors that influence transfer, and to develop cognitive models that can predict when transfer is likely to occur. The factor of interest to the present investigation is variation during training. Our experiments add to the longstanding empirical investigation of the controversial relationship between training variation, and subsequent transfer. We also offer a novel explanation for such results in the form of an instance-based model that accounts for the benefits of variation in simple terms of psychological similarity. We first review the relevant concepts and literature.</p>
<section id="similarity-and-instance-based-approaches-to-transfer-of-learning" class="level2" data-number="7.1"><h2 data-number="7.1" class="anchored" data-anchor-id="similarity-and-instance-based-approaches-to-transfer-of-learning">
<span class="header-section-number">7.1</span> Similarity and instance-based approaches to transfer of learning</h2>
<p>Notions of similarity have long played a central role in many prominent models of generalization of learning, as well as in the longstanding theoretical issue of whether learners abstract an aggregate, summary representation, or if they simply store individual instances. Early models of learning often assumed that discrete experiences with some task or category were not stored individually in memory, but instead promoted the formation of a summary representation, often referred to as a prototype or schema, and that exposure to novel examples would then prompt the retrieval of whichever preexisting prototype was most similar <span class="citation" data-cites="posnerGenesisAbstractIdeas1968">(<a href="#ref-posnerGenesisAbstractIdeas1968" role="doc-biblioref">Posner &amp; Keele, 1968</a>)</span>. Prototype models were later challenged by the success of instance-based or exemplar models – which were shown to provide an account of generalization as good or better than prototype models, with the advantage of not assuming the explicit construction of an internal prototype <span class="citation" data-cites="estesArrayModelsCategory1986 hintzmanMINERVASimulationModel1984 medinContextTheoryClassification1978 nosofskyAttentionSimilarityIdentificationcategorization1986">(<a href="#ref-estesArrayModelsCategory1986" role="doc-biblioref">Estes, 1986</a>; <a href="#ref-hintzmanMINERVASimulationModel1984" role="doc-biblioref">Hintzman, 1984</a>; <a href="#ref-medinContextTheoryClassification1978" role="doc-biblioref">Medin &amp; Schaffer, 1978</a>; <a href="#ref-nosofskyAttentionSimilarityIdentificationcategorization1986" role="doc-biblioref">Nosofsky, 1986</a> )</span>. Instance-based models assume that learners encode each experience with a task as a separate instance/exemplar/trace, and that each encoded trace is in turn compared against novel stimuli. As the number of stored instances increases, so does the likelihood that some previously stored instance will be retrieved to aid in the performance of a novel task. Stored instances are retrieved in the context of novel stimuli or tasks if they are sufficiently similar, thus suggesting that the process of computing similarity is of central importance to generalization.</p>
<p>Similarity, defined in this literature as a function of psychological distance between instances or categories, has provided a successful account of generalization across numerous tasks and domains. In an influential study demonstrating an ordinal similarity effect, experimenters employed a numerosity judgment task in which participants quickly report the number of dots flashed on a screen. Performance (in terms of response times to new patterns) on novel dot configurations varied as an inverse function of their similarity to previously trained dot configurations <span class="citation" data-cites="palmeriExemplarSimilarityDevelopment1997">Palmeri (<a href="#ref-palmeriExemplarSimilarityDevelopment1997" role="doc-biblioref">1997</a>)</span>. That is, performance was better on novel configurations moderately similar to trained configurations than to configurations with low-similarity, and also better on low-similarity configurations than to even less similar, unrelated configurations. Instance-based approaches have had some success accounting for performance in certain sub-domains of motor learning <span class="citation" data-cites="cohenWhereGraspsAre2004 crumpEpisodicContributionsSequential2010 meighWhatMemoryRepresentation2018 poldrackRelationshipSkillLearning1999 wifallReachingResponseSelection2017 crumpEpisodicContributionsSequential2010">(<a href="#ref-cohenWhereGraspsAre2004" role="doc-biblioref">Cohen &amp; Rosenbaum, 2004</a>; <a href="#ref-crumpEpisodicContributionsSequential2010" role="doc-biblioref">Crump &amp; Logan, 2010</a>, <a href="#ref-crumpEpisodicContributionsSequential2010" role="doc-biblioref">2010</a>; <a href="#ref-meighWhatMemoryRepresentation2018" role="doc-biblioref">Meigh et al., 2018</a>; <a href="#ref-poldrackRelationshipSkillLearning1999" role="doc-biblioref">Poldrack et al., 1999</a>; <a href="#ref-wifallReachingResponseSelection2017" role="doc-biblioref">Wifall et al., 2017</a>)</span> trained participants to type words on an unfamiliar keyboard, while constraining the letters composing the training words to a pre-specified letter set. Following training, typing speed was tested on previously experienced words composed of previously experienced letters; novel words composed of letters from the trained letter set; and novel words composed of letters from an untrained letter set. Consistent with an instance-based account, transfer performance was graded such that participants were fastest at typing the words they had previously trained on, followed by novel words composed of letters they had trained on, and slowest performance for new words composed of untrained letters.</p>
</section><section id="the-effect-of-training-variability-on-transfer" class="level2" data-number="7.2"><h2 data-number="7.2" class="anchored" data-anchor-id="the-effect-of-training-variability-on-transfer">
<span class="header-section-number">7.2</span> The effect of training variability on transfer</h2>
<p>While similarity-based models account for transfer by the degree of similarity between previous and new experiences, a largely separate body of research has focused on improving transfer by manipulating characteristics of the initial training stage. Such characteristics have included training difficulty, spacing, temporal order, feedback schedules, and the primary focus of the current work – variability of training examples.</p>
<p>Research on the effects of varied training typically compares participants trained under constant, or minimal variability conditions to those trained from a variety of examples or conditions <span class="citation" data-cites="czyzVariabilityPracticeInformation2021 soderstromLearningPerformanceIntegrative2015">(<a href="#ref-czyzVariabilityPracticeInformation2021" role="doc-biblioref">Czyż, 2021</a>; <a href="#ref-soderstromLearningPerformanceIntegrative2015" role="doc-biblioref">Soderstrom &amp; Bjork, 2015</a>)</span>. Varied training has been shown to influence learning in myriad domains including categorization of simple stimuli <span class="citation" data-cites="hahnEffectsCategoryDiversity2005 maddoxStimulusRangeDiscontinuity2011 posnerGenesisAbstractIdeas1968">(<a href="#ref-hahnEffectsCategoryDiversity2005" role="doc-biblioref">Hahn et al., 2005</a>; <a href="#ref-maddoxStimulusRangeDiscontinuity2011" role="doc-biblioref">Maddox &amp; Filoteo, 2011</a>; <a href="#ref-posnerGenesisAbstractIdeas1968" role="doc-biblioref">Posner &amp; Keele, 1968</a>)</span>, complex categorization <span class="citation" data-cites="nosofskyModelguidedSearchOptimal2018">(<a href="#ref-nosofskyModelguidedSearchOptimal2018" role="doc-biblioref">Nosofsky et al., 2018</a>)</span>, language learning <span class="citation" data-cites="jonesDensityDistinctivenessEarly2020 perryLearnLocallyThink2010 twomeyAllRightNoises2018 wonnacottInputEffectsAcquisition2012">(<a href="#ref-jonesDensityDistinctivenessEarly2020" role="doc-biblioref">Jones &amp; Brandt, 2020</a>; <a href="#ref-perryLearnLocallyThink2010" role="doc-biblioref">Perry et al., 2010</a>; <a href="#ref-twomeyAllRightNoises2018" role="doc-biblioref">Twomey et al., 2018</a>; <a href="#ref-wonnacottInputEffectsAcquisition2012" role="doc-biblioref">Wonnacott et al., 2012</a>)</span>, anagram completion <span class="citation" data-cites="goodeSuperiorityVariableRepeated2008">(<a href="#ref-goodeSuperiorityVariableRepeated2008" role="doc-biblioref">Goode et al., 2008</a>)</span>, trajectory extrapolation <span class="citation" data-cites="fulvioTaskSpecificResponseStrategy2014">(<a href="#ref-fulvioTaskSpecificResponseStrategy2014" role="doc-biblioref">Fulvio et al., 2014</a>)</span>, task switching <span class="citation" data-cites="sabahWhenLessMore2019">(<a href="#ref-sabahWhenLessMore2019" role="doc-biblioref">Sabah et al., 2019</a>)</span>, associative learning <span class="citation" data-cites="leeEvidentialDiversityIncreases2019">(<a href="#ref-leeEvidentialDiversityIncreases2019" role="doc-biblioref">Lee et al., 2019</a>)</span>, visual search <span class="citation" data-cites="georgeStimulusVariabilityTask2021 gonzalezDiversityTrainingEnhances2011 kelleyLearningAttendEffects2009">(<a href="#ref-georgeStimulusVariabilityTask2021" role="doc-biblioref">George &amp; Egner, 2021</a>; <a href="#ref-gonzalezDiversityTrainingEnhances2011" role="doc-biblioref">Gonzalez &amp; Madhavan, 2011</a>; <a href="#ref-kelleyLearningAttendEffects2009" role="doc-biblioref">Kelley &amp; Yantis, 2009</a>)</span>, voice identity learning <span class="citation" data-cites="lavanEffectsHighVariability2019">(<a href="#ref-lavanEffectsHighVariability2019" role="doc-biblioref">Lavan et al., 2019</a>)</span>, simple motor learning <span class="citation" data-cites="braunMotorTaskVariation2009 kerrSpecificVariedPractice1978 rollerVariablePracticeLenses2001 willeyLimitedGeneralizationVaried2018">(<a href="#ref-braunMotorTaskVariation2009" role="doc-biblioref">Braun et al., 2009</a>; <a href="#ref-kerrSpecificVariedPractice1978" role="doc-biblioref">Kerr &amp; Booth, 1978</a>; <a href="#ref-rollerVariablePracticeLenses2001" role="doc-biblioref">Roller et al., 2001</a>; <a href="#ref-willeyLimitedGeneralizationVaried2018" role="doc-biblioref">Willey &amp; Liu, 2018a</a>)</span>, sports training <span class="citation" data-cites="greenPracticeVariabilityTransfer1995 greenPracticeVariabilityTransfer1995a">North et al. (<a href="#ref-northEffectConsistentVaried2019" role="doc-biblioref">2019</a>)</span>, and training on a complex video game <span class="citation" data-cites="seowTransferEffectsVaried2019">(<a href="#ref-seowTransferEffectsVaried2019" role="doc-biblioref">Seow et al., 2019</a>)</span>.</p>
<p>Training variation has received a particularly large amount of attention within the domain of visuomotor skill learning. Much of this research has been influenced by the work of <span class="citation" data-cites="schmidtSchemaTheoryDiscrete1975">Schmidt (<a href="#ref-schmidtSchemaTheoryDiscrete1975" role="doc-biblioref">1975</a>)</span>, who proposed a schema-based account of motor learning as an attempt to address the longstanding problem of how novel movements are produced. According to Schema Theory, learners possess general motor programs for classes of movements (e.g.&nbsp;throwing a ball with an underhand movement), as well as schema rules that determine how a motor program is parameterized or scaled for a particular movement. Schema theory predicts that varied training results in the formation of a more general schema-rule, which can allow for transfer to novel movements within a given movement class. Experiments that test this hypothesis are often designed to compare the transfer performance of a constant-trained group against that of a varied-trained group. Both groups train on the same task, but the varied group practices from multiple levels of a task-relevant dimension that remains invariant for the constant group. For example, investigators might train two groups of participants to throw a projectile at a target, with a constant group that throws from a single location, and a varied group that throws from multiple locations. Both groups are then tested from novel locations. Empirically observed benefits of the varied-trained group are then attributed to the variation they received during training, a finding observed in numerous studies <span class="citation" data-cites="catalanoDistantTransferCoincident1984a chuaPracticeVariabilityPromotes2019 goodwinEffectDifferentQuantities1998 kerrSpecificVariedPractice1978 wulfEffectTypePractice1991">(<a href="#ref-catalanoDistantTransferCoincident1984a" role="doc-biblioref">Catalano &amp; Kleiner, 1984</a>; <a href="#ref-chuaPracticeVariabilityPromotes2019" role="doc-biblioref">Chua et al., 2019</a>; <a href="#ref-goodwinEffectDifferentQuantities1998" role="doc-biblioref">Goodwin et al., 1998</a>; <a href="#ref-kerrSpecificVariedPractice1978" role="doc-biblioref">Kerr &amp; Booth, 1978</a>; <a href="#ref-wulfEffectTypePractice1991" role="doc-biblioref">Wulf, 1991</a>)</span>, and the benefits of this variation are typically thought to be mediated by the development of a more general schema for the throwing motion.</p>
<p>Of course, the relationship between training variability and transfer is unlikely to be a simple function wherein increased variation is always beneficial. Numerous studies have found null, or in some cases negative effects of training variation <span class="citation" data-cites="deloshExtrapolationSineQua1997 sinkeviciuteRoleInputVariability2019 wrisbergVariabilityPracticeHypothesis1987">(<a href="#ref-deloshExtrapolationSineQua1997" role="doc-biblioref">DeLosh et al., 1997</a>; <a href="#ref-sinkeviciuteRoleInputVariability2019" role="doc-biblioref">Sinkeviciute et al., 2019</a>; <a href="#ref-wrisbergVariabilityPracticeHypothesis1987" role="doc-biblioref">Wrisberg et al., 1987</a>)</span>, and many more have suggested that the benefits of variability may depend on additional factors such as prior task experience, the order of training trials, or the type of transfer being measured <span class="citation" data-cites="bernikerEffectsTrainingBreadth2014 braithwaiteEffectsVariationPrior2015 hahnEffectsCategoryDiversity2005 lavanEffectsHighVariability2019 northEffectConsistentVaried2019 sadakataIndividualAptitudeMandarin2014 zamanPerceptualVariabilityImplications2021">(<a href="#ref-bernikerEffectsTrainingBreadth2014" role="doc-biblioref">Berniker et al., 2014</a>; <a href="#ref-braithwaiteEffectsVariationPrior2015" role="doc-biblioref">Braithwaite &amp; Goldstone, 2015</a>; <a href="#ref-hahnEffectsCategoryDiversity2005" role="doc-biblioref">Hahn et al., 2005</a>; <a href="#ref-lavanEffectsHighVariability2019" role="doc-biblioref">Lavan et al., 2019</a>; <a href="#ref-northEffectConsistentVaried2019" role="doc-biblioref">North et al., 2019</a>; <a href="#ref-sadakataIndividualAptitudeMandarin2014" role="doc-biblioref">Sadakata &amp; McQueen, 2014</a>; <a href="#ref-zamanPerceptualVariabilityImplications2021" role="doc-biblioref">Zaman et al., 2021</a>)</span>.</p>
</section><section id="issues-with-previous-research" class="level2" data-number="7.3"><h2 data-number="7.3" class="anchored" data-anchor-id="issues-with-previous-research">
<span class="header-section-number">7.3</span> Issues with Previous Research</h2>
<p>Although the benefits of training variation in visuomotor skill learning have been observed many times, null findings have also been repeatedly found, leading some researchers to question the veracity of the variability of practice hypothesis <span class="citation" data-cites="newellSchemaTheory19752003 vanrossumSchmidtSchemaTheory1990">(<a href="#ref-newellSchemaTheory19752003" role="doc-biblioref">Newell, 2003</a>; <a href="#ref-vanrossumSchmidtSchemaTheory1990" role="doc-biblioref">Van Rossum, 1990</a>)</span>. Critics have also pointed out that investigations of the effects of training variability, of the sort described above, often fail to control for the effect of similarity between training and testing conditions. For training tasks in which participants have numerous degrees of freedom (e.g.&nbsp;projectile throwing tasks where participants control the x and y velocity of the projectile), varied groups are likely to experience a wider range of the task space over the course of their training (e.g.&nbsp;more unique combinations of x and y velocities). Experimenters may attempt to account for this possibility by ensuring that the training location(s) of the varied and constant groups are an equal distance away from the eventual transfer locations, such that their training throws are, on average, equally similar to throws that would lead to good performance at the transfer locations. However, even this level of experimental control may still be insufficient to rule out the effect of similarity on transfer. Given that psychological similarity is typically best described as either a Gaussian or exponentially decaying function of psychological distance <span class="citation" data-cites="ennisMultidimensionalStochasticTheory1988 ghahramaniGeneralizationLocalRemappings1996 loganInstanceTheoryAutomatization1988 nosofskySimilarityScalingCognitive1992 shepardUniversalLawGeneralization1987 thoroughmanRapidReshapingHuman2005">(<a href="#ref-ennisMultidimensionalStochasticTheory1988" role="doc-biblioref">Ennis et al., 1988</a>; <a href="#ref-ghahramaniGeneralizationLocalRemappings1996" role="doc-biblioref">Ghahramani et al., 1996</a>; <a href="#ref-loganInstanceTheoryAutomatization1988" role="doc-biblioref">Logan, 1988</a>; <a href="#ref-nosofskySimilarityScalingCognitive1992" role="doc-biblioref">Nosofsky, 1992</a>; <a href="#ref-shepardUniversalLawGeneralization1987" role="doc-biblioref">Shepard, 1987</a>; <a href="#ref-thoroughmanRapidReshapingHuman2005" role="doc-biblioref">Thoroughman &amp; Taylor, 2005</a> )</span>, it is plausible that a subset of the most similar training instances could have a disproportionate impact on generalization to transfer conditions, even if the average distance between training and transfer conditions is identical between groups. Figure 1 demonstrates the consequences of a generalization gradient that drops off as a Gaussian function of distance from training, as compared to a linear drop-off.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">theme_set</span><span class="op">(</span><span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">p</span><span class="op">=</span><span class="fl">2</span></span>
<span><span class="va">c</span><span class="op">&lt;-</span> <span class="fl">.0002</span></span>
<span><span class="va">simdat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">200</span>,<span class="fl">1000</span><span class="op">)</span>,<span class="fl">3</span><span class="op">)</span>,condit<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"varied"</span>,<span class="fl">1602</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"constant"</span>,<span class="fl">801</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                     train.position<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">400</span>,<span class="fl">801</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">800</span>,<span class="fl">801</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">600</span>,<span class="fl">801</span><span class="op">)</span><span class="op">)</span>,c<span class="op">=</span><span class="fl">.0002</span>,p<span class="op">=</span><span class="fl">2</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>                     <span class="fu">mutate</span><span class="op">(</span>plotjitter<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">condit</span><span class="op">==</span><span class="st">"varied"</span>,<span class="fl">0</span>,<span class="fl">7</span><span class="op">)</span>,</span>
<span>                            linScale<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">condit</span><span class="op">==</span><span class="st">"varied"</span>,<span class="fl">980</span>,<span class="fl">1000</span><span class="op">)</span>,</span>
<span>                            genGauss<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">c</span><span class="op">*</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span><span class="op">-</span><span class="va">train.position</span><span class="op">)</span><span class="op">^</span><span class="va">p</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                            genLinear<span class="op">=</span><span class="fl">1000</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">x</span><span class="op">-</span><span class="va">train.position</span><span class="op">)</span><span class="op">+</span><span class="va">plotjitter</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="co">#group_by(condit) %&gt;% mutate(scaleLinear=(genLinear-min(genLinear))/(max(genLinear)-min(genLinear))) %&gt;%</span></span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">x</span>,<span class="va">condit</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">summarise</span><span class="op">(</span>genGauss<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">genGauss</span><span class="op">)</span>,genLinear<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">genLinear</span><span class="op">)</span><span class="op">/</span><span class="va">linScale</span>,.groups <span class="op">=</span> <span class="st">'keep'</span><span class="op">)</span></span>
<span><span class="va">colorVec</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"darkblue"</span>,<span class="st">"darkred"</span><span class="op">)</span></span>
<span><span class="va">plotSpecs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu">geom_line</span><span class="op">(</span>alpha<span class="op">=</span><span class="fl">.7</span>,size<span class="op">=</span><span class="fl">.4</span><span class="op">)</span>,<span class="fu">scale_color_manual</span><span class="op">(</span>values<span class="op">=</span><span class="va">colorVec</span><span class="op">)</span>,</span>
<span>                  <span class="fu">geom_vline</span><span class="op">(</span>alpha<span class="op">=</span><span class="fl">.55</span>,xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">400</span>,<span class="fl">800</span><span class="op">)</span>,color<span class="op">=</span><span class="va">colorVec</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,</span>
<span>                  <span class="fu">geom_vline</span><span class="op">(</span>alpha<span class="op">=</span><span class="fl">.55</span>,xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">600</span><span class="op">)</span>,color<span class="op">=</span><span class="va">colorVec</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>                  <span class="fu">ylim</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1.05</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                  <span class="co">#xlim(c(250,950)),</span></span>
<span>                  <span class="fu">scale_x_continuous</span><span class="op">(</span>breaks<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">200</span>,<span class="fl">1000</span>,by<span class="op">=</span><span class="fl">200</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                  <span class="fu">xlab</span><span class="op">(</span><span class="st">"Test Stimulus"</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">447</span>,y<span class="op">=</span><span class="fl">1.05</span>,label<span class="op">=</span><span class="st">"Varied"</span>,size<span class="op">=</span><span class="fl">3.1</span>,fontface<span class="op">=</span><span class="st">"plain"</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">450</span>,y<span class="op">=</span><span class="fl">1.02</span>,label<span class="op">=</span><span class="st">"Training"</span>,size<span class="op">=</span><span class="fl">3.1</span>,fontface<span class="op">=</span><span class="st">"plain"</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">659</span>,y<span class="op">=</span><span class="fl">1.05</span>,label<span class="op">=</span><span class="st">"Constant"</span>,size<span class="op">=</span><span class="fl">3.1</span>,fontface<span class="op">=</span><span class="st">"plain"</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">657</span>,y<span class="op">=</span><span class="fl">1.02</span>,label<span class="op">=</span><span class="st">"Training"</span>,size<span class="op">=</span><span class="fl">3.1</span>,fontface<span class="op">=</span><span class="st">"plain"</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">847</span>,y<span class="op">=</span><span class="fl">1.05</span>,label<span class="op">=</span><span class="st">"Varied"</span>,size<span class="op">=</span><span class="fl">3.1</span>,fontface<span class="op">=</span><span class="st">"plain"</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">850</span>,y<span class="op">=</span><span class="fl">1.02</span>,label<span class="op">=</span><span class="st">"Training"</span>,size<span class="op">=</span><span class="fl">3.1</span>,fontface<span class="op">=</span><span class="st">"plain"</span><span class="op">)</span>,</span>
<span>                  <span class="fu">theme</span><span class="op">(</span>panel.border <span class="op">=</span> <span class="fu">element_rect</span><span class="op">(</span>colour <span class="op">=</span> <span class="st">"black"</span>, fill<span class="op">=</span><span class="cn">NA</span>, size<span class="op">=</span><span class="fl">1</span><span class="op">)</span>,</span>
<span>                        legend.position<span class="op">=</span><span class="st">"none"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ip1</span> <span class="op">&lt;-</span> <span class="va">simdat</span>  <span class="op">%&gt;%</span> <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">x</span>,y<span class="op">=</span><span class="va">genGauss</span>,group<span class="op">=</span><span class="va">condit</span>,col<span class="op">=</span><span class="va">condit</span><span class="op">)</span><span class="op">)</span><span class="op">+</span><span class="va">plotSpecs</span><span class="op">+</span><span class="fu">ylab</span><span class="op">(</span><span class="st">""</span><span class="op">)</span></span>
<span><span class="va">ip2</span> <span class="op">&lt;-</span> <span class="va">simdat</span> <span class="op">%&gt;%</span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">x</span>,y<span class="op">=</span><span class="va">genLinear</span>,group<span class="op">=</span><span class="va">condit</span>,col<span class="op">=</span><span class="va">condit</span><span class="op">)</span><span class="op">)</span><span class="op">+</span><span class="va">plotSpecs</span><span class="op">+</span><span class="fu">ylab</span><span class="op">(</span><span class="st">"Amount of Generalization"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#gridExtra::grid.arrange(ip2,ip1,ncol=2)</span></span>
<span></span>
<span><span class="va">gtitle</span><span class="op">=</span><span class="st">"Figure 1"</span></span>
<span><span class="va">title</span> <span class="op">=</span> <span class="fu">ggdraw</span><span class="op">(</span><span class="op">)</span><span class="op">+</span><span class="fu">draw_label</span><span class="op">(</span><span class="va">gtitle</span>,fontface <span class="op">=</span> <span class="st">'bold'</span>,x<span class="op">=</span><span class="fl">0</span>,hjust<span class="op">=</span><span class="fl">0</span>,size<span class="op">=</span><span class="fl">11</span><span class="op">)</span><span class="op">+</span><span class="fu">theme</span><span class="op">(</span>plot.margin <span class="op">=</span> <span class="fu">margin</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">captionText</span><span class="op">=</span><span class="fu">str_wrap</span><span class="op">(</span><span class="st">"Figure 1. Left panel: Generalization predicted from a simple model that assumes a linear generalization function. A varied group (red vertical lines indicate the 2 training locations) trained from positions 400 and 800, and a constant group (blue vertical line), trained from position 600. Right panel: if a Gaussian generalization function is assumed, then varied training (400, 800) is predicted to result in better generalization to positions close to 400 and 800 than does constant training at 600. "</span>,<span class="fl">200</span><span class="op">)</span></span>
<span><span class="va">capt</span><span class="op">=</span><span class="fu">ggdraw</span><span class="op">(</span><span class="op">)</span><span class="op">+</span><span class="fu">draw_label</span><span class="op">(</span><span class="va">captionText</span>,fontface <span class="op">=</span> <span class="st">'italic'</span>,x<span class="op">=</span><span class="fl">0</span>,hjust<span class="op">=</span><span class="fl">0</span>,size<span class="op">=</span><span class="fl">11</span><span class="op">)</span><span class="op">+</span><span class="fu">theme</span><span class="op">(</span>plot.margin <span class="op">=</span> <span class="fu">margin</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">plot_grid</span><span class="op">(</span><span class="va">title</span>,<span class="cn">NULL</span>,<span class="va">ip1</span>,<span class="va">ip2</span>,<span class="va">capt</span>,<span class="cn">NULL</span>,ncol<span class="op">=</span><span class="fl">2</span>,rel_heights<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.1</span>,<span class="fl">1</span>,<span class="fl">.15</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>In addition to largely overlooking the potential for non-linear generalization to confound interpretations of training manipulations, the visuomotor skill learning literature also rarely considers alternatives to schema representations <span class="citation" data-cites="chamberlinMemoryRepresentationMotor1992">(<a href="#ref-chamberlinMemoryRepresentationMotor1992" role="doc-biblioref">Chamberlin &amp; Magill, 1992b</a>)</span>. Although schema-theory remains influential within certain literatures, instance or exemplar-based models have accounted for human behavior across myriad domains <span class="citation" data-cites="jamiesonInstanceTheoryDomaingeneral2022 loganInstanceTheoryAttention2002a">(<a href="#ref-jamiesonInstanceTheoryDomaingeneral2022" role="doc-biblioref">Jamieson et al., 2022</a>; <a href="#ref-loganInstanceTheoryAttention2002a" role="doc-biblioref">Logan, 2002</a>)</span>. As mentioned above, instance based accounts have been shown to perform well on a variety of different tasks with motoric components <span class="citation" data-cites="crumpEpisodicContributionsSequential2010 gandolfoMotorLearningField1996a meighWhatMemoryRepresentation2018 rosenbaumPlanningReachesEvaluating1995 vandamMappingShapeVisuomotor2015">(<a href="#ref-crumpEpisodicContributionsSequential2010" role="doc-biblioref">Crump &amp; Logan, 2010</a>; <a href="#ref-gandolfoMotorLearningField1996a" role="doc-biblioref">Gandolfo et al., 1996</a>; <a href="#ref-meighWhatMemoryRepresentation2018" role="doc-biblioref">Meigh et al., 2018</a>; <a href="#ref-rosenbaumPlanningReachesEvaluating1995" role="doc-biblioref">Rosenbaum et al., 1995</a>; <a href="#ref-vandamMappingShapeVisuomotor2015" role="doc-biblioref">van Dam &amp; Ernst, 2015</a>)</span>. However, such accounts have received little attention within the subdomain of visuomotor skill learning focused on the benefits of varied training.</p>
<p>The present work examines whether the commonly observed benefits of varied training can be accounted for by between-group differences in similarity between training and testing throws. We first attempt to replicate previous work finding an advantage of varied training over constant training in a projectile launching task. We then examine the extent to which this advantage can be explained by an instance-based similarity model.</p>
</section></section><section id="experiment-1" class="level1" data-number="8"><h1 data-number="8">
<span class="header-section-number">8</span> Experiment 1</h1>
<section id="methods" class="level2" data-number="8.1"><h2 data-number="8.1" class="anchored" data-anchor-id="methods">
<span class="header-section-number">8.1</span> Methods</h2>
<section id="sample-size-estimation" class="level3" data-number="8.1.1"><h3 data-number="8.1.1" class="anchored" data-anchor-id="sample-size-estimation">
<span class="header-section-number">8.1.1</span> Sample Size Estimation</h3>
<p>To obtain an independent estimate of effect size, we identified previous investigations which included between-subjects contrasts of varied and constant conditions following training on an accuracy based projectile launching task <span class="citation" data-cites="chuaPracticeVariabilityPromotes2019 goodwinEffectDifferentQuantities1998 kerrSpecificVariedPractice1978 wulfEffectTypePractice1991">(<a href="#ref-chuaPracticeVariabilityPromotes2019" role="doc-biblioref">Chua et al., 2019</a>; <a href="#ref-goodwinEffectDifferentQuantities1998" role="doc-biblioref">Goodwin et al., 1998</a>; <a href="#ref-kerrSpecificVariedPractice1978" role="doc-biblioref">Kerr &amp; Booth, 1978</a>; <a href="#ref-wulfEffectTypePractice1991" role="doc-biblioref">Wulf, 1991</a>)</span>. We then averaged effects across these studies, yielding a Cohens f =.43. The GPower 3.1 software package <span class="citation" data-cites="faulStatisticalPowerAnalyses2009">(<a href="#ref-faulStatisticalPowerAnalyses2009" role="doc-biblioref">Faul et al., 2009</a>)</span>, 2009) was then used to determine that a power of 80% requires a sample size of at least 23 participants per condition. All experiments reported in the present manuscript exceed this minimum number of participants per condition.</p>
</section><section id="participants" class="level3" data-number="8.1.2"><h3 data-number="8.1.2" class="anchored" data-anchor-id="participants">
<span class="header-section-number">8.1.2</span> Participants</h3>
<p>Participants were recruited from an undergraduate population that is 63% female and consists almost entirely of individuals aged 18-22 years. A total of 110 Indiana University psychology students participated in Experiment 1. We subsequently excluded 34 participants poor performance at one of the dependent measures of the task (2.5-3 standard deviations worse than the median subject at the task) or for displaying a pattern of responses that was clearly indicative of a lack of engagement with the task (e.g.&nbsp;simply dropping the ball on each trial rather than throwing it at the target), or for reporting that they completed the experiment on a phone or tablet device, despite the instructions not to use one of these devices. A total of 74 participants were retained for the final analyses, 35 in the varied group and 39 in the constant group.</p>
</section><section id="task" class="level3" data-number="8.1.3"><h3 data-number="8.1.3" class="anchored" data-anchor-id="task">
<span class="header-section-number">8.1.3</span> Task</h3>
<p>The experimental task was programmed in JavaScript, using packages from the Phaser physics engine (https://phaser.io) and the jsPsych library (de Leeuw, 2015). The stimuli, presented on a black background, consisted of a circular blue ball – controlled by the participant via the mouse or trackpad cursor; a rectangular green target; a red rectangular barrier located between the ball and the target; and an orange square within which the participant could control the ball before releasing it in a throw towards the target. Because the task was administered online, the absolute distance between stimuli could vary depending on the size of the computer monitor being used, but the relative distance between the stimuli was held constant. Likewise, the distance between the center of the target, and the training and testing locations was scaled such that relative distances were preserved regardless of screen size. For the sake of brevity, subsequent mentions of this relative distance between stimuli, or the position where the ball landed in relation to the center of the target, will be referred to simply as distance. Methods Figure 2 displays the layout of the task, as it would appear to a participant at the start of a trial, with the ball appearing in the center of the orange square. Using a mouse or trackpad, participants click down on the ball to take control of the ball, connecting the movement of the ball to the movement of the cursor. Participants can then “wind up” the ball by dragging it (within the confines of the orange square) and then launch the ball by releasing the cursor. If the ball does not land on the target, participants are presented with feedback in red text at the top right of the screen, on how many units away they were from the center of the target. If the ball was thrown outside of the boundary of the screen participants are given feedback as to how far away from the target center the ball would have been if it had continued its trajectory. If the ball strikes the barrier (from the side or by landing on top), feedback is presented telling participants to avoid hitting the barrier. If participants drag the ball outside of the orange square before releasing it, the trial terminates, and they are reminded to release the ball within the orange square. If the ball lands on the target, feedback is presented in green text, confirming that the target was hit, and presenting additional feedback on how many units away the ball was from the exact center of the target.</p>
<p><a href="https://pcl.sitehost.iu.edu/tg/demos/igas_expt1_demo.html" target="_blank">Link to abbrevaited example of task</a>.</p>
</section></section><section id="results" class="level2" data-number="8.2"><h2 data-number="8.2" class="anchored" data-anchor-id="results">
<span class="header-section-number">8.2</span> Results</h2>
</section><section id="data-processing-and-statistical-packages" class="level2" data-number="8.3"><h2 data-number="8.3" class="anchored" data-anchor-id="data-processing-and-statistical-packages">
<span class="header-section-number">8.3</span> Data Processing and Statistical Packages</h2>
<p>To prepare the data, we first removed trials that were not easily interpretable as performance indicators in our task. Removed trials included: 1) those in which participants dragged the ball outside of the orange starting box without releasing it, 2) trials in which participants clicked on the ball, and then immediately released it, causing the ball to drop straight down, 3) outlier trials in which the ball was thrown more than 2.5 standard deviations further than the average throw (calculated separately for each throwing position), and 4) trials in which the ball struck the barrier. The primary measure of performance used in all analyses was the absolute distance away from the center of the target. The absolute distance was calculated on every trial, and then averaged within each subject to yield a single performance score, for each position. A consistent pattern across training and testing phases in both experiments was for participants to perform worse from throwing positions further away from the target – a pattern which we refer to as the difficulty of the positions. However, there were no interactions between throwing position and training conditions, allowing us to collapse across positions in cases where contrasts for specific positions were not of interest. All data processing and statistical analyses were performed in R version 4.03 (R Core Team, 2020). ANOVAs for group comparisons were performed using the rstatix package (Kassambara, 2021)****.</p>
</section><section id="training-phase" class="level2" data-number="8.4"><h2 data-number="8.4" class="anchored" data-anchor-id="training-phase">
<span class="header-section-number">8.4</span> Training Phase</h2>
<p>Figure 3 below shows aggregate training performance binned into three stages representing the beginning, middle, and end of the training phase. Because the two conditions trained from target distances that were not equally difficult, it was not possible to directly compare performance between conditions in the training phase. Our focus for the training data analysis was instead to establish that participants did improve their performance over the course of training, and to examine whether there was any interaction between training stage and condition. Descriptive statistics for the intermittent testing phase are provided in the supplementary materials.</p>
<p>We performed an ANOVA comparison with stage as a within-group factor and condition as between-group factor. The analysis revealed a significant effect of training stage F(2,142)=62.4, p&lt;.001, <span class="math inline">\(\eta^{2}_G\)</span> = .17, such that performance improved over the course of training There was no significant effect of condition F(1,71)=1.42, p=.24, <span class="math inline">\(\eta^{2}_G\)</span> = .02, and no significant interaction between condition and training stage, F(2,142)=.10, p=.91, <span class="math inline">\(\eta^{2}_G\)</span> &lt; .01.</p>
</section><section id="testing-phase" class="level2" data-number="8.5"><h2 data-number="8.5" class="anchored" data-anchor-id="testing-phase">
<span class="header-section-number">8.5</span> Testing Phase</h2>
<p>In Experiment 1, a single constant-trained group was compared against a single varied-trained group. At the transfer phase, all participants were tested from 3 positions: 1) the positions(s) from their own training, 2) the training position(s) of the other group, and 3) a position novel to both groups. Overall, group performance was compared with a mixed type III ANOVA, with condition (varied vs.&nbsp;constant) as a between-subject factor and throwing location as a within-subject variable. The effect of throwing position was strong, F(3,213) = 56.12, p&lt;.001, η2G = .23. The effect of training condition was significant F(1,71)=8.19, p&lt;.01, η2G = .07. There was no significant interaction between group and position, F(3,213)=1.81, p=.15, η2G = .01.</p>
<p><br><br></p>
</section><section id="discussion" class="level2" data-number="8.6"><h2 data-number="8.6" class="anchored" data-anchor-id="discussion">
<span class="header-section-number">8.6</span> Discussion</h2>
<p>In Experiment 1, we found that varied training resulted in superior testing performance than constant training, from both a position novel to both groups, and from the position at which the constant group was trained, which was novel to the varied condition. The superiority of varied training over constant training even at the constant training position is of particular note, given that testing at this position should have been highly similar for participants in the constant condition. It should also be noted, though, that testing at the constant trained position is not exactly identical to training from that position, given that the context of testing is different in several ways from that of training, such as the testing trials from the different positions being intermixed, as well as a simple change in context as a function of time. Such contextual differences will be further considered in the General Discussion.</p>
<p>In addition to the variation of throwing position during training, the participants in the varied condition of Experiment 1 also received training practice from the closest/easiest position, as well as from the furthest/most difficult position that would later be encountered by all participants during testing. The varied condition also had the potential advantage of interpolating both of the novel positions from which they would later be tested. Experiment 2 thus sought to address these issues by comparing a varied condition to multiple constant conditions.</p>
</section></section><section id="experiment-2" class="level1" data-number="9"><h1 data-number="9">
<span class="header-section-number">9</span> Experiment 2</h1>
<p>In Experiment 2, we sought to replicate our findings from Experiment 1 with a new sample of participants, while also addressing the possibility of the pattern of results in Experiment 1 being explained by some idiosyncrasy of the particular training location of the constant group relative to the varied group. To this end, Experiment 2 employed the same basic procedure as Experiment 1, but was designed with six separate constant groups each trained from one of six different locations (400, 500, 625, 675, 800, or 900), and a varied group trained from two locations (500 and 800). Participants in all seven groups were then tested from each of the 6 unique positions.</p>
<section id="methods-1" class="level2" data-number="9.1"><h2 data-number="9.1" class="anchored" data-anchor-id="methods-1">
<span class="header-section-number">9.1</span> Methods</h2>
<section id="participants-1" class="level3" data-number="9.1.1"><h3 data-number="9.1.1" class="anchored" data-anchor-id="participants-1">
<span class="header-section-number">9.1.1</span> Participants</h3>
<p>A total of 306 Indiana University psychology students participated in Experiment 2, which was also conducted online. As was the case in experiment 1, the undergraduate population from which we recruited participants was 63% female and primarily composed of 18–22-year-old individuals. Using the same procedure as experiment 1, we excluded 98 participants for exceptionally poor performance at one of the dependent measures of the task, or for displaying a pattern of responses indicative of a lack of engagement with the task. A total of 208 participants were included in the final analyses with 31 in the varied group and 32, 28, 37, 25, 29, 26 participants in the constant groups training from location 400, 500, 625, 675, 800, and 900, respectively. All participants were compensated with course credit.</p>
</section><section id="task-and-procedure" class="level3" data-number="9.1.2"><h3 data-number="9.1.2" class="anchored" data-anchor-id="task-and-procedure">
<span class="header-section-number">9.1.2</span> Task and Procedure</h3>
<p>The task of Experiment 2 was identical to that of Experiment 1, in all but some minor adjustments to the height of the barrier, and the relative distance between the barrier and the target. Additionally, the intermittent testing trials featured in experiment 1 were not utilized in experiment 2, and all training and testing trials were presented with feedback. An abbreviated demo of the task used for Experiment 2 can be found at (https://pcl.sitehost.iu.edu/tg/demos/igas_expt2_demo.html).</p>
<p>The procedure for Experiment 2 was also quite similar to experiment 1. Participants completed 140 training trials, all of which were from the same position for the constant groups and split evenly (70 trials each - randomized) for the varied group. In the testing phase, participants completed 30 trials from each of the six locations that had been used separately across each of the constant groups during training. Each of the constant groups thus experience one trained location and five novel throwing locations in the testing phase, while the varied group experiences 2 previously trained, and 4 novel locations.</p>
</section></section><section id="results-1" class="level2" data-number="9.2"><h2 data-number="9.2" class="anchored" data-anchor-id="results-1">
<span class="header-section-number">9.2</span> Results</h2>
<section id="data-processing-and-statistical-packages-1" class="level3" data-number="9.2.1"><h3 data-number="9.2.1" class="anchored" data-anchor-id="data-processing-and-statistical-packages-1">
<span class="header-section-number">9.2.1</span> Data Processing and Statistical Packages</h3>
<p>After confirming that condition and throwing position did not have any significant interactions, we standardized performance within each position, and then average across position to yield a single performance measure per participant. This standardization did not influence our pattern of results. As in experiment 1, we performed type III ANOVA’s due to our unbalanced design, however the pattern of results presented below is not altered if type 1 or type III tests are used instead. The statistical software for the primary analyses was the same as for experiment 1. Individual learning rates in the testing phase, compared between groups in the supplementary analyses, were fit using the TEfit package in R <span class="citation" data-cites="cochraneTEfitsNonlinearRegression2020">(<a href="#ref-cochraneTEfitsNonlinearRegression2020" role="doc-biblioref">Cochrane, 2020</a>)</span>.</p>
</section><section id="training-phase-1" class="level3" data-number="9.2.2"><h3 data-number="9.2.2" class="anchored" data-anchor-id="training-phase-1">
<span class="header-section-number">9.2.2</span> Training Phase</h3>
<p>The different training conditions trained from positions that were not equivalently difficult and are thus not easily amenable to comparison. As previously stated, the primary interest of the training data is confirmation that some learning did occur. Figure 5 depicts the training performance of the varied group alongside that of the aggregate of the six constant groups (5a), and each of the 6 separate constant groups (5b). An ANOVA comparison with training stage (beginning, middle, end) as a within-group factor and group (the varied condition vs.&nbsp;the 6 constant conditions collapsed together) as a between-subject factor revealed no significant effect of group on training performance, F(1,206)=.55,p=.49, <span class="math inline">\(\eta^{2}_G\)</span> &lt;.01, a significant effect of training stage F(2,412)=77.91, p&lt;.001, <span class="math inline">\(\eta^{2}_G\)</span> =.05, and no significant interaction between group and training stage, F(2,412)=.489 p=.61, <span class="math inline">\(\eta^{2}_G\)</span> &lt;.01. We also tested for a difference in training performance between the varied group and the two constant groups that trained matching throwing positions (i.e., the constant groups training from position 500, and position 800). The results of our ANOVA on this limited dataset mirrors that of the full-group analysis, with no significant effect of group F(1,86)=.48, p=.49, <span class="math inline">\(\eta^{2}_G\)</span> &lt;.01, a significant effect of training stage F(2,172)=56.29, p&lt;.001, <span class="math inline">\(\eta^{2}_G\)</span> =.11, and no significant interaction between group and training stage, F(2,172)=.341 p=.71, <span class="math inline">\(\eta^{2}_G\)</span> &lt;.01.</p>
</section><section id="testing-phase-1" class="level3" data-number="9.2.3"><h3 data-number="9.2.3" class="anchored" data-anchor-id="testing-phase-1">
<span class="header-section-number">9.2.3</span> Testing Phase</h3>
<p>In Experiment 2, a single varied condition (trained from two positions, 500 and 800), was compared against six separate constant groups (trained from a single position, 400, 500, 625, 675, 800 or 900). For the testing phase, all participants were tested from all six positions, four of which were novel for the varied condition, and five of which were novel for each of the constant groups. For a general comparison, we took the absolute deviations for each throwing position and computed standardized scores across all participants, and then averaged across throwing position. The six constant groups were then collapsed together allowing us to make a simple comparison between training conditions (constant vs. varied). A type III between-subjects ANOVA was performed, yielding a significant effect of condition F(1,206)=4.33, p=.039, <span class="math inline">\(\eta^{2}_G\)</span> =.02. Descriptive statistics for each condition are shown in table 2. Figure 6A visualizes the consistent advantage of the varied condition over the constant groups across the testing positions. Figure 6b shows performance between the varied condition and the individual constant groups.</p>
<p><br><br><br></p>
<p>Next, we compared the testing performance of constant and varied groups from only positions that participants had not encountered during training. Constant participants each had 5 novel positions, whereas varied participants tested from 4 novel positions (400,625,675,900). We first standardized performance within in each position, and then averaged across positions. Here again, we found a significant effect of condition (constant vs.&nbsp;varied): F(1,206)=4.30, p=.039, <span class="math inline">\(\eta^{2}_G\)</span> = .02 .</p>
<p>Finally, corresponding to the comparison of position 760 from experiment 1, we compared the test performance of the varied group against the constant group from only the positions that the constant groups trained. Such positions were novel to the varied group (thus this analysis omitted two constant groups that trained from positions 500 or 800 as those positions were not novel to the varied group). Figure 7 displays the particular subset of comparisons utilized for this analysis. Again, we standardized performance within each position before performing the analyses on the aggregated data. In this case, the effect of condition did not reach statistical significance F(1,149)=3.14, p=.079, <span class="math inline">\(\eta^{2}_G\)</span> = .02. Table 4 provides descriptive statistics.</p>
<p><br><br></p>
</section></section><section id="discussion-1" class="level2" data-number="9.3"><h2 data-number="9.3" class="anchored" data-anchor-id="discussion-1">
<span class="header-section-number">9.3</span> Discussion</h2>
<p>The results of experiment 2 largely conform to the findings of experiment 1. Participants in both varied and constant conditions improved at the task during the training phase. We did not observe the common finding of training under varied conditions producing worse performance during acquisition than training under constant conditions <span class="citation" data-cites="catalanoDistantTransferCoincident1984a wrisbergVariabilityPracticeHypothesis1987">(<a href="#ref-catalanoDistantTransferCoincident1984a" role="doc-biblioref">Catalano &amp; Kleiner, 1984</a>; <a href="#ref-wrisbergVariabilityPracticeHypothesis1987" role="doc-biblioref">Wrisberg et al., 1987</a>)</span>, which has been suggested to relate to the subsequent benefits of varied training in retention and generalization testing <span class="citation" data-cites="soderstromLearningPerformanceIntegrative2015">(<a href="#ref-soderstromLearningPerformanceIntegrative2015" role="doc-biblioref">Soderstrom &amp; Bjork, 2015</a>)</span>. However our finding of no difference in training performance between constant and varied groups has been observed in previous work <span class="citation" data-cites="chuaPracticeVariabilityPromotes2019 moxleySchemaVariabilityPractice1979 pigottMotorSchemaStructure1984">(<a href="#ref-chuaPracticeVariabilityPromotes2019" role="doc-biblioref">Chua et al., 2019</a>; <a href="#ref-moxleySchemaVariabilityPractice1979" role="doc-biblioref">Moxley, 1979</a>; <a href="#ref-pigottMotorSchemaStructure1984" role="doc-biblioref">Pigott &amp; Shapiro, 1984</a>)</span>.</p>
<p>In the testing phase, our varied group significantly outperformed the constant conditions in both a general comparison, and in an analysis limited to novel throwing positions. The observed benefit of varied over constant training echoes the findings of many previous visuomotor skill learning studies that have continued to emerge since the introduction of Schmidt’s influential Schema Theory <span class="citation" data-cites="catalanoDistantTransferCoincident1984a chuaPracticeVariabilityPromotes2019 goodwinEffectDifferentQuantities1998 mccrackenTestSchemaTheory1977 moxleySchemaVariabilityPractice1979 newellVariabilityPracticeTransfer1976 pigottMotorSchemaStructure1984 rollerVariablePracticeLenses2001 schmidtSchemaTheoryDiscrete1975 willeyLongtermMotorLearning2018 wrisbergVariabilityPracticeHypothesis1987 wulfEffectTypePractice1991">(<a href="#ref-catalanoDistantTransferCoincident1984a" role="doc-biblioref">Catalano &amp; Kleiner, 1984</a>; <a href="#ref-chuaPracticeVariabilityPromotes2019" role="doc-biblioref">Chua et al., 2019</a>; <a href="#ref-goodwinEffectDifferentQuantities1998" role="doc-biblioref">Goodwin et al., 1998</a>; <a href="#ref-mccrackenTestSchemaTheory1977" role="doc-biblioref">McCracken &amp; Stelmach, 1977</a>; <a href="#ref-moxleySchemaVariabilityPractice1979" role="doc-biblioref">Moxley, 1979</a>; <a href="#ref-newellVariabilityPracticeTransfer1976" role="doc-biblioref">Newell &amp; Shapiro, 1976</a>; <a href="#ref-pigottMotorSchemaStructure1984" role="doc-biblioref">Pigott &amp; Shapiro, 1984</a>; <a href="#ref-rollerVariablePracticeLenses2001" role="doc-biblioref">Roller et al., 2001</a>; <a href="#ref-schmidtSchemaTheoryDiscrete1975" role="doc-biblioref">Schmidt, 1975</a>; <a href="#ref-willeyLongtermMotorLearning2018" role="doc-biblioref">Willey &amp; Liu, 2018b</a>; <a href="#ref-wrisbergVariabilityPracticeHypothesis1987" role="doc-biblioref">Wrisberg et al., 1987</a>; <a href="#ref-wulfEffectTypePractice1991" role="doc-biblioref">Wulf, 1991</a>)</span>. We also join a much smaller set of research to observe this pattern in a computerized task <span class="citation" data-cites="seowTransferEffectsVaried2019">(<a href="#ref-seowTransferEffectsVaried2019" role="doc-biblioref">Seow et al., 2019</a>)</span>. One departure from the experiment 1 findings concerns the pattern wherein the varied group outperformed the constant group even from the training position of the constant group, which was significant in experiment 1, but did not reach significance in experiment 2. Although this pattern has been observed elsewhere in the literature <span class="citation" data-cites="goodeSuperiorityVariableRepeated2008 kerrSpecificVariedPractice1978">(<a href="#ref-goodeSuperiorityVariableRepeated2008" role="doc-biblioref">Goode et al., 2008</a>; <a href="#ref-kerrSpecificVariedPractice1978" role="doc-biblioref">Kerr &amp; Booth, 1978</a>)</span>, the overall evidence for this effect appears to be far weaker than for the more general benefit of varied training in conditions novel to all training groups.</p>
</section></section><section id="computational-model" class="level1" data-number="10"><h1 data-number="10">
<span class="header-section-number">10</span> Computational Model</h1>
<p>Controlling for the similarity between training and testing The primary goal of Experiment 2 was to examine whether the benefits of variability would persist after accounting for individual differences in the similarity between trained and tested throwing locations. To this end, we modelled each throw as a two-dimensional point in the space of x and y velocities applied to the projectile at the moment of release. For each participant, we took each individual training throw, and computed the similarity between that throw and the entire population of throws within the solution space for each of the 6 testing positions. We defined the solution space empirically as the set of all combinations of x and y throw velocities that resulted in hitting the target. We then summed each of the trial-level similarities to produce a single similarity for each testing position score relating how the participant threw the ball during training and the solutions that would result in target hits from each of the six testing positions – thus resulting in six separate similarity scores for each participant. Figure 8a visualizes the solution space for each location and illustrates how different combinations of x and y velocity result in successfully striking the target from different launching positions. As illustrated in Figure 8b, the solution throws represent just a small fraction of the entire space of velocity combinations used by participants throughout the experiment.</p>
<p>(ref:taskSpace) Figure 8a is a visual representation of the combinations of throw parameters (x and y velocities applied to the ball at launch), which resulted in target hits during the testing phase. This empirical solution space was compiled from all of the participants in experiment 2. Figure 8b shows the solution space within the context of all of the throws made throughout the testing phase of the experiment.</p>
<p>For each individual trial, the Euclidean distance (Equation 1) was computed between the velocity components (x and y) of that trial and the velocity components of each individual solution throw for each of the 6 positions from which participants would be tested in the final phase of the study. The P parameter in Equation 1 is set equal to 2, reflecting a Gaussian similarity gradient. Then, as per an instance-based model of similarity <span class="citation" data-cites="loganInstanceTheoryAttention2002a nosofskySimilarityScalingCognitive1992">(<a href="#ref-loganInstanceTheoryAttention2002a" role="doc-biblioref">Logan, 2002</a>; <a href="#ref-nosofskySimilarityScalingCognitive1992" role="doc-biblioref">Nosofsky, 1992</a>)</span>, these distances were multiplied by a sensitivity parameter, c, and then exponentiated to yield a similarity value. The parameter c controls the rate with which similarity-based generalization drops off as the Euclidean distance between two throws in x- and y-velocity space increases. If c has a large value, then even a small difference between two throws’ velocities greatly decreases the extent of generalization from one to the other. A small value for c produces broad generalization from one throw to another despite relatively large differences in their velocities. The similarity values for each training individual throw made by a given participant were then summed to yield a final similarity score, with a separate score computed for each of the 6 testing positions. The final similarity score is construable as index of how accurate the throws a participant made during the training phase would be for each of the testing positions.</p>
<p><strong>Equation 1:</strong> [ Similarity_{I,J} = * e<sup>{-c</sup>dp_{i,j}} ]</p>
<p><strong>Equation 2:</strong> <span class="math display">\[ d_{i,j} = \sqrt{(x_{Train_i}-x_{Solution_j})^2 + (y_{Train_i}-y_{Solution_j})^2 } \]</span></p>
<p>A simple linear regression revealed that these similarity scores were significantly predictive of performance in the transfer stage, t =-15.88, p&lt;.01, <span class="math inline">\(r^2\)</span>=.17, such that greater similarity between training throws and solution spaces for each of the test locations resulted in better performance. We then repeated the group comparisons above while including similarity as a covariate in the model. Comparing the varied and constant groups in testing performance from all testing positions yielded a significant effect of similarity, F(1, 205)=85.66, p&lt;.001, <span class="math inline">\(\eta^{2}_G\)</span> =.29, and also a significant effect of condition (varied vs.&nbsp;constant), F(1, 205)=6.03, p=.015, <span class="math inline">\(\eta^{2}_G\)</span> =.03. The group comparison limited to only novel locations for the varied group pit against trained location for the constant group resulted in a significant effect of similarity, F(1,148)=31.12, p&lt;.001, <span class="math inline">\(\eta^{2}_G\)</span> =.18 as well as for condition F(1,148)=11.55, p&lt;.001, <span class="math inline">\(\eta^{2}_G\)</span> =.07. For all comparisons, the pattern of results was consistent with the initial findings from experiment 2, with the varied group still performing significantly better than the constant group.</p>
<section id="fitting-model-parameters-separately-by-group" class="level2" data-number="10.1"><h2 data-number="10.1" class="anchored" data-anchor-id="fitting-model-parameters-separately-by-group">
<span class="header-section-number">10.1</span> Fitting model parameters separately by group</h2>
<p>To directly control for similarity in Experiment 2, we developed a model-based measure of the similarity between training throws and testing conditions. This similarity measure was a significant predictor of testing performance, e.g., participants whose training throws were more similar to throws that resulted in target hits from the testing positions, tended to perform better during the testing phase. Importantly, the similarity measure did not explain away the group-level benefits of varied training, which remained significant in our linear model predicting testing performance after similarity was added to the model. However, previous research has suggested that participants may differ in their level of generalization as a function of prior experience, and that such differences in generalization gradients can be captured by fitting the generalization parameter of an instance-based model separately to each group <span class="citation" data-cites="hahnEffectsCategoryDiversity2005 lambertsFlexibleTuningSimilarity1994">(<a href="#ref-hahnEffectsCategoryDiversity2005" role="doc-biblioref">Hahn et al., 2005</a>; <a href="#ref-lambertsFlexibleTuningSimilarity1994" role="doc-biblioref">Lamberts, 1994</a>)</span>. Relatedly, the influential Bayesian generalization model developed by <span class="citation" data-cites="tenenbaumGeneralizationSimilarityBayesian2001a">Tenenbaum &amp; Griffiths (<a href="#ref-tenenbaumGeneralizationSimilarityBayesian2001a" role="doc-biblioref">2001</a>)</span> predicts that the breadth of generalization will increase when a rational agent encounters a wider variety of examples. Following these leads, we assume that in addition to learning the task itself, participants are also adjusting how generalizable their experience should be. Varied versus constant participants may be expected to learn to generalize their experience to different degrees. To accommodate this difference, the generalization parameter of the instance-based model (in the present case, the c parameter) can be allowed to vary between the two groups to reflect the tendency of learners to adaptively tune the extent of their generalization. One specific hypothesis is that people adaptively set a value of c to fit the variability of their training experience <span class="citation" data-cites="nosofskyExemplarbasedAccountsMultiplesystem2000 sakamotoTrackingVariabilityLearning2006">(<a href="#ref-nosofskyExemplarbasedAccountsMultiplesystem2000" role="doc-biblioref">Nosofsky &amp; Johansen, 2000</a>; <a href="#ref-sakamotoTrackingVariabilityLearning2006" role="doc-biblioref">Sakamoto et al., 2006</a>)</span>. If one’s training experience is relatively variable, as with the variable training condition, then one might infer that future test situations will also be variable, in which case a low value of c will allow better generalization because generalization will drop off slowly with training-to-testing distance. Conversely, if one’s training experience has little variability, as found in the constant training conditions, then one might adopt a high value of c so that generalization falls off rapidly away from the trained positions.</p>
<p>To address this possibility, we compared the original instance-based model of similarity fit against a modified model which separately fits the generalization parameter, c, to varied and constant participants. To perform this parameter fitting, we used the optim function in R, and fit the model to find the c value(s) that maximized the correlation between similarity and testing performance.</p>
<p>Both models generate distinct similarity values between training and testing locations. Much like the analyses in Experiment 2, these similarity values are regressed against testing performance in models of the form shown below. As was the case previously, testing performance is defined as the mean absolute distance from the center of the target (with a separate score for each participant, from each position).</p>
<p>Linear models 1 and 3 both show that similarity is a significant predictor of testing performance (p&lt;.01). Of greater interest is the difference between linear model 2, in which similarity is computed from a single c value fit from all participants (Similarity1c), with linear model 4, which fits the c parameter separately between groups (Similarity2c). In linear model 2, the effect of training group remains significant when controlling for Similarity1c (p&lt;.01), with the varied group still performing significantly better. However, in linear model 4 the addition of the Similarity2c predictor results in the effect of training group becoming nonsignificant (p=.40), suggesting that the effect of varied vs.&nbsp;constant training is accounted for by the Similarity2c predictor. Next, to further establish a difference between the models, we performed nested model comparisons using ANOVA, to see if the addition of the training group parameter led to a significant improvement in model performance. In the first comparison, ANOVA(Linear Model 1, Linear Model 2), the addition of the training group predictor significantly improved the performance of the model (F=22.07, p&lt;.01). However, in the second model comparison, ANOVA (Linear model 3, Linear Model 4) found no improvement in model performance with the addition of the training group predictor (F=1.61, p=.20).</p>
<p>Finally, we sought to confirm that similarity values generated from the adjusted Similarity2c model had more predictive power than those generated from the original Similarity1c model. Using the BIC function in R, we compared BIC values between linear model 1 (BIC=14604.00) and linear model 3 (BIC = 14587.64). The lower BIC value of model 3 suggests a modest advantage for predicting performance using a similarity measure computed with two c values over similarity computed with a single c value. When fit with separate c values, the best fitting c parameters for the model consistently optimized such that the c value for the varied group (c=.00008) was smaller in magnitude than the c value for the constant group(c= .00011). Recall that similarity decreases as a Gaussian function of distance (equation 1 above), and a smaller value of c will result in a more gradual drop-off in similarity as the distance between training throws and testing solutions increases.</p>
<p>In summary, our modeling suggests that an instance-based model which assumes equivalent generalization gradients between constant and varied trained participants is unable to account for the extent of benefits of varied over constant training observed at testing. The evidence for this in the comparative model fits is that when a varied/constant dummy-coded variable for condition is explicitly added to the model, the variable adds a significant contribution to the prediction of test performance, with the variable condition yielding better performance than the constant conditions. However, if the instance-based generalization model is modified to assume that the training groups can differ in the steepness of their generalization gradient, by incorporating a separate generalization parameter for each group, then the instance-based model can account for our experimental results without explicitly taking training group into account. Henceforth this model will be referred to as the Instance-based Generalization with Adaptive Similarity (IGAS) model.</p>
</section></section><section id="general-discussion" class="level1" data-number="11"><h1 data-number="11">
<span class="header-section-number">11</span> General Discussion</h1>
<p>Across two experiments, we found evidence in support of the benefits of variability hypothesis in a simple, computerized projectile throwing task. Generalization was observed in both constant and varied participants, in that both groups tended to perform better at novel positions in the testing phase than did participants who started with those positions in the training phase. However, varied trained participants consistently performed better than constant trained participants, in terms of both the testing phase in general, and in a comparison that only included untrained positions. We also found some evidence for the less commonly observed pattern wherein varied-trained participants outperform constant-trained participants even from conditions identical to the constant group training <span class="citation" data-cites="goodeSuperiorityVariableRepeated2008 greenPracticeVariabilityTransfer1995a kerrSpecificVariedPractice1978">(<a href="#ref-goodeSuperiorityVariableRepeated2008" role="doc-biblioref">Goode et al., 2008</a>; <a href="#ref-greenPracticeVariabilityTransfer1995a" role="doc-biblioref">Green et al., 1995</a>; <a href="#ref-kerrSpecificVariedPractice1978" role="doc-biblioref">Kerr &amp; Booth, 1978</a>)</span>. In experiment 1 varied participants performed significantly better on this identity comparison. In Experiment 2, the comparison was not significant initially, but became significant after controlling for the similarity measure that incorporates only a single value for the steepness of similarity-based generalization (c). Furthermore, we showed that the general pattern of results from Experiment 2 could be parsimoniously accommodated by an instance-based similarity model, but only with the assumption that constant and varied participants generalize their training experience to different degrees. Our results thus suggest that the benefits of variation cannot be explained by the varied-trained participants simply covering a broader range of the task space. Rather, the modeling suggests that varied participants also learn to adaptively tune their generalization function such that throwing locations generalize more broadly to one another than they do in the constant condition. A learning system could end up adopting a higher c value in the constant than variable training conditions by monitoring the trial-by-trial variability of the training items. The c parameter would be adapted downwards when adjacent training items are dissimilar to each other and adapted upwards when adjacent training items are the same. In this fashion, contextually appropriate c values could be empirically learned. This learning procedure would capture the insight that if a situation has a high amount variability, then the learner should be predisposed toward thinking that subsequent test items will also show considerable variability, in which case generalization gradients should be broad, as is achieved by low values for c.</p>
<p>Also of interest is whether the IGAS model can predict the pattern of results wherein the varied condition outperforms the constant condition even from the position on which the constant condition trained. Although our models were fit using all of the Experiment 2 training and testing data, not just that of the identity comparisons, in Figure 9 we demonstrate how a simplified version of the IGAS model could in principle produce such a pattern. In addition to the assumption of differential generalization between varied and constant conditions, our simplified model makes explicit an assumption that is incorporated into the full IGAS model – namely that even when being tested from a position identical to that which was trained, there are always some psychological contextual differences between training and testing throws, resulting in a non-zero dissimilarity.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode css code-with-copy"><code class="sourceCode css"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>caption<span class="op">,</span> <span class="fu">.caption</span>{</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">font-style</span>:<span class="dv">italic</span><span class="op">;</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">margin-top</span>:<span class="dv">0.5</span><span class="dt">em</span><span class="op">;</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">margin-bottom</span>:<span class="dv">0.5</span><span class="dt">em</span><span class="op">;</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">width</span>:<span class="dv">100</span><span class="dt">%</span><span class="op">;</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">text-align</span>: <span class="dv">left</span><span class="op">;</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># </span></span>
<span></span>
<span><span class="va">p</span><span class="op">=</span><span class="fl">2</span></span>
<span><span class="va">c</span><span class="op">&lt;-</span> <span class="fl">.000002</span></span>
<span></span>
<span><span class="va">trainingTestingDifference</span><span class="op">=</span><span class="fl">2000</span>;</span>
<span><span class="va">cvaried</span><span class="op">=</span><span class="fl">.00002</span></span>
<span><span class="va">cconstant</span><span class="op">=</span><span class="fl">.0005</span></span>
<span><span class="va">simdat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">200</span>,<span class="fl">1000</span><span class="op">)</span>,<span class="fl">3</span><span class="op">)</span>,condit<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"varied"</span>,<span class="fl">1602</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"constant"</span>,<span class="fl">801</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                     train.position<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">400</span>,<span class="fl">801</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">800</span>,<span class="fl">801</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">600</span>,<span class="fl">801</span><span class="op">)</span><span class="op">)</span>,c<span class="op">=</span><span class="fl">.0002</span>,p<span class="op">=</span><span class="fl">2</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>                     <span class="fu">mutate</span><span class="op">(</span>c2<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">condit</span><span class="op">==</span><span class="st">"varied"</span>,<span class="va">cvaried</span>,<span class="va">cconstant</span><span class="op">)</span>,</span>
<span>                            genGauss<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">c</span><span class="op">*</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span><span class="op">-</span><span class="va">train.position</span><span class="op">)</span><span class="op">^</span><span class="va">p</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                            genGaussDist<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">c</span><span class="op">*</span><span class="op">(</span><span class="va">trainingTestingDifference</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span><span class="op">-</span><span class="va">train.position</span><span class="op">)</span><span class="op">^</span><span class="va">p</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                            genGauss2<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">c2</span><span class="op">*</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span><span class="op">-</span><span class="va">train.position</span><span class="op">)</span><span class="op">^</span><span class="va">p</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                            genGaussDist2<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">c2</span><span class="op">*</span><span class="op">(</span><span class="va">trainingTestingDifference</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span><span class="op">-</span><span class="va">train.position</span><span class="op">)</span><span class="op">^</span><span class="va">p</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                            <span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">x</span>,<span class="va">condit</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">summarise</span><span class="op">(</span>genGauss<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">genGauss</span><span class="op">)</span>,genGauss2<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">genGauss2</span><span class="op">)</span>,genGaussDist<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">genGaussDist</span><span class="op">)</span>,genGaussDist2<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">genGaussDist2</span><span class="op">)</span>,.groups<span class="op">=</span><span class="st">'keep'</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co">#plot(x,exp(c*(trainingTestingDifference+abs(x-800)))+exp(c*(trainingTestingDifference+abs(x-400)))</span></span>
<span></span>
<span><span class="va">colorVec</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"darkblue"</span>,<span class="st">"darkred"</span><span class="op">)</span></span>
<span><span class="va">plotSpecs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu">geom_line</span><span class="op">(</span>alpha<span class="op">=</span><span class="fl">.7</span><span class="op">)</span>,<span class="fu">scale_color_manual</span><span class="op">(</span>values<span class="op">=</span><span class="va">colorVec</span><span class="op">)</span>,</span>
<span>                  <span class="fu">geom_vline</span><span class="op">(</span>alpha<span class="op">=</span><span class="fl">.55</span>,xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">400</span>,<span class="fl">800</span><span class="op">)</span>,color<span class="op">=</span><span class="va">colorVec</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,</span>
<span>                  <span class="fu">geom_vline</span><span class="op">(</span>alpha<span class="op">=</span><span class="fl">.55</span>,xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">600</span><span class="op">)</span>,color<span class="op">=</span><span class="va">colorVec</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>                  <span class="fu">ylim</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1.05</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                  <span class="co">#xlim(c(250,950)),</span></span>
<span>                  <span class="fu">scale_x_continuous</span><span class="op">(</span>breaks<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">200</span>,<span class="fl">1000</span>,by<span class="op">=</span><span class="fl">200</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                  <span class="fu">xlab</span><span class="op">(</span><span class="st">"Test Stimulus"</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">455</span>,y<span class="op">=</span><span class="fl">1.05</span>,label<span class="op">=</span><span class="st">"Varied"</span>,size<span class="op">=</span><span class="fl">3.1</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">455</span>,y<span class="op">=</span><span class="fl">1.01</span>,label<span class="op">=</span><span class="st">"Training"</span>,size<span class="op">=</span><span class="fl">3.1</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">662</span>,y<span class="op">=</span><span class="fl">1.05</span>,label<span class="op">=</span><span class="st">"Constant"</span>,size<span class="op">=</span><span class="fl">3.1</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">657</span>,y<span class="op">=</span><span class="fl">1.01</span>,label<span class="op">=</span><span class="st">"Training"</span>,size<span class="op">=</span><span class="fl">3.1</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">855</span>,y<span class="op">=</span><span class="fl">1.05</span>,label<span class="op">=</span><span class="st">"Varied"</span>,size<span class="op">=</span><span class="fl">3.1</span><span class="op">)</span>,</span>
<span>                  <span class="fu">annotate</span><span class="op">(</span>geom<span class="op">=</span><span class="st">"text"</span>,x<span class="op">=</span><span class="fl">855</span>,y<span class="op">=</span><span class="fl">1.01</span>,label<span class="op">=</span><span class="st">"Training"</span>,size<span class="op">=</span><span class="fl">3.1</span><span class="op">)</span>,</span>
<span>                  <span class="fu">theme</span><span class="op">(</span>panel.border <span class="op">=</span> <span class="fu">element_rect</span><span class="op">(</span>colour <span class="op">=</span> <span class="st">"black"</span>, fill<span class="op">=</span><span class="cn">NA</span>, size<span class="op">=</span><span class="fl">1</span><span class="op">)</span>,</span>
<span>                        legend.position<span class="op">=</span><span class="st">"none"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ip1</span> <span class="op">&lt;-</span> <span class="va">simdat</span>  <span class="op">%&gt;%</span> <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">x</span>,y<span class="op">=</span><span class="va">genGauss</span>,group<span class="op">=</span><span class="va">condit</span>,col<span class="op">=</span><span class="va">condit</span><span class="op">)</span><span class="op">)</span><span class="op">+</span><span class="va">plotSpecs</span><span class="op">+</span><span class="fu">ylab</span><span class="op">(</span><span class="st">"Amount of Generalization"</span><span class="op">)</span><span class="op">+</span><span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Identical context, 1c"</span><span class="op">)</span></span>
<span><span class="va">ip2</span> <span class="op">&lt;-</span> <span class="va">simdat</span> <span class="op">%&gt;%</span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">x</span>,y<span class="op">=</span><span class="va">genGauss2</span>,group<span class="op">=</span><span class="va">condit</span>,col<span class="op">=</span><span class="va">condit</span><span class="op">)</span><span class="op">)</span><span class="op">+</span><span class="va">plotSpecs</span><span class="op">+</span><span class="fu">ylab</span><span class="op">(</span><span class="st">""</span><span class="op">)</span><span class="op">+</span><span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Identical context, 2c"</span><span class="op">)</span></span>
<span><span class="va">ip3</span> <span class="op">&lt;-</span> <span class="va">simdat</span>  <span class="op">%&gt;%</span> <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">x</span>,y<span class="op">=</span><span class="va">genGaussDist</span>,group<span class="op">=</span><span class="va">condit</span>,col<span class="op">=</span><span class="va">condit</span><span class="op">)</span><span class="op">)</span><span class="op">+</span><span class="va">plotSpecs</span><span class="op">+</span><span class="fu">ylab</span><span class="op">(</span><span class="st">"Amount of Generalization"</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Added distance due to context context, 1c"</span><span class="op">)</span><span class="op">+</span><span class="fu">theme</span><span class="op">(</span>plot.margin <span class="op">=</span> <span class="fu">margin</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">ip4</span> <span class="op">&lt;-</span> <span class="va">simdat</span> <span class="op">%&gt;%</span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">x</span>,y<span class="op">=</span><span class="va">genGaussDist2</span>,group<span class="op">=</span><span class="va">condit</span>,col<span class="op">=</span><span class="va">condit</span><span class="op">)</span><span class="op">)</span><span class="op">+</span><span class="va">plotSpecs</span><span class="op">+</span><span class="fu">ylab</span><span class="op">(</span><span class="st">""</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Added distance due to context context, 2c"</span><span class="op">)</span><span class="op">+</span><span class="fu">theme</span><span class="op">(</span>plot.margin <span class="op">=</span> <span class="fu">margin</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># gridExtra::grid.arrange(ip1,ip2,ip3,ip4,ncol=2)</span></span>
<span></span>
<span><span class="va">gtitle</span><span class="op">=</span><span class="st">"Figure 9."</span></span>
<span><span class="va">title</span> <span class="op">=</span> <span class="fu">ggdraw</span><span class="op">(</span><span class="op">)</span><span class="op">+</span><span class="fu">draw_label</span><span class="op">(</span><span class="va">gtitle</span>,fontface <span class="op">=</span> <span class="st">'bold'</span>,x<span class="op">=</span><span class="fl">0</span>,hjust<span class="op">=</span><span class="fl">0</span>,size<span class="op">=</span><span class="fl">11</span><span class="op">)</span><span class="op">+</span><span class="fu">theme</span><span class="op">(</span>plot.margin <span class="op">=</span> <span class="fu">margin</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">plot_grid</span><span class="op">(</span><span class="va">title</span>,<span class="cn">NULL</span>,<span class="va">ip1</span>,<span class="va">ip2</span>,<span class="va">ip3</span>,<span class="va">ip4</span>,ncol<span class="op">=</span><span class="fl">2</span>,rel_heights<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.1</span>,<span class="fl">.8</span>,<span class="fl">.8</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>As mentioned above, the idea that learners flexibly adjust their generalization gradient based on prior experience does have precedent in the domains of category learning <span class="citation" data-cites="ahaConceptLearningFlexible1992 briscoeConceptualComplexityBias2011 hahnEffectsCategoryDiversity2005 lambertsFlexibleTuningSimilarity1994 opdebeeckRepresentationPerceivedShape2008">(<a href="#ref-ahaConceptLearningFlexible1992" role="doc-biblioref">Aha &amp; Goldstone, 1992</a>; <a href="#ref-briscoeConceptualComplexityBias2011" role="doc-biblioref">Briscoe &amp; Feldman, 2011</a>; <a href="#ref-hahnEffectsCategoryDiversity2005" role="doc-biblioref">Hahn et al., 2005</a>; <a href="#ref-lambertsFlexibleTuningSimilarity1994" role="doc-biblioref">Lamberts, 1994</a>; <a href="#ref-opdebeeckRepresentationPerceivedShape2008" role="doc-biblioref">Op de Beeck et al., 2008</a>)</span>, and sensorimotor adaptation <span class="citation" data-cites="marongelliAdvantageFlexibleNeuronal2013 taylorContextdependentGeneralization2013 thoroughmanRapidReshapingHuman2005">(<a href="#ref-marongelliAdvantageFlexibleNeuronal2013" role="doc-biblioref">Marongelli &amp; Thoroughman, 2013</a>; <a href="#ref-taylorContextdependentGeneralization2013" role="doc-biblioref">Taylor &amp; Ivry, 2013</a>; <a href="#ref-thoroughmanRapidReshapingHuman2005" role="doc-biblioref">Thoroughman &amp; Taylor, 2005</a>)</span>. <span class="citation" data-cites="lambertsFlexibleTuningSimilarity1994">Lamberts (<a href="#ref-lambertsFlexibleTuningSimilarity1994" role="doc-biblioref">1994</a>)</span> showed that a simple manipulation of background knowledge during a categorization test resulted in participants generalizing their training experience more or less broadly, and moreover that such a pattern could be captured by allowing the generalization parameter of an instance-based similarity model to be fit separately between conditions. The flexible generalization parameter has also successfully accounted for generalization behavior in cases where participants have been trained on categories that differ in their relative variability <span class="citation" data-cites="hahnEffectsCategoryDiversity2005 sakamotoTrackingVariabilityLearning2006">(<a href="#ref-hahnEffectsCategoryDiversity2005" role="doc-biblioref">Hahn et al., 2005</a>; <a href="#ref-sakamotoTrackingVariabilityLearning2006" role="doc-biblioref">Sakamoto et al., 2006</a>)</span>. However, to the best of our knowledge, IGAS is the first instance-based similarity model that has been put forward to account for the effect of varied training in a visuomotor skill task. Although IGAS was inspired by work in the domain of category learning, its success in a distinct domain may not be surprising in light of the numerous prior observations that at least certain aspects of learning and generalization may operate under common principles across different tasks and domains <span class="citation" data-cites="censorCommonMechanismsHuman2012 hillsCentralExecutiveSearch2010 jamiesonInstanceTheoryDomaingeneral2022 lawSharedMechanismsPerceptual2010 roarkComparingPerceptualCategory2021 rosenbaumAcquisitionIntellectualPerceptualMotor2001a vigoLearningDifficultyVisual2018 wallIdentifyingRelationshipsCognitive2021 wuSimilaritiesDifferencesSpatial2020 yangGeneralLearningAbility2020">(<a href="#ref-censorCommonMechanismsHuman2012" role="doc-biblioref">Censor et al., 2012</a>; <a href="#ref-hillsCentralExecutiveSearch2010" role="doc-biblioref">Hills et al., 2010</a>; <a href="#ref-jamiesonInstanceTheoryDomaingeneral2022" role="doc-biblioref">Jamieson et al., 2022</a>; <a href="#ref-lawSharedMechanismsPerceptual2010" role="doc-biblioref">Law &amp; Gold, 2010</a>; <a href="#ref-roarkComparingPerceptualCategory2021" role="doc-biblioref">Roark et al., 2021</a>; <a href="#ref-rosenbaumAcquisitionIntellectualPerceptualMotor2001a" role="doc-biblioref">Rosenbaum et al., 2001</a>; <a href="#ref-vigoLearningDifficultyVisual2018" role="doc-biblioref">Vigo et al., 2018</a>; <a href="#ref-wallIdentifyingRelationshipsCognitive2021" role="doc-biblioref">Wall et al., 2021</a>; <a href="#ref-wuSimilaritiesDifferencesSpatial2020" role="doc-biblioref">Wu et al., 2020</a>; <a href="#ref-yangGeneralLearningAbility2020" role="doc-biblioref">Yang et al., 2020</a>)</span>.</p>
<p>Our modelling approach does differ from category learning implementations of instance-based models in several ways. One such difference is the nature of the training instances that are assumed to be stored. In category learning studies, instances are represented as points in a multidimensional space of all of the attributes that define a category item (e.g.&nbsp;size/color/shape). Rather than defining instances in terms of what stimuli learners experience, our approach assumes that stored, motor instances reflect how they act, in terms of the velocity applied to the ball on each throw. An advantage of many motor learning tasks is the relative ease with which task execution variables can be directly measured (e.g.&nbsp;movement force, velocity, angle, posture) in addition to the decision and response time measures that typically exhaust the data generated from more classical cognitive tasks. Of course, whether learners actually are storing each individual motor instance is a fundamental question beyond the scope of the current work – though as described in the introduction there is some evidence in support of this idea <span class="citation" data-cites="chamberlinNoteSchemaExemplar1992 crumpEpisodicContributionsSequential2010 hommelEventFilesEvidence1998 meighWhatMemoryRepresentation2018 poldrackRelationshipSkillLearning1999">(<a href="#ref-chamberlinNoteSchemaExemplar1992" role="doc-biblioref">Chamberlin &amp; Magill, 1992a</a>; <a href="#ref-crumpEpisodicContributionsSequential2010" role="doc-biblioref">Crump &amp; Logan, 2010</a>; <a href="#ref-hommelEventFilesEvidence1998" role="doc-biblioref">Hommel, 1998</a>; <a href="#ref-meighWhatMemoryRepresentation2018" role="doc-biblioref">Meigh et al., 2018</a>; <a href="#ref-poldrackRelationshipSkillLearning1999" role="doc-biblioref">Poldrack et al., 1999</a>)</span>. A particularly noteworthy instance-based model of sensory-motor behavior is the Knowledge II model of Rosenbaum and colleagues <span class="citation" data-cites="cohenWhereGraspsAre2004 rosenbaumPlanningReachesEvaluating1995">(<a href="#ref-cohenWhereGraspsAre2004" role="doc-biblioref">Cohen &amp; Rosenbaum, 2004</a>; <a href="#ref-rosenbaumPlanningReachesEvaluating1995" role="doc-biblioref">Rosenbaum et al., 1995</a>)</span>. Knowledge II explicitly defines instances as postures (joint combinations), and is thus far more detailed than IGAS in regards to the contents of stored instances. Knowledge II also differs from IGAS in that learning is accounted for by both the retrieval of stored postures, and the generation of novel postures via the modification of retrieved postures. A promising avenue for future research would be to combine the adaptive similarity mechanism of IGAS with the novel instance generation mechanisms of Knowledge II.</p>
<p>Our findings also have some conceptual overlap with an earlier study on the effects of varied training in a coincident timing task <span class="citation" data-cites="catalanoDistantTransferCoincident1984a">(<a href="#ref-catalanoDistantTransferCoincident1984a" role="doc-biblioref">Catalano &amp; Kleiner, 1984</a>)</span>. In this task, participants observe a series of lamps lighting up consecutively, and attempt to time a button press with the onset of the final lamp. The design consisted of four separate constant groups, each training from a single lighting velocity, and a single varied group training with all four of the lighting velocities used by the individual constant groups. Participants were then split into four separate testing conditions, each of which were tested from a single novel lighting velocity of varying distance from the training conditions. The result of primary interest was that all participants performed worse as the distance between training and testing velocity increased – a typical generalization decrement. However, varied participants showed less of a decrement than did constant participants. The authors take this result as evidence that varied training results in a less-steep generalization gradient than does constant training. Although the experimental conclusions of Catalano and Kleiner are similar to our own, our work is novel in that we account for our results with a cognitive model, and without assuming the formation of a schema. Additionally, the way in which Catalano and Kleiner collapse their separate constant groups together may result in similarity confounds between varied and constant conditions that leaves their study open to methodological criticisms, especially in light of related work which demonstrated that the extent to which varied training may be beneficial can depend on whether the constant group they are compared against trained from similar conditions to those later tested <span class="citation" data-cites="wrisbergVariabilityPracticeHypothesis1987">(<a href="#ref-wrisbergVariabilityPracticeHypothesis1987" role="doc-biblioref">Wrisberg et al., 1987</a>)</span>. Our study alleviates such concerns by explicitly controlling for similarity.</p>
<section id="limitations" class="level2" data-number="11.1"><h2 data-number="11.1" class="anchored" data-anchor-id="limitations">
<span class="header-section-number">11.1</span> Limitations</h2>
<p>A limitation of this study concerns the ordering of the testing/transfer trials at the conclusion of both experiments. Participants were tested from each separate position (4 in Experiment 1, 6 in Experiment 2) in a random, intermixed order. Because the varied group was trained from two positions that were also randomly ordered, they may have benefited from experience with this type of sequencing, whereas the constant groups had no experience with switching between positions trial to trial. This concern is somewhat ameliorated by the fact that the testing phase performance of the constant groups from their trained position was not significantly worse than their level of performance at the end of the training phase, suggesting that they were not harmed by random ordering of positions during testing. It should also be noted that the computerized task utilized in the present work is relatively simple compared to many of the real-world tasks utilized in prior research. It is thus conceivable that the effect of variability in more complex tasks is distinct from the process put forward in the present work. An important challenge for future work will be to assess the extent to which IGAS can account for generalization in relatively complex tasks with far more degrees of freedom.</p>
<p>It is common for psychological process models of categorization learning to use an approach such as multidimensional scaling so as to transform the stimuli from the physical dimensions used in the particular task into the psychological dimensions more reflective of the actual human representations <span class="citation" data-cites="nosofskySimilarityScalingCognitive1992 shepardUniversalLawGeneralization1987">(<a href="#ref-nosofskySimilarityScalingCognitive1992" role="doc-biblioref">Nosofsky, 1992</a>; <a href="#ref-shepardUniversalLawGeneralization1987" role="doc-biblioref">Shepard, 1987</a>)</span>. Such scaling typically entails having participants rate the similarity between individual items and using these similarity judgements to then compute the psychological distances between stimuli, which can then be fed into a subsequent model. In the present investigation, there was no such way to scale the x and y velocity components in terms of the psychological similarity, and thus our modelling does rely on the assumption that the psychological distances between the different throwing positions are proportional to absolute distances in the metric space of the task (e.g. the relative distance between positions 400 and 500 is equivalent to that between 800 and 900). However, an advantage of our approach is that we are measuring similarity in terms of how participants behave (applying a velocity to the ball), rather than the metric features of the task stimuli.</p>
</section><section id="conclusion" class="level2" data-number="11.2"><h2 data-number="11.2" class="anchored" data-anchor-id="conclusion">
<span class="header-section-number">11.2</span> Conclusion</h2>
<p>Our experiments demonstrate a reliable benefit of varied training in a simple projectile launching task. Such results were accounted for by an instance-based model that assumes that varied training results in the computation of a broader similarity-based generalization gradient. Instance-based models augmented with this assumption may be a valuable approach towards better understanding skill generalization and transfer.</p>
</section><section id="references" class="level2" data-number="11.3"><h2 data-number="11.3" class="anchored" data-anchor-id="references">
<span class="header-section-number">11.3</span> References</h2>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-ahaConceptLearningFlexible1992" class="csl-entry" role="listitem">
Aha, D. W., &amp; Goldstone, R. L. (1992). Concept <span>Learning</span> and <span>Flexible Weighting</span>. <em>In <span>Proceedings</span> of the <span>Fourteenth Annual Conference</span> of the <span>Cognitive Science Society</span></em>, 534–539.
</div>
<div id="ref-barnettWhenWhereWe2002" class="csl-entry" role="listitem">
Barnett, S. M., &amp; Ceci, S. J. (2002). When and where do we apply what we learn?: <span>A</span> taxonomy for far transfer. <em>Psychological Bulletin</em>, <em>128</em>(4), 612–637. <a href="https://doi.org/10.1037//0033-2909.128.4.612">https://doi.org/10.1037//0033-2909.128.4.612</a>
</div>
<div id="ref-bernikerEffectsTrainingBreadth2014" class="csl-entry" role="listitem">
Berniker, M., Mirzaei, H., &amp; Kording, K. P. (2014). The effects of training breadth on motor generalization. <em>Journal of Neurophysiology</em>, <em>112</em>(11), 2791–2798. <a href="https://doi.org/10.1152/jn.00615.2013">https://doi.org/10.1152/jn.00615.2013</a>
</div>
<div id="ref-braithwaiteEffectsVariationPrior2015" class="csl-entry" role="listitem">
Braithwaite, D. W., &amp; Goldstone, R. L. (2015). Effects of <span>Variation</span> and <span>Prior Knowledge</span> on <span>Abstract Concept Learning</span>. <em>Cognition and Instruction</em>, <em>33</em>(3), 226–256. <a href="https://doi.org/10.1080/07370008.2015.1067215">https://doi.org/10.1080/07370008.2015.1067215</a>
</div>
<div id="ref-braunMotorTaskVariation2009" class="csl-entry" role="listitem">
Braun, D. A., Aertsen, A., Wolpert, D. M., &amp; Mehring, C. (2009). Motor <span>Task Variation Induces Structural Learning</span>. <em>Current Biology</em>, <em>19</em>(4), 352–357. <a href="https://doi.org/10.1016/j.cub.2009.01.036">https://doi.org/10.1016/j.cub.2009.01.036</a>
</div>
<div id="ref-briscoeConceptualComplexityBias2011" class="csl-entry" role="listitem">
Briscoe, E., &amp; Feldman, J. (2011). Conceptual complexity and the bias/variance tradeoff. <em>Cognition</em>, <em>118</em>(1), 2–16. <a href="https://doi.org/10.1016/j.cognition.2010.10.004">https://doi.org/10.1016/j.cognition.2010.10.004</a>
</div>
<div id="ref-catalanoDistantTransferCoincident1984a" class="csl-entry" role="listitem">
Catalano, J. F., &amp; Kleiner, B. M. (1984). Distant <span>Transfer</span> in <span>Coincident Timing</span> as a <span>Function</span> of <span>Variability</span> of <span>Practice</span>. <em>Perceptual and Motor Skills</em>, <em>58</em>(3), 851–856. <a href="https://doi.org/10.2466/pms.1984.58.3.851">https://doi.org/10.2466/pms.1984.58.3.851</a>
</div>
<div id="ref-censorCommonMechanismsHuman2012" class="csl-entry" role="listitem">
Censor, N., Sagi, D., &amp; Cohen, L. G. (2012). Common mechanisms of human perceptual and motor learning. <em>Nature Reviews Neuroscience</em>, <em>13</em>(9), 658–664. <a href="https://doi.org/10.1038/nrn3315">https://doi.org/10.1038/nrn3315</a>
</div>
<div id="ref-chamberlinNoteSchemaExemplar1992" class="csl-entry" role="listitem">
Chamberlin, C. J., &amp; Magill, R. A. (1992a). A <span>Note</span> on <span>Schema</span> and <span>Exemplar Approaches</span> to <span>Motor Skill Representation</span> in <span>Memory</span>. <em>Journal of Motor Behavior</em>, <em>24</em>(2), 221–224. <a href="https://doi.org/10.1080/00222895.1992.9941617">https://doi.org/10.1080/00222895.1992.9941617</a>
</div>
<div id="ref-chamberlinMemoryRepresentationMotor1992" class="csl-entry" role="listitem">
Chamberlin, C. J., &amp; Magill, R. A. (1992b). The <span>Memory Representation</span> of <span>Motor Skills</span>: <span>A Test</span> of <span>Schema Theory</span>. <em>Journal of Motor Behavior</em>, <em>24</em>(4), 309–319. <a href="https://doi.org/10.1080/00222895.1992.9941627">https://doi.org/10.1080/00222895.1992.9941627</a>
</div>
<div id="ref-chuaPracticeVariabilityPromotes2019" class="csl-entry" role="listitem">
Chua, L.-K., Dimapilis, M. K., Iwatsuki, T., Abdollahipour, R., Lewthwaite, R., &amp; Wulf, G. (2019). Practice variability promotes an external focus of attention and enhances motor skill learning. <em>Human Movement Science</em>, <em>64</em>, 307–319. <a href="https://doi.org/10.1016/j.humov.2019.02.015">https://doi.org/10.1016/j.humov.2019.02.015</a>
</div>
<div id="ref-cochraneTEfitsNonlinearRegression2020" class="csl-entry" role="listitem">
Cochrane, A. (2020). <span>TEfits</span>: <span>Nonlinear</span> regression for time-evolving indices. <em>Journal of Open Source Software</em>, <em>5</em>(52), 2535. <a href="https://doi.org/10.21105/joss.02535">https://doi.org/10.21105/joss.02535</a>
</div>
<div id="ref-cohenWhereGraspsAre2004" class="csl-entry" role="listitem">
Cohen, R. G., &amp; Rosenbaum, D. A. (2004). Where grasps are made reveals how grasps are planned: Generation and recall of motor plans. <em>Experimental Brain Research</em>, <em>157</em>(4). <a href="https://doi.org/10.1007/s00221-004-1862-9">https://doi.org/10.1007/s00221-004-1862-9</a>
</div>
<div id="ref-crumpEpisodicContributionsSequential2010" class="csl-entry" role="listitem">
Crump, M. J. C., &amp; Logan, G. D. (2010). Episodic contributions to sequential control: <span>Learning</span> from a typist’s touch. <em>Journal of Experimental Psychology: Human Perception and Performance</em>, <em>36</em>(3), 662–672. <a href="https://doi.org/10.1037/a0018390">https://doi.org/10.1037/a0018390</a>
</div>
<div id="ref-czyzVariabilityPracticeInformation2021" class="csl-entry" role="listitem">
Czyż, S. H. (2021). Variability of <span>Practice</span>, <span>Information Processing</span>, and <span>Decision Making</span>? <em>Frontiers in Psychology</em>, <em>12</em>. <a href="https://doi.org/10.3389/fpsyg.2021.639131">https://doi.org/10.3389/fpsyg.2021.639131</a>
</div>
<div id="ref-deloshExtrapolationSineQua1997" class="csl-entry" role="listitem">
DeLosh, E. L., McDaniel, M. A., &amp; Busemeyer, J. R. (1997). Extrapolation: <span>The Sine Qua Non</span> for <span>Abstraction</span> in <span>Function Learning</span>. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, 19.
</div>
<div id="ref-dettermanCaseProsecutionTransfer1993" class="csl-entry" role="listitem">
Detterman, D. K. (1993). The case for the prosecution: <span>Transfer</span> as an epiphenomenon. In <em>Transfer on trial: <span>Intelligence</span>, cognition, and instruction</em> (pp. 1–24). <span>Ablex Publishing</span>.
</div>
<div id="ref-ennisMultidimensionalStochasticTheory1988" class="csl-entry" role="listitem">
Ennis, D. M., Palen, J. J., &amp; Mullen, K. (1988). A multidimensional stochastic theory of similarity. <em>Journal of Mathematical Psychology</em>, <em>32</em>(4), 449–465. <a href="https://doi.org/10.1016/0022-2496(88)90023-5">https://doi.org/10.1016/0022-2496(88)90023-5</a>
</div>
<div id="ref-estesArrayModelsCategory1986" class="csl-entry" role="listitem">
Estes, W. K. (1986). Array models for category learning. <em>Cognitive Psychology</em>, <em>18</em>(4), 500–549. <a href="https://doi.org/10.1016/0010-0285(86)90008-3">https://doi.org/10.1016/0010-0285(86)90008-3</a>
</div>
<div id="ref-faulStatisticalPowerAnalyses2009" class="csl-entry" role="listitem">
Faul, F., Erdfelder, E., Buchner, A., &amp; Lang, A.-G. (2009). Statistical power analyses using <span>G</span>*<span>Power</span> 3.1: <span>Tests</span> for correlation and regression analyses. <em>Behavior Research Methods</em>, <em>41</em>(4), 1149–1160. <a href="https://doi.org/10.3758/BRM.41.4.1149">https://doi.org/10.3758/BRM.41.4.1149</a>
</div>
<div id="ref-fulvioTaskSpecificResponseStrategy2014" class="csl-entry" role="listitem">
Fulvio, J. M., Green, C. S., &amp; Schrater, P. R. (2014). Task-<span>Specific Response Strategy Selection</span> on the <span>Basis</span> of <span>Recent Training Experience</span>. <em>PLOS Computational Biology</em>, <em>10</em>(1), e1003425. <a href="https://doi.org/10.1371/journal.pcbi.1003425">https://doi.org/10.1371/journal.pcbi.1003425</a>
</div>
<div id="ref-gandolfoMotorLearningField1996a" class="csl-entry" role="listitem">
Gandolfo, F., Mussa-Ivaldi, F. A., &amp; Bizzi, E. (1996). Motor learning by field approximation. <em>Proceedings of the National Academy of Sciences</em>, <em>93</em>(9), 3843–3846. <a href="https://doi.org/10.1073/pnas.93.9.3843">https://doi.org/10.1073/pnas.93.9.3843</a>
</div>
<div id="ref-georgeStimulusVariabilityTask2021" class="csl-entry" role="listitem">
George, N., &amp; Egner, T. (2021). Stimulus variability and task relevance modulate binding-learning. <em>Attention, Perception, &amp; Psychophysics</em>. <a href="https://doi.org/10.3758/s13414-021-02338-6">https://doi.org/10.3758/s13414-021-02338-6</a>
</div>
<div id="ref-ghahramaniGeneralizationLocalRemappings1996" class="csl-entry" role="listitem">
Ghahramani, Z., Wolpert, D. M., &amp; Jordan, M. I. (1996). Generalization to <span>Local Remappings</span> of the <span>Visuomotor Coordinate Transformation</span>. <em>Journal of Neuroscience</em>, <em>16</em>(21), 7085–7096. <a href="https://doi.org/10.1523/JNEUROSCI.16-21-07085.1996">https://doi.org/10.1523/JNEUROSCI.16-21-07085.1996</a>
</div>
<div id="ref-gonzalezDiversityTrainingEnhances2011" class="csl-entry" role="listitem">
Gonzalez, C., &amp; Madhavan, P. (2011). Diversity during training enhances detection of novel stimuli. <em>Journal of Cognitive Psychology</em>, <em>23</em>(3), 342–350. <a href="https://doi.org/10.1080/20445911.2011.507187">https://doi.org/10.1080/20445911.2011.507187</a>
</div>
<div id="ref-goodeSuperiorityVariableRepeated2008" class="csl-entry" role="listitem">
Goode, M. K., Geraci, L., &amp; Roediger, H. L. (2008). Superiority of variable to repeated practice in transfer on anagram solution. <em>Psychonomic Bulletin &amp; Review</em>, <em>15</em>(3), 662–666. <a href="https://doi.org/10.3758/PBR.15.3.662">https://doi.org/10.3758/PBR.15.3.662</a>
</div>
<div id="ref-goodwinEffectDifferentQuantities1998" class="csl-entry" role="listitem">
Goodwin, J. E., Eckerson, J. M., Grimes, C. R., &amp; Gordon, P. M. (1998). Effect of <span>Different Quantities</span> of <span>Variable Practice</span> on <span>Acquisition</span>, <span>Retention</span>, and <span>Transfer</span> of <span>An Applied Motor Skill</span>. <em>Perceptual and Motor Skills</em>, <em>87</em>(1), 147–151. <a href="https://doi.org/10.2466/pms.1998.87.1.147">https://doi.org/10.2466/pms.1998.87.1.147</a>
</div>
<div id="ref-greenPracticeVariabilityTransfer1995a" class="csl-entry" role="listitem">
Green, D. P., Whitehead, J., &amp; Sugden, D. A. (1995). Practice <span>Variability</span> and <span>Transfer</span> of a <span>Racket Skill</span>. <em>Perceptual and Motor Skills</em>, <em>81</em>(3_suppl), 1275–1281. <a href="https://doi.org/10.2466/pms.1995.81.3f.1275">https://doi.org/10.2466/pms.1995.81.3f.1275</a>
</div>
<div id="ref-hahnEffectsCategoryDiversity2005" class="csl-entry" role="listitem">
Hahn, U., Bailey, T. M., &amp; Elvin, L. B. C. (2005). Effects of category diversity on learning, memory, and generalization. <em>Memory &amp; Cognition</em>, <em>33</em>(2), 289–302. <a href="https://doi.org/10.3758/BF03195318">https://doi.org/10.3758/BF03195318</a>
</div>
<div id="ref-hillsCentralExecutiveSearch2010" class="csl-entry" role="listitem">
Hills, T. T., Todd, P. M., &amp; Goldstone, R. L. (2010). The central executive as a search process: <span>Priming</span> exploration and exploitation across domains. <em>Journal of Experimental Psychology: General</em>, <em>139</em>(4), 590–609. <a href="https://doi.org/10.1037/a0020666">https://doi.org/10.1037/a0020666</a>
</div>
<div id="ref-hintzmanMINERVASimulationModel1984" class="csl-entry" role="listitem">
Hintzman, D. L. (1984). <span>MINERVA</span> 2: <span>A</span> simulation model of human memory. <em>Behavior Research Methods, Instruments, &amp; Computers</em>, <em>16</em>(2), 96–101. <a href="https://doi.org/10.3758/BF03202365">https://doi.org/10.3758/BF03202365</a>
</div>
<div id="ref-hommelEventFilesEvidence1998" class="csl-entry" role="listitem">
Hommel, B. (1998). Event <span>Files</span>: <span>Evidence</span> for <span>Automatic Integration</span> of <span>Stimulus-Response Episodes</span>. <em>Visual Cognition</em>, <em>5</em>(1-2), 183–216. <a href="https://doi.org/10.1080/713756773">https://doi.org/10.1080/713756773</a>
</div>
<div id="ref-jamiesonInstanceTheoryDomaingeneral2022" class="csl-entry" role="listitem">
Jamieson, R. K., Johns, B. T., Vokey, J. R., &amp; Jones, M. N. (2022). Instance theory as a domain-general framework for cognitive psychology. <em>Nature Reviews Psychology</em>, <em>1</em>(3), 174–183. <a href="https://doi.org/10.1038/s44159-022-00025-3">https://doi.org/10.1038/s44159-022-00025-3</a>
</div>
<div id="ref-jonesDensityDistinctivenessEarly2020" class="csl-entry" role="listitem">
Jones, S. D., &amp; Brandt, S. (2020). Density and <span>Distinctiveness</span> in <span>Early Word Learning</span>: <span>Evidence From Neural Network Simulations</span>. <em>Cognitive Science</em>, <em>44</em>(1), e12812. <a href="https://doi.org/10.1111/cogs.12812">https://doi.org/10.1111/cogs.12812</a>
</div>
<div id="ref-kelleyLearningAttendEffects2009" class="csl-entry" role="listitem">
Kelley, T. A., &amp; Yantis, S. (2009). Learning to attend: <span>Effects</span> of practice on information selection. <em>Journal of Vision</em>, <em>9</em>(7), 16. <a href="https://doi.org/10.1167/9.7.16">https://doi.org/10.1167/9.7.16</a>
</div>
<div id="ref-kerrSpecificVariedPractice1978" class="csl-entry" role="listitem">
Kerr, R., &amp; Booth, B. (1978). Specific and varied practice of motor skill. <em>Perceptual and Motor Skills</em>, <em>46</em>(2), 395–401.
</div>
<div id="ref-lambertsFlexibleTuningSimilarity1994" class="csl-entry" role="listitem">
Lamberts, K. (1994). Flexible <span>Tuning</span> of <span>Similarity</span> in <span>Exemplar-Based Categorization</span>. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>20</em>(5), 1003–1021.
</div>
<div id="ref-lavanEffectsHighVariability2019" class="csl-entry" role="listitem">
Lavan, N., Knight, S., Hazan, V., &amp; McGettigan, C. (2019). The effects of high variability training on voice identity learning. <em>Cognition</em>, <em>193</em>, 104026. <a href="https://doi.org/10.1016/j.cognition.2019.104026">https://doi.org/10.1016/j.cognition.2019.104026</a>
</div>
<div id="ref-lawSharedMechanismsPerceptual2010" class="csl-entry" role="listitem">
Law, C.-T., &amp; Gold, J. I. (2010). Shared <span>Mechanisms</span> of <span>Perceptual Learning</span> and <span>Decision Making</span>. <em>Topics in Cognitive Science</em>, <em>2</em>(2), 226–238. <a href="https://doi.org/10.1111/j.1756-8765.2009.01044.x">https://doi.org/10.1111/j.1756-8765.2009.01044.x</a>
</div>
<div id="ref-leeEvidentialDiversityIncreases2019" class="csl-entry" role="listitem">
Lee, J. C., Lovibond, P. F., &amp; Hayes, B. K. (2019). Evidential diversity increases generalisation in predictive learning. <em>Quarterly Journal of Experimental Psychology</em>, <em>72</em>(11), 2647–2657. <a href="https://doi.org/10.1177/1747021819857065">https://doi.org/10.1177/1747021819857065</a>
</div>
<div id="ref-loganInstanceTheoryAutomatization1988" class="csl-entry" role="listitem">
Logan, G. D. (1988). Toward an instance theory of automatization. <em>Psychological Review</em>, <em>95</em>(4), 492–527.
</div>
<div id="ref-loganInstanceTheoryAttention2002a" class="csl-entry" role="listitem">
Logan, G. D. (2002). An instance theory of attention and memory. <em>Psychological Review</em>, <em>109</em>(2), 376–400.
</div>
<div id="ref-maddoxStimulusRangeDiscontinuity2011" class="csl-entry" role="listitem">
Maddox, W. T., &amp; Filoteo, J. V. (2011). Stimulus range and discontinuity effects on information-integration category learning and generalization. <em>Attention, Perception, &amp; Psychophysics</em>, <em>73</em>(4), 1279–1295. <a href="https://doi.org/10.3758/s13414-011-0101-2">https://doi.org/10.3758/s13414-011-0101-2</a>
</div>
<div id="ref-marongelliAdvantageFlexibleNeuronal2013" class="csl-entry" role="listitem">
Marongelli, E., &amp; Thoroughman, K. (2013). The advantage of flexible neuronal tunings in neural network models for motor learning. <em>Frontiers in Computational Neuroscience</em>, <em>7</em>, 100. <a href="https://doi.org/10.3389/fncom.2013.00100">https://doi.org/10.3389/fncom.2013.00100</a>
</div>
<div id="ref-mccrackenTestSchemaTheory1977" class="csl-entry" role="listitem">
McCracken, H. D., &amp; Stelmach, G. E. (1977). A <span>Test</span> of the <span>Schema Theory</span> of <span>Discrete Motor Learning</span>. <em>Journal of Motor Behavior</em>, <em>9</em>(3), 193–201. <a href="https://doi.org/10.1080/00222895.1977.10735109">https://doi.org/10.1080/00222895.1977.10735109</a>
</div>
<div id="ref-medinContextTheoryClassification1978" class="csl-entry" role="listitem">
Medin, D. L., &amp; Schaffer, M. M. (1978). Context <span>Theory</span> of <span>Classification Learning</span>. <em>Psychological Review</em>, <em>85</em>(3), 207.
</div>
<div id="ref-meighWhatMemoryRepresentation2018" class="csl-entry" role="listitem">
Meigh, K. M., Shaiman, S., Tompkins, C. A., Abbott, K. V., &amp; Nokes-Malach, T. (2018). What memory representation is acquired during nonword speech production learning? <span>The</span> influence of stimulus features and training modality on nonword encoding. <em>Cogent Psychology</em>, <em>5</em>(1), 1493714. <a href="https://doi.org/10.1080/23311908.2018.1493714">https://doi.org/10.1080/23311908.2018.1493714</a>
</div>
<div id="ref-moxleySchemaVariabilityPractice1979" class="csl-entry" role="listitem">
Moxley, S. E. (1979). Schema: <span>The Variability</span> of <span>Practice Hypothesis</span>. <em>Journal of Motor Behavior</em>, <em>11</em>(1), 65–70. <a href="https://doi.org/10.1080/00222895.1979.10735173">https://doi.org/10.1080/00222895.1979.10735173</a>
</div>
<div id="ref-newellSchemaTheory19752003" class="csl-entry" role="listitem">
Newell, K. M. (2003). Schema <span>Theory</span> (1975): <span>Retrospectives</span> and <span>Prospectives</span>. <em>Research Quarterly for Exercise and Sport</em>, <em>74</em>(4), 383–388. <a href="https://doi.org/10.1080/02701367.2003.10609108">https://doi.org/10.1080/02701367.2003.10609108</a>
</div>
<div id="ref-newellVariabilityPracticeTransfer1976" class="csl-entry" role="listitem">
Newell, K. M., &amp; Shapiro, D. C. (1976). Variability of <span>Practice</span> and <span>Transfer</span> of <span>Training</span>: <span>Some Evidence Toward</span> a <span>Schema View</span> of <span>Motor Learning</span>. <em>Journal of Motor Behavior</em>, <em>8</em>(3), 233–243. <a href="https://doi.org/10.1080/00222895.1976.10735077">https://doi.org/10.1080/00222895.1976.10735077</a>
</div>
<div id="ref-northEffectConsistentVaried2019" class="csl-entry" role="listitem">
North, J. S., Bezodis, N. E., Murphy, C. P., Runswick, O. R., Pocock, C., &amp; Roca, A. (2019). The effect of consistent and varied follow-through practice schedules on learning a table tennis backhand. <em>Journal of Sports Sciences</em>, <em>37</em>(6), 613–620. <a href="https://doi.org/10.1080/02640414.2018.1522683">https://doi.org/10.1080/02640414.2018.1522683</a>
</div>
<div id="ref-nosofskyAttentionSimilarityIdentificationcategorization1986" class="csl-entry" role="listitem">
Nosofsky, R. M. (1986). Attention, similarity, and the identification-categorization relationship. <em>Journal of Experimental Psychology: General</em>, <em>115</em>(1), 39–57.
</div>
<div id="ref-nosofskySimilarityScalingCognitive1992" class="csl-entry" role="listitem">
Nosofsky, R. M. (1992). Similarity scaling and cognitive process models. <em>Annual Review of Psychology</em>, <em>43</em>(1), 25–53.
</div>
<div id="ref-nosofskyExemplarbasedAccountsMultiplesystem2000" class="csl-entry" role="listitem">
Nosofsky, R. M., &amp; Johansen, M. K. (2000). Exemplar-based accounts of "multiple-system" phenomena in perceptual categorization. <em>Psychonomic Bulletin &amp; Review</em>, <em>7</em>(3), 375–402.
</div>
<div id="ref-nosofskyModelguidedSearchOptimal2018" class="csl-entry" role="listitem">
Nosofsky, R. M., Sanders, C. A., Zhu, X., &amp; McDaniel, M. A. (2018). Model-guided search for optimal natural-science-category training exemplars: <span>A</span> work in progress. <em>Psychonomic Bulletin &amp; Review</em>, <em>26</em>(1), 48–76. <a href="https://doi.org/10.3758/s13423-018-1508-8">https://doi.org/10.3758/s13423-018-1508-8</a>
</div>
<div id="ref-opdebeeckRepresentationPerceivedShape2008" class="csl-entry" role="listitem">
Op de Beeck, H. P., Wagemans, J., &amp; Vogels, R. (2008). The representation of perceived shape similarity and its role for category learning in monkeys: <span>A</span> modeling study. <em>Vision Research</em>, <em>48</em>(4), 598–610. <a href="https://doi.org/10.1016/j.visres.2007.11.019">https://doi.org/10.1016/j.visres.2007.11.019</a>
</div>
<div id="ref-palmeriExemplarSimilarityDevelopment1997" class="csl-entry" role="listitem">
Palmeri, T. J. (1997). Exemplar <span>Similarity</span> and the <span>Development</span> of <span>Automaticity</span>. <em>Journal of Experimental Psychology: Human Learning and Memory</em>, <em>23</em>(2), 324–354.
</div>
<div id="ref-perryLearnLocallyThink2010" class="csl-entry" role="listitem">
Perry, L. K., Samuelson, L. K., Malloy, L. M., &amp; Schiffer, R. N. (2010). Learn <span>Locally</span>, <span>Think Globally</span>: <span>Exemplar Variability Supports Higher-Order Generalization</span> and <span>Word Learning</span>. <em>Psychological Science</em>, <em>21</em>(12), 1894–1902. <a href="https://doi.org/10.1177/0956797610389189">https://doi.org/10.1177/0956797610389189</a>
</div>
<div id="ref-pigottMotorSchemaStructure1984" class="csl-entry" role="listitem">
Pigott, R. E., &amp; Shapiro, D. C. (1984). Motor <span>Schema</span>: <span>The Structure</span> of the <span>Variability Session</span>. <em>Research Quarterly for Exercise and Sport</em>, <em>55</em>(1), 41–45. <a href="https://doi.org/10.1080/02701367.1984.10605353">https://doi.org/10.1080/02701367.1984.10605353</a>
</div>
<div id="ref-poldrackRelationshipSkillLearning1999" class="csl-entry" role="listitem">
Poldrack, R. A., Selco, S. L., Field, J. E., &amp; Cohen, N. J. (1999). The relationship between skill learning and repetition priming: <span>Experimental</span> and computational analyses. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>25</em>(1), 208–235. <a href="https://doi.org/10.1037/0278-7393.25.1.208">https://doi.org/10.1037/0278-7393.25.1.208</a>
</div>
<div id="ref-posnerGenesisAbstractIdeas1968" class="csl-entry" role="listitem">
Posner, M. I., &amp; Keele, S. W. (1968). On the genesis of abstract ideas. <em>Journal of Experimental Psychology</em>, <em>77</em>(3), 353–363.
</div>
<div id="ref-roarkComparingPerceptualCategory2021" class="csl-entry" role="listitem">
Roark, C. L., Paulon, G., Sarkar, A., &amp; Chandrasekaran, B. (2021). Comparing perceptual category learning across modalities in the same individuals. <em>Psychonomic Bulletin &amp; Review</em>, <em>28</em>(3), 898–909. <a href="https://doi.org/10.3758/s13423-021-01878-0">https://doi.org/10.3758/s13423-021-01878-0</a>
</div>
<div id="ref-rollerVariablePracticeLenses2001" class="csl-entry" role="listitem">
Roller, C. A., Cohen, H. S., Kimball, K. T., &amp; Bloomberg, J. J. (2001). Variable practice with lenses improves visuo-motor plasticity. <em>Cognitive Brain Research</em>, <em>12</em>(2), 341–352. <a href="https://doi.org/10.1016/S0926-6410(01)00077-5">https://doi.org/10.1016/S0926-6410(01)00077-5</a>
</div>
<div id="ref-rosenbaumAcquisitionIntellectualPerceptualMotor2001a" class="csl-entry" role="listitem">
Rosenbaum, D. A., Carlson, R. A., &amp; Gilmore, R. O. (2001). Acquisition of <span>Intellectual</span> and <span>Perceptual-Motor Skills</span>. <em>Annual Review of Psychology</em>, <em>52</em>(1), 453–470. <a href="https://doi.org/10.1146/annurev.psych.52.1.453">https://doi.org/10.1146/annurev.psych.52.1.453</a>
</div>
<div id="ref-rosenbaumPlanningReachesEvaluating1995" class="csl-entry" role="listitem">
Rosenbaum, D. A., Loukopoulos, L. D., Meulenbroek, R. G., Vaughan, J., &amp; Engelbrecht, S. E. (1995). Planning reaches by evaluating stored postures. <em>Psychological Review</em>, <em>102</em>(1), 28.
</div>
<div id="ref-sabahWhenLessMore2019" class="csl-entry" role="listitem">
Sabah, K., Dolk, T., Meiran, N., &amp; Dreisbach, G. (2019). When less is more: Costs and benefits of varied vs. Fixed content and structure in short-term task switching training. <em>Psychological Research</em>, <em>83</em>(7), 1531–1542. <a href="https://doi.org/10.1007/s00426-018-1006-7">https://doi.org/10.1007/s00426-018-1006-7</a>
</div>
<div id="ref-sadakataIndividualAptitudeMandarin2014" class="csl-entry" role="listitem">
Sadakata, M., &amp; McQueen, J. M. (2014). Individual aptitude in <span>Mandarin</span> lexical tone perception predicts effectiveness of high-variability training. <em>Frontiers in Psychology</em>, <em>5</em>, 1318. <a href="https://doi.org/10.3389/fpsyg.2014.01318">https://doi.org/10.3389/fpsyg.2014.01318</a>
</div>
<div id="ref-sakamotoTrackingVariabilityLearning2006" class="csl-entry" role="listitem">
Sakamoto, Y., Love, B. C., &amp; Jones, M. (2006). Tracking <span>Variability</span> in <span>Learning</span>: <span>Contrasting Statistical</span> and <span>Similarity-Based Accounts</span>. <em>Proceedings of the 28th Annual Conference of the Cognitive Science Society. Vancouver, Canada: Cognitive Science Society</em>.
</div>
<div id="ref-schmidtSchemaTheoryDiscrete1975" class="csl-entry" role="listitem">
Schmidt, R. A. (1975). A schema theory of discrete motor skill learning. <em>Psychological Review</em>, <em>82</em>(4), 225–260. <a href="https://doi.org/10.1037/h0076770">https://doi.org/10.1037/h0076770</a>
</div>
<div id="ref-seowTransferEffectsVaried2019" class="csl-entry" role="listitem">
Seow, R. Y. T., Betts, S., &amp; Anderson, J. R. (2019). Transfer effects of varied practice and adaptation to changes in complex skill acquisition. <em>Proceedings of the 17th International Conference on Cognitive Modelling</em>, 222–227.
</div>
<div id="ref-shepardUniversalLawGeneralization1987" class="csl-entry" role="listitem">
Shepard, R. N. (1987). Toward a universal law of generalization for psychological science. <em>Science</em>, <em>237</em>(4820), 1317–1323.
</div>
<div id="ref-sinkeviciuteRoleInputVariability2019" class="csl-entry" role="listitem">
Sinkeviciute, R., Brown, H., Brekelmans, G., &amp; Wonnacott, E. (2019). The role of input variability and learner age in second language vocabulary learning. <em>Studies in Second Language Acquisition</em>, <em>41</em>(04), 795–820. <a href="https://doi.org/10.1017/S0272263119000263">https://doi.org/10.1017/S0272263119000263</a>
</div>
<div id="ref-soderstromLearningPerformanceIntegrative2015" class="csl-entry" role="listitem">
Soderstrom, N. C., &amp; Bjork, R. A. (2015). Learning versus performance: <span>An</span> integrative review. <em>Perspectives on Psychological Science</em>, <em>10</em>(2), 176–199.
</div>
<div id="ref-taylorContextdependentGeneralization2013" class="csl-entry" role="listitem">
Taylor, J., &amp; Ivry, R. (2013). Context-dependent generalization. <em>Frontiers in Human Neuroscience</em>, <em>7</em>, 171. <a href="https://doi.org/10.3389/fnhum.2013.00171">https://doi.org/10.3389/fnhum.2013.00171</a>
</div>
<div id="ref-tenenbaumGeneralizationSimilarityBayesian2001a" class="csl-entry" role="listitem">
Tenenbaum, J. B., &amp; Griffiths, T. L. (2001). Generalization, similarity, and <span>Bayesian</span> inference. <em>Behavioral and Brain Sciences</em>, <em>24</em>(4), 629–640. <a href="https://doi.org/10.1017/S0140525X01000061">https://doi.org/10.1017/S0140525X01000061</a>
</div>
<div id="ref-thoroughmanRapidReshapingHuman2005" class="csl-entry" role="listitem">
Thoroughman, K. A., &amp; Taylor, J. A. (2005). Rapid <span>Reshaping</span> of <span>Human Motor Generalization</span>. <em>Journal of Neuroscience</em>, <em>25</em>(39), 8948–8953. <a href="https://doi.org/10.1523/JNEUROSCI.1771-05.2005">https://doi.org/10.1523/JNEUROSCI.1771-05.2005</a>
</div>
<div id="ref-twomeyAllRightNoises2018" class="csl-entry" role="listitem">
Twomey, K. E., Ma, L., &amp; Westermann, G. (2018). All the <span>Right Noises</span>: <span>Background Variability Helps Early Word Learning</span>. <em>Cognitive Science</em>, <em>42</em>(S2), 413–438. <a href="https://doi.org/10.1111/cogs.12539">https://doi.org/10.1111/cogs.12539</a>
</div>
<div id="ref-vandamMappingShapeVisuomotor2015" class="csl-entry" role="listitem">
van Dam, L. C. J., &amp; Ernst, M. O. (2015). Mapping <span>Shape</span> to <span>Visuomotor Mapping</span>: <span>Learning</span> and <span>Generalisation</span> of <span>Sensorimotor Behaviour Based</span> on <span>Contextual Information</span>. <em>PLOS Computational Biology</em>, <em>11</em>(3), e1004172. <a href="https://doi.org/10.1371/journal.pcbi.1004172">https://doi.org/10.1371/journal.pcbi.1004172</a>
</div>
<div id="ref-vanrossumSchmidtSchemaTheory1990" class="csl-entry" role="listitem">
Van Rossum, J. H. A. (1990). Schmidt’s schema theory: The empirical base of the variability of practice hypothesis. <em>Human Movement Science</em>, <em>9</em>(3-5), 387–435. <a href="https://doi.org/10.1016/0167-9457(90)90010-B">https://doi.org/10.1016/0167-9457(90)90010-B</a>
</div>
<div id="ref-vigoLearningDifficultyVisual2018" class="csl-entry" role="listitem">
Vigo, R., Doan, K.-M. C., Doan, C. A., &amp; Pinegar, S. (2018). On the learning difficulty of visual and auditory modal concepts: <span>Evidence</span> for a single processing system. <em>Cognitive Processing</em>, <em>19</em>(1), 1–16. <a href="https://doi.org/10.1007/s10339-017-0840-7">https://doi.org/10.1007/s10339-017-0840-7</a>
</div>
<div id="ref-wallIdentifyingRelationshipsCognitive2021" class="csl-entry" role="listitem">
Wall, L., Gunawan, D., Brown, S. D., Tran, M.-N., Kohn, R., &amp; Hawkins, G. E. (2021). Identifying relationships between cognitive processes across tasks, contexts, and time. <em>Behavior Research Methods</em>, <em>53</em>(1), 78–95. <a href="https://doi.org/10.3758/s13428-020-01405-4">https://doi.org/10.3758/s13428-020-01405-4</a>
</div>
<div id="ref-wifallReachingResponseSelection2017" class="csl-entry" role="listitem">
Wifall, T., Buss, A. T., Farmer, T. A., Spencer, J. P., &amp; Hazeltine, E. (2017). Reaching into response selection: <span>Stimulus</span> and response similarity influence central operations. <em>Journal of Experimental Psychology: Human Perception and Performance</em>, <em>43</em>(3), 555–568. <a href="https://doi.org/10.1037/xhp0000301">https://doi.org/10.1037/xhp0000301</a>
</div>
<div id="ref-willeyLimitedGeneralizationVaried2018" class="csl-entry" role="listitem">
Willey, C. R., &amp; Liu, Z. (2018a). Limited generalization with varied, as compared to specific, practice in short-term motor learning. <em>Acta Psychologica</em>, <em>182</em>, 39–45. <a href="https://doi.org/10.1016/j.actpsy.2017.11.008">https://doi.org/10.1016/j.actpsy.2017.11.008</a>
</div>
<div id="ref-willeyLongtermMotorLearning2018" class="csl-entry" role="listitem">
Willey, C. R., &amp; Liu, Z. (2018b). Long-term motor learning: <span>Effects</span> of varied and specific practice. <em>Vision Research</em>, <em>152</em>, 10–16. <a href="https://doi.org/10.1016/j.visres.2017.03.012">https://doi.org/10.1016/j.visres.2017.03.012</a>
</div>
<div id="ref-wonnacottInputEffectsAcquisition2012" class="csl-entry" role="listitem">
Wonnacott, E., Boyd, J. K., Thomson, J., &amp; Goldberg, A. E. (2012). Input effects on the acquisition of a novel phrasal construction in 5year olds. <em>Journal of Memory and Language</em>, <em>66</em>(3), 458–478. <a href="https://doi.org/10.1016/j.jml.2011.11.004">https://doi.org/10.1016/j.jml.2011.11.004</a>
</div>
<div id="ref-wrisbergVariabilityPracticeHypothesis1987" class="csl-entry" role="listitem">
Wrisberg, C. A., Winter, T. P., &amp; Kuhlman, J. S. (1987). The <span>Variability</span> of <span>Practice Hypothesis</span>: <span>Further Tests</span> and <span>Methodological Discussion</span>. <em>Research Quarterly for Exercise and Sport</em>, <em>58</em>(4), 369–374. <a href="https://doi.org/10.1080/02701367.1987.10608114">https://doi.org/10.1080/02701367.1987.10608114</a>
</div>
<div id="ref-wuSimilaritiesDifferencesSpatial2020" class="csl-entry" role="listitem">
Wu, C. M., Schulz, E., Garvert, M. M., Meder, B., &amp; Schuck, N. W. (2020). Similarities and differences in spatial and non-spatial cognitive maps. <em>PLOS Computational Biology</em>, <em>16</em>(9). <a href="https://doi.org/10.1101/2020.01.21.914556">https://doi.org/10.1101/2020.01.21.914556</a>
</div>
<div id="ref-wulfEffectTypePractice1991" class="csl-entry" role="listitem">
Wulf, G. (1991). The effect of type of practice on motor learning in children. <em>Applied Cognitive Psychology</em>, <em>5</em>(2), 123–134. <a href="https://doi.org/10.1002/acp.2350050206">https://doi.org/10.1002/acp.2350050206</a>
</div>
<div id="ref-yangGeneralLearningAbility2020" class="csl-entry" role="listitem">
Yang, J., Yan, F.-F., Chen, L., Xi, J., Fan, S., Zhang, P., Lu, Z.-L., &amp; Huang, C.-B. (2020). General learning ability in perceptual learning. <em>Proceedings of the National Academy of Sciences</em>, <em>117</em>(32), 19092–19100. <a href="https://doi.org/10.1073/pnas.2002903117">https://doi.org/10.1073/pnas.2002903117</a>
</div>
<div id="ref-zamanPerceptualVariabilityImplications2021" class="csl-entry" role="listitem">
Zaman, J., Chalkia, A., Zenses, A.-K., Bilgin, A. S., Beckers, T., Vervliet, B., &amp; Boddez, Y. (2021). Perceptual variability: <span>Implications</span> for learning and generalization. <em>Psychonomic Bulletin &amp; Review</em>, <em>28</em>(1), 1–19. <a href="https://doi.org/10.3758/s13423-020-01780-1">https://doi.org/10.3758/s13423-020-01780-1</a>
</div>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./Introduction.html" class="pagination-link  aria-label=">4&nbsp; <span class="chapter-title">Introduction</span>"&gt;
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./HTW.html" class="pagination-link" aria-label="<span class='chapter-number'>6</span>&nbsp; <span class='chapter-title'>HTW Project</span>">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">HTW Project</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb4" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> IGAS Project</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> last-modified</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">#page-layout: full</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="an">code-fold:</span><span class="co"> true</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="an">code-tools:</span><span class="co"> true</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span><span class="co"> </span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">  warning: false</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">  eval: false </span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> </span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">  markdown: </span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">    wrap: 72</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>[Pdf of the journal</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>article](Assets/Gorman_Goldstone_2022_Instance-based_model_varied_practice.pdf){target="_blank"}\</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>[Link to online version of journal</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>article](https://www.sciencedirect.com/science/article/abs/pii/S0010028522000299){target="_blank"}</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="in">```{r echo=FALSE}</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::opts_chunk$set(echo=FALSE)</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="in"># source('build_toc.R')</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="in"># files &lt;- list.files(pattern = '*.Rmd', recursive = F) </span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="in"># files = files[!grepl('^_', basename(files)) | grepl('^_index[.]', basename(files))]</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="in"># t1 &lt;- render_toc("htw_n.Rmd")</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="in"># #cat(t1)</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="in"># </span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="in"># </span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="in"># render_toc("igas_n.Rmd")</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="in">library(thematic)</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="in">thematic_on(bg="#fcfcfc")</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="fu"># Abstract</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>Exposing learners to variability during training has been demonstrated</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>to improve performance in subsequent transfer testing. Such variability</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>benefits are often accounted for by assuming that learners are</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>developing some general task schema or structure. However much of this</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>research has neglected to account for differences in similarity between</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>varied and constant training conditions. In a between-groups</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>manipulation, we trained participants on a simple projectile launching</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>task, with either varied or constant conditions. We replicate previous</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>findings showing a transfer advantage of varied over constant training.</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>Furthermore, we show that a standard similarity model is insufficient to</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>account for the benefits of variation, but, if the model is adjusted to</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>assume that varied learners are tuned towards a broader generalization</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>gradient, then a similarity-based model is sufficient to explain the</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>observed benefits of variation. Our results therefore suggest that some</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>variability benefits can be accommodated within instance-based models</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>without positing the learning of some schemata or structure.</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a><span class="in">```{r load, include=FALSE}</span></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a><span class="in">source('Functions/IGAS_ProcessFunctions.R')</span></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a><span class="in">library(webexercises)</span></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a><span class="in">library(kableExtra)</span></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a><span class="in">library(knitr)</span></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::opts_chunk$set(echo = FALSE)</span></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a><span class="in">#rm(list=ls())</span></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a><span class="in">###### data loading and organization #######</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a><span class="in"># load the processed data from experiment 1 and 2</span></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a><span class="in">e1 &lt;- readRDS("data/igas_e1_cleanedData-final.rds")%&gt;% mutate(initialVelocityX=X_Velocity,initialVelocityY=Y_Velocity,stageInt=as.numeric(as.character(experimentStage)))</span></span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a><span class="in">e2&lt;- readRDS('data/igas_e2_cleanedData-final.rds')%&gt;% mutate(initialVelocityX=X_Velocity,initialVelocityY=Y_Velocity)</span></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a><span class="in"># load subject similarity data - computed with the IGAS model in 'IGAS-SimModel.R'</span></span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a><span class="in">e2_sim &lt;- readRDS('data/IGAS_Similarity-Performance.rds')</span></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a><span class="in">options(contrasts = c("contr.sum", "contr.poly"))</span></span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a><span class="in">defaultContrasts = options()$contrasts</span></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a><span class="in">theme_set(theme_classic())</span></span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a><span class="in">dodge &lt;- position_dodge(width = 0.9)</span></span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a><span class="in">e2GrpPos &lt;- c("400","500","625","675","800","900")</span></span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a><span class="in">e2Grp &lt;- paste("Constant","Constant", "Constant","Constant","Constant","Constant", "Varied")</span></span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a><span class="in">e2Labels &lt;- paste(c("400\n Constant","500\n Constant","625\n Constant","675\n Constant",</span></span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a><span class="in">                   "800\n Constant","900\n Constant","500-800\n Varied"),sep="")</span></span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a><span class="in">e1Pos &lt;- c("610","760","835","910")</span></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a><span class="in">e1Var &lt;- paste("Varied Train Position","Constant Train Position", "Novel Position", "Varied Training Position")</span></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a><span class="in">e1Labels&lt;- paste(c("610\n Varied Trained","760\n Constant Trained","835\n Novel Location","910\n Varied Trained"),sep="")</span></span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction</span></span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a>The past century of research on human learning has produced ample</span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a>evidence that although learners can improve at almost any task, such</span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a>improvements are often specific to the trained task, with unreliable or</span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a>even nonexistent transfer to novel tasks or conditions</span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@barnettWhenWhereWe2002; @dettermanCaseProsecutionTransfer1993</span><span class="co">]</span>. Such</span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a>transfer challenges are of noteworthy practical relevance, given that</span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a>educators, trainers, and rehabilitators typically intend for their</span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a>students to be able to apply what they have learned to new situations.</span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a>It is therefore important to better understand the factors that</span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a>influence transfer, and to develop cognitive models that can predict</span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a>when transfer is likely to occur. The factor of interest to the present</span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>investigation is variation during training. Our experiments add to the</span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a>longstanding empirical investigation of the controversial relationship</span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a>between training variation, and subsequent transfer. We also offer a</span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a>novel explanation for such results in the form of an instance-based</span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a>model that accounts for the benefits of variation in simple terms of</span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a>psychological similarity. We first review the relevant concepts and</span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a>literature.</span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a><span class="fu">## Similarity and instance-based approaches to transfer of learning</span></span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-109"><a href="#cb4-109" aria-hidden="true" tabindex="-1"></a>Notions of similarity have long played a central role in many prominent</span>
<span id="cb4-110"><a href="#cb4-110" aria-hidden="true" tabindex="-1"></a>models of generalization of learning, as well as in the longstanding</span>
<span id="cb4-111"><a href="#cb4-111" aria-hidden="true" tabindex="-1"></a>theoretical issue of whether learners abstract an aggregate, summary</span>
<span id="cb4-112"><a href="#cb4-112" aria-hidden="true" tabindex="-1"></a>representation, or if they simply store individual instances. Early</span>
<span id="cb4-113"><a href="#cb4-113" aria-hidden="true" tabindex="-1"></a>models of learning often assumed that discrete experiences with some</span>
<span id="cb4-114"><a href="#cb4-114" aria-hidden="true" tabindex="-1"></a>task or category were not stored individually in memory, but instead</span>
<span id="cb4-115"><a href="#cb4-115" aria-hidden="true" tabindex="-1"></a>promoted the formation of a summary representation, often referred to as</span>
<span id="cb4-116"><a href="#cb4-116" aria-hidden="true" tabindex="-1"></a>a prototype or schema, and that exposure to novel examples would then</span>
<span id="cb4-117"><a href="#cb4-117" aria-hidden="true" tabindex="-1"></a>prompt the retrieval of whichever preexisting prototype was most similar</span>
<span id="cb4-118"><a href="#cb4-118" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@posnerGenesisAbstractIdeas1968</span><span class="co">]</span>. Prototype</span>
<span id="cb4-119"><a href="#cb4-119" aria-hidden="true" tabindex="-1"></a>models were later challenged by the success of instance-based or</span>
<span id="cb4-120"><a href="#cb4-120" aria-hidden="true" tabindex="-1"></a>exemplar models -- which were shown to provide an account of</span>
<span id="cb4-121"><a href="#cb4-121" aria-hidden="true" tabindex="-1"></a>generalization as good or better than prototype models, with the</span>
<span id="cb4-122"><a href="#cb4-122" aria-hidden="true" tabindex="-1"></a>advantage of not assuming the explicit construction of an internal</span>
<span id="cb4-123"><a href="#cb4-123" aria-hidden="true" tabindex="-1"></a>prototype [@estesArrayModelsCategory1986;</span>
<span id="cb4-124"><a href="#cb4-124" aria-hidden="true" tabindex="-1"></a>@hintzmanMINERVASimulationModel1984;</span>
<span id="cb4-125"><a href="#cb4-125" aria-hidden="true" tabindex="-1"></a>@medinContextTheoryClassification1978;</span>
<span id="cb4-126"><a href="#cb4-126" aria-hidden="true" tabindex="-1"></a>@nosofskyAttentionSimilarityIdentificationcategorization1986 ].</span>
<span id="cb4-127"><a href="#cb4-127" aria-hidden="true" tabindex="-1"></a>Instance-based models assume that learners encode each experience with a</span>
<span id="cb4-128"><a href="#cb4-128" aria-hidden="true" tabindex="-1"></a>task as a separate instance/exemplar/trace, and that each encoded trace</span>
<span id="cb4-129"><a href="#cb4-129" aria-hidden="true" tabindex="-1"></a>is in turn compared against novel stimuli. As the number of stored</span>
<span id="cb4-130"><a href="#cb4-130" aria-hidden="true" tabindex="-1"></a>instances increases, so does the likelihood that some previously stored</span>
<span id="cb4-131"><a href="#cb4-131" aria-hidden="true" tabindex="-1"></a>instance will be retrieved to aid in the performance of a novel task.</span>
<span id="cb4-132"><a href="#cb4-132" aria-hidden="true" tabindex="-1"></a>Stored instances are retrieved in the context of novel stimuli or tasks</span>
<span id="cb4-133"><a href="#cb4-133" aria-hidden="true" tabindex="-1"></a>if they are sufficiently similar, thus suggesting that the process of</span>
<span id="cb4-134"><a href="#cb4-134" aria-hidden="true" tabindex="-1"></a>computing similarity is of central importance to generalization.</span>
<span id="cb4-135"><a href="#cb4-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-136"><a href="#cb4-136" aria-hidden="true" tabindex="-1"></a>Similarity, defined in this literature as a function of psychological</span>
<span id="cb4-137"><a href="#cb4-137" aria-hidden="true" tabindex="-1"></a>distance between instances or categories, has provided a successful</span>
<span id="cb4-138"><a href="#cb4-138" aria-hidden="true" tabindex="-1"></a>account of generalization across numerous tasks and domains. In an</span>
<span id="cb4-139"><a href="#cb4-139" aria-hidden="true" tabindex="-1"></a>influential study demonstrating an ordinal similarity effect,</span>
<span id="cb4-140"><a href="#cb4-140" aria-hidden="true" tabindex="-1"></a>experimenters employed a numerosity judgment task in which participants</span>
<span id="cb4-141"><a href="#cb4-141" aria-hidden="true" tabindex="-1"></a>quickly report the number of dots flashed on a screen. Performance (in</span>
<span id="cb4-142"><a href="#cb4-142" aria-hidden="true" tabindex="-1"></a>terms of response times to new patterns) on novel dot configurations</span>
<span id="cb4-143"><a href="#cb4-143" aria-hidden="true" tabindex="-1"></a>varied as an inverse function of their similarity to previously trained</span>
<span id="cb4-144"><a href="#cb4-144" aria-hidden="true" tabindex="-1"></a>dot configurations @palmeriExemplarSimilarityDevelopment1997. That is, performance was better on</span>
<span id="cb4-145"><a href="#cb4-145" aria-hidden="true" tabindex="-1"></a>novel configurations moderately similar to trained configurations than</span>
<span id="cb4-146"><a href="#cb4-146" aria-hidden="true" tabindex="-1"></a>to configurations with low-similarity, and also better on low-similarity</span>
<span id="cb4-147"><a href="#cb4-147" aria-hidden="true" tabindex="-1"></a>configurations than to even less similar, unrelated configurations.</span>
<span id="cb4-148"><a href="#cb4-148" aria-hidden="true" tabindex="-1"></a>Instance-based approaches have had some success accounting for</span>
<span id="cb4-149"><a href="#cb4-149" aria-hidden="true" tabindex="-1"></a>performance in certain sub-domains of motor learning <span class="co">[</span><span class="ot">@cohenWhereGraspsAre2004; @crumpEpisodicContributionsSequential2010; @meighWhatMemoryRepresentation2018; @poldrackRelationshipSkillLearning1999; @wifallReachingResponseSelection2017; @crumpEpisodicContributionsSequential2010</span><span class="co">]</span> trained participants to type words on an unfamiliar keyboard, while constraining the letters composing the training words to a pre-specified letter set. Following</span>
<span id="cb4-150"><a href="#cb4-150" aria-hidden="true" tabindex="-1"></a>training, typing speed was tested on previously experienced words</span>
<span id="cb4-151"><a href="#cb4-151" aria-hidden="true" tabindex="-1"></a>composed of previously experienced letters; novel words composed of</span>
<span id="cb4-152"><a href="#cb4-152" aria-hidden="true" tabindex="-1"></a>letters from the trained letter set; and novel words composed of letters</span>
<span id="cb4-153"><a href="#cb4-153" aria-hidden="true" tabindex="-1"></a>from an untrained letter set. Consistent with an instance-based account,</span>
<span id="cb4-154"><a href="#cb4-154" aria-hidden="true" tabindex="-1"></a>transfer performance was graded such that participants were fastest at</span>
<span id="cb4-155"><a href="#cb4-155" aria-hidden="true" tabindex="-1"></a>typing the words they had previously trained on, followed by novel words</span>
<span id="cb4-156"><a href="#cb4-156" aria-hidden="true" tabindex="-1"></a>composed of letters they had trained on, and slowest performance for new</span>
<span id="cb4-157"><a href="#cb4-157" aria-hidden="true" tabindex="-1"></a>words composed of untrained letters.</span>
<span id="cb4-158"><a href="#cb4-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-159"><a href="#cb4-159" aria-hidden="true" tabindex="-1"></a><span class="fu">## The effect of training variability on transfer</span></span>
<span id="cb4-160"><a href="#cb4-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-161"><a href="#cb4-161" aria-hidden="true" tabindex="-1"></a>While similarity-based models account for transfer by the degree of</span>
<span id="cb4-162"><a href="#cb4-162" aria-hidden="true" tabindex="-1"></a>similarity between previous and new experiences, a largely separate body</span>
<span id="cb4-163"><a href="#cb4-163" aria-hidden="true" tabindex="-1"></a>of research has focused on improving transfer by manipulating</span>
<span id="cb4-164"><a href="#cb4-164" aria-hidden="true" tabindex="-1"></a>characteristics of the initial training stage. Such characteristics have</span>
<span id="cb4-165"><a href="#cb4-165" aria-hidden="true" tabindex="-1"></a>included training difficulty, spacing, temporal order, feedback</span>
<span id="cb4-166"><a href="#cb4-166" aria-hidden="true" tabindex="-1"></a>schedules, and the primary focus of the current work -- variability of</span>
<span id="cb4-167"><a href="#cb4-167" aria-hidden="true" tabindex="-1"></a>training examples.</span>
<span id="cb4-168"><a href="#cb4-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-169"><a href="#cb4-169" aria-hidden="true" tabindex="-1"></a>Research on the effects of varied training typically compares</span>
<span id="cb4-170"><a href="#cb4-170" aria-hidden="true" tabindex="-1"></a>participants trained under constant, or minimal variability conditions</span>
<span id="cb4-171"><a href="#cb4-171" aria-hidden="true" tabindex="-1"></a>to those trained from a variety of examples or conditions <span class="co">[</span><span class="ot">@czyzVariabilityPracticeInformation2021; @soderstromLearningPerformanceIntegrative2015</span><span class="co">]</span>. Varied training has been shown to influence</span>
<span id="cb4-172"><a href="#cb4-172" aria-hidden="true" tabindex="-1"></a>learning in myriad domains including categorization of simple stimuli <span class="co">[</span><span class="ot">@hahnEffectsCategoryDiversity2005; @maddoxStimulusRangeDiscontinuity2011; @posnerGenesisAbstractIdeas1968</span><span class="co">]</span>,</span>
<span id="cb4-173"><a href="#cb4-173" aria-hidden="true" tabindex="-1"></a>complex categorization <span class="co">[</span><span class="ot">@nosofskyModelguidedSearchOptimal2018</span><span class="co">]</span>, language learning <span class="co">[</span><span class="ot">@jonesDensityDistinctivenessEarly2020; @perryLearnLocallyThink2010; @twomeyAllRightNoises2018; @wonnacottInputEffectsAcquisition2012</span><span class="co">]</span>, anagram completion <span class="co">[</span><span class="ot">@goodeSuperiorityVariableRepeated2008</span><span class="co">]</span>, trajectory</span>
<span id="cb4-174"><a href="#cb4-174" aria-hidden="true" tabindex="-1"></a>extrapolation <span class="co">[</span><span class="ot">@fulvioTaskSpecificResponseStrategy2014</span><span class="co">]</span>, task switching <span class="co">[</span><span class="ot">@sabahWhenLessMore2019</span><span class="co">]</span>, associative learning <span class="co">[</span><span class="ot">@leeEvidentialDiversityIncreases2019</span><span class="co">]</span>, visual search <span class="co">[</span><span class="ot">@georgeStimulusVariabilityTask2021; @gonzalezDiversityTrainingEnhances2011; @kelleyLearningAttendEffects2009</span><span class="co">]</span>, voice</span>
<span id="cb4-175"><a href="#cb4-175" aria-hidden="true" tabindex="-1"></a>identity learning <span class="co">[</span><span class="ot">@lavanEffectsHighVariability2019</span><span class="co">]</span>, simple motor learning <span class="co">[</span><span class="ot">@braunMotorTaskVariation2009; @kerrSpecificVariedPractice1978; @rollerVariablePracticeLenses2001; @willeyLimitedGeneralizationVaried2018</span><span class="co">]</span>,</span>
<span id="cb4-176"><a href="#cb4-176" aria-hidden="true" tabindex="-1"></a>sports training  <span class="co">[</span><span class="ot">@greenPracticeVariabilityTransfer1995; @greenPracticeVariabilityTransfer1995a @northEffectConsistentVaried2019</span><span class="co">]</span>, and training</span>
<span id="cb4-177"><a href="#cb4-177" aria-hidden="true" tabindex="-1"></a>on a complex video game <span class="co">[</span><span class="ot">@seowTransferEffectsVaried2019</span><span class="co">]</span>.</span>
<span id="cb4-178"><a href="#cb4-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-179"><a href="#cb4-179" aria-hidden="true" tabindex="-1"></a>Training variation has received a particularly large amount of attention</span>
<span id="cb4-180"><a href="#cb4-180" aria-hidden="true" tabindex="-1"></a>within the domain of visuomotor skill learning. Much of this research</span>
<span id="cb4-181"><a href="#cb4-181" aria-hidden="true" tabindex="-1"></a>has been influenced by the work of @schmidtSchemaTheoryDiscrete1975, who proposed a</span>
<span id="cb4-182"><a href="#cb4-182" aria-hidden="true" tabindex="-1"></a>schema-based account of motor learning as an attempt to address the</span>
<span id="cb4-183"><a href="#cb4-183" aria-hidden="true" tabindex="-1"></a>longstanding problem of how novel movements are produced. According to</span>
<span id="cb4-184"><a href="#cb4-184" aria-hidden="true" tabindex="-1"></a>Schema Theory, learners possess general motor programs for classes of</span>
<span id="cb4-185"><a href="#cb4-185" aria-hidden="true" tabindex="-1"></a>movements (e.g. throwing a ball with an underhand movement), as well as</span>
<span id="cb4-186"><a href="#cb4-186" aria-hidden="true" tabindex="-1"></a>schema rules that determine how a motor program is parameterized or</span>
<span id="cb4-187"><a href="#cb4-187" aria-hidden="true" tabindex="-1"></a>scaled for a particular movement. Schema theory predicts that varied</span>
<span id="cb4-188"><a href="#cb4-188" aria-hidden="true" tabindex="-1"></a>training results in the formation of a more general schema-rule, which</span>
<span id="cb4-189"><a href="#cb4-189" aria-hidden="true" tabindex="-1"></a>can allow for transfer to novel movements within a given movement class.</span>
<span id="cb4-190"><a href="#cb4-190" aria-hidden="true" tabindex="-1"></a>Experiments that test this hypothesis are often designed to compare the</span>
<span id="cb4-191"><a href="#cb4-191" aria-hidden="true" tabindex="-1"></a>transfer performance of a constant-trained group against that of a</span>
<span id="cb4-192"><a href="#cb4-192" aria-hidden="true" tabindex="-1"></a>varied-trained group. Both groups train on the same task, but the varied</span>
<span id="cb4-193"><a href="#cb4-193" aria-hidden="true" tabindex="-1"></a>group practices from multiple levels of a task-relevant dimension that</span>
<span id="cb4-194"><a href="#cb4-194" aria-hidden="true" tabindex="-1"></a>remains invariant for the constant group. For example, investigators</span>
<span id="cb4-195"><a href="#cb4-195" aria-hidden="true" tabindex="-1"></a>might train two groups of participants to throw a projectile at a</span>
<span id="cb4-196"><a href="#cb4-196" aria-hidden="true" tabindex="-1"></a>target, with a constant group that throws from a single location, and a</span>
<span id="cb4-197"><a href="#cb4-197" aria-hidden="true" tabindex="-1"></a>varied group that throws from multiple locations. Both groups are then</span>
<span id="cb4-198"><a href="#cb4-198" aria-hidden="true" tabindex="-1"></a>tested from novel locations. Empirically observed benefits of the</span>
<span id="cb4-199"><a href="#cb4-199" aria-hidden="true" tabindex="-1"></a>varied-trained group are then attributed to the variation they received</span>
<span id="cb4-200"><a href="#cb4-200" aria-hidden="true" tabindex="-1"></a>during training, a finding observed in numerous studies <span class="co">[</span><span class="ot">@catalanoDistantTransferCoincident1984a; @chuaPracticeVariabilityPromotes2019; @goodwinEffectDifferentQuantities1998; @kerrSpecificVariedPractice1978; @wulfEffectTypePractice1991</span><span class="co">]</span>, and the benefits of this variation are typically</span>
<span id="cb4-201"><a href="#cb4-201" aria-hidden="true" tabindex="-1"></a>thought to be mediated by the development of a more general schema for</span>
<span id="cb4-202"><a href="#cb4-202" aria-hidden="true" tabindex="-1"></a>the throwing motion.</span>
<span id="cb4-203"><a href="#cb4-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-204"><a href="#cb4-204" aria-hidden="true" tabindex="-1"></a>Of course, the relationship between training variability and transfer is</span>
<span id="cb4-205"><a href="#cb4-205" aria-hidden="true" tabindex="-1"></a>unlikely to be a simple function wherein increased variation is always</span>
<span id="cb4-206"><a href="#cb4-206" aria-hidden="true" tabindex="-1"></a>beneficial. Numerous studies have found null, or in some cases negative</span>
<span id="cb4-207"><a href="#cb4-207" aria-hidden="true" tabindex="-1"></a>effects of training variation <span class="co">[</span><span class="ot">@deloshExtrapolationSineQua1997; @sinkeviciuteRoleInputVariability2019; @wrisbergVariabilityPracticeHypothesis1987</span><span class="co">]</span>, and many more have suggested that the</span>
<span id="cb4-208"><a href="#cb4-208" aria-hidden="true" tabindex="-1"></a>benefits of variability may depend on additional factors such as prior</span>
<span id="cb4-209"><a href="#cb4-209" aria-hidden="true" tabindex="-1"></a>task experience, the order of training trials, or the type of transfer</span>
<span id="cb4-210"><a href="#cb4-210" aria-hidden="true" tabindex="-1"></a>being measured <span class="co">[</span><span class="ot">@bernikerEffectsTrainingBreadth2014; @braithwaiteEffectsVariationPrior2015; @hahnEffectsCategoryDiversity2005; @lavanEffectsHighVariability2019; @northEffectConsistentVaried2019; @sadakataIndividualAptitudeMandarin2014; @zamanPerceptualVariabilityImplications2021</span><span class="co">]</span>. </span>
<span id="cb4-211"><a href="#cb4-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-212"><a href="#cb4-212" aria-hidden="true" tabindex="-1"></a><span class="fu">## Issues with Previous Research</span></span>
<span id="cb4-213"><a href="#cb4-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-214"><a href="#cb4-214" aria-hidden="true" tabindex="-1"></a>Although the benefits of training variation in visuomotor skill learning</span>
<span id="cb4-215"><a href="#cb4-215" aria-hidden="true" tabindex="-1"></a>have been observed many times, null findings have also been repeatedly</span>
<span id="cb4-216"><a href="#cb4-216" aria-hidden="true" tabindex="-1"></a>found, leading some researchers to question the veracity of the</span>
<span id="cb4-217"><a href="#cb4-217" aria-hidden="true" tabindex="-1"></a>variability of practice hypothesis <span class="co">[</span><span class="ot">@newellSchemaTheory19752003; @vanrossumSchmidtSchemaTheory1990</span><span class="co">]</span>.</span>
<span id="cb4-218"><a href="#cb4-218" aria-hidden="true" tabindex="-1"></a>Critics have also pointed out that investigations of the effects of</span>
<span id="cb4-219"><a href="#cb4-219" aria-hidden="true" tabindex="-1"></a>training variability, of the sort described above, often fail to control</span>
<span id="cb4-220"><a href="#cb4-220" aria-hidden="true" tabindex="-1"></a>for the effect of similarity between training and testing conditions.</span>
<span id="cb4-221"><a href="#cb4-221" aria-hidden="true" tabindex="-1"></a>For training tasks in which participants have numerous degrees of</span>
<span id="cb4-222"><a href="#cb4-222" aria-hidden="true" tabindex="-1"></a>freedom (e.g. projectile throwing tasks where participants control the x</span>
<span id="cb4-223"><a href="#cb4-223" aria-hidden="true" tabindex="-1"></a>and y velocity of the projectile), varied groups are likely to</span>
<span id="cb4-224"><a href="#cb4-224" aria-hidden="true" tabindex="-1"></a>experience a wider range of the task space over the course of their</span>
<span id="cb4-225"><a href="#cb4-225" aria-hidden="true" tabindex="-1"></a>training (e.g. more unique combinations of x and y velocities).</span>
<span id="cb4-226"><a href="#cb4-226" aria-hidden="true" tabindex="-1"></a>Experimenters may attempt to account for this possibility by ensuring</span>
<span id="cb4-227"><a href="#cb4-227" aria-hidden="true" tabindex="-1"></a>that the training location(s) of the varied and constant groups are an</span>
<span id="cb4-228"><a href="#cb4-228" aria-hidden="true" tabindex="-1"></a>equal distance away from the eventual transfer locations, such that</span>
<span id="cb4-229"><a href="#cb4-229" aria-hidden="true" tabindex="-1"></a>their training throws are, on average, equally similar to throws that</span>
<span id="cb4-230"><a href="#cb4-230" aria-hidden="true" tabindex="-1"></a>would lead to good performance at the transfer locations. However, even</span>
<span id="cb4-231"><a href="#cb4-231" aria-hidden="true" tabindex="-1"></a>this level of experimental control may still be insufficient to rule out</span>
<span id="cb4-232"><a href="#cb4-232" aria-hidden="true" tabindex="-1"></a>the effect of similarity on transfer. Given that psychological</span>
<span id="cb4-233"><a href="#cb4-233" aria-hidden="true" tabindex="-1"></a>similarity is typically best described as either a Gaussian or</span>
<span id="cb4-234"><a href="#cb4-234" aria-hidden="true" tabindex="-1"></a>exponentially decaying function of psychological distance <span class="co">[</span><span class="ot">@ennisMultidimensionalStochasticTheory1988; @ghahramaniGeneralizationLocalRemappings1996; @loganInstanceTheoryAutomatization1988; @nosofskySimilarityScalingCognitive1992; @shepardUniversalLawGeneralization1987; @thoroughmanRapidReshapingHuman2005 </span><span class="co">]</span>, it is plausible that a subset of the</span>
<span id="cb4-235"><a href="#cb4-235" aria-hidden="true" tabindex="-1"></a>most similar training instances could have a disproportionate impact on</span>
<span id="cb4-236"><a href="#cb4-236" aria-hidden="true" tabindex="-1"></a>generalization to transfer conditions, even if the average distance</span>
<span id="cb4-237"><a href="#cb4-237" aria-hidden="true" tabindex="-1"></a>between training and transfer conditions is identical between groups.</span>
<span id="cb4-238"><a href="#cb4-238" aria-hidden="true" tabindex="-1"></a>Figure 1 demonstrates the consequences of a generalization gradient that</span>
<span id="cb4-239"><a href="#cb4-239" aria-hidden="true" tabindex="-1"></a>drops off as a Gaussian function of distance from training, as compared</span>
<span id="cb4-240"><a href="#cb4-240" aria-hidden="true" tabindex="-1"></a>to a linear drop-off.</span>
<span id="cb4-241"><a href="#cb4-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-242"><a href="#cb4-242" aria-hidden="true" tabindex="-1"></a><span class="in">```{r Toy Model, fig.width=9,fig.height=5.0}</span></span>
<span id="cb4-243"><a href="#cb4-243" aria-hidden="true" tabindex="-1"></a><span class="in">theme_set(theme_classic())</span></span>
<span id="cb4-244"><a href="#cb4-244" aria-hidden="true" tabindex="-1"></a><span class="in">p=2</span></span>
<span id="cb4-245"><a href="#cb4-245" aria-hidden="true" tabindex="-1"></a><span class="in">c&lt;- .0002</span></span>
<span id="cb4-246"><a href="#cb4-246" aria-hidden="true" tabindex="-1"></a><span class="in">simdat &lt;- data.frame(x=rep(seq(200,1000),3),condit=c(rep("varied",1602),rep("constant",801)),</span></span>
<span id="cb4-247"><a href="#cb4-247" aria-hidden="true" tabindex="-1"></a><span class="in">                     train.position=c(rep(400,801),rep(800,801),rep(600,801)),c=.0002,p=2) %&gt;%</span></span>
<span id="cb4-248"><a href="#cb4-248" aria-hidden="true" tabindex="-1"></a><span class="in">                     mutate(plotjitter=ifelse(condit=="varied",0,7),</span></span>
<span id="cb4-249"><a href="#cb4-249" aria-hidden="true" tabindex="-1"></a><span class="in">                            linScale=ifelse(condit=="varied",980,1000),</span></span>
<span id="cb4-250"><a href="#cb4-250" aria-hidden="true" tabindex="-1"></a><span class="in">                            genGauss=exp(-c*(abs((x-train.position)^p))),</span></span>
<span id="cb4-251"><a href="#cb4-251" aria-hidden="true" tabindex="-1"></a><span class="in">                            genLinear=1000-abs(x-train.position)+plotjitter) %&gt;% </span></span>
<span id="cb4-252"><a href="#cb4-252" aria-hidden="true" tabindex="-1"></a><span class="in">  #group_by(condit) %&gt;% mutate(scaleLinear=(genLinear-min(genLinear))/(max(genLinear)-min(genLinear))) %&gt;%</span></span>
<span id="cb4-253"><a href="#cb4-253" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(x,condit) %&gt;%</span></span>
<span id="cb4-254"><a href="#cb4-254" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(genGauss=mean(genGauss),genLinear=mean(genLinear)/linScale,.groups = 'keep')</span></span>
<span id="cb4-255"><a href="#cb4-255" aria-hidden="true" tabindex="-1"></a><span class="in">colorVec=c("darkblue","darkred")</span></span>
<span id="cb4-256"><a href="#cb4-256" aria-hidden="true" tabindex="-1"></a><span class="in">plotSpecs &lt;- list(geom_line(alpha=.7,size=.4),scale_color_manual(values=colorVec),</span></span>
<span id="cb4-257"><a href="#cb4-257" aria-hidden="true" tabindex="-1"></a><span class="in">                  geom_vline(alpha=.55,xintercept = c(400,800),color=colorVec[2]),</span></span>
<span id="cb4-258"><a href="#cb4-258" aria-hidden="true" tabindex="-1"></a><span class="in">                  geom_vline(alpha=.55,xintercept = c(600),color=colorVec[1]),</span></span>
<span id="cb4-259"><a href="#cb4-259" aria-hidden="true" tabindex="-1"></a><span class="in">                  ylim(c(0,1.05)),</span></span>
<span id="cb4-260"><a href="#cb4-260" aria-hidden="true" tabindex="-1"></a><span class="in">                  #xlim(c(250,950)),</span></span>
<span id="cb4-261"><a href="#cb4-261" aria-hidden="true" tabindex="-1"></a><span class="in">                  scale_x_continuous(breaks=seq(200,1000,by=200)),</span></span>
<span id="cb4-262"><a href="#cb4-262" aria-hidden="true" tabindex="-1"></a><span class="in">                  xlab("Test Stimulus"),</span></span>
<span id="cb4-263"><a href="#cb4-263" aria-hidden="true" tabindex="-1"></a><span class="in">                  annotate(geom="text",x=447,y=1.05,label="Varied",size=3.1,fontface="plain"),</span></span>
<span id="cb4-264"><a href="#cb4-264" aria-hidden="true" tabindex="-1"></a><span class="in">                  annotate(geom="text",x=450,y=1.02,label="Training",size=3.1,fontface="plain"),</span></span>
<span id="cb4-265"><a href="#cb4-265" aria-hidden="true" tabindex="-1"></a><span class="in">                  annotate(geom="text",x=659,y=1.05,label="Constant",size=3.1,fontface="plain"),</span></span>
<span id="cb4-266"><a href="#cb4-266" aria-hidden="true" tabindex="-1"></a><span class="in">                  annotate(geom="text",x=657,y=1.02,label="Training",size=3.1,fontface="plain"),</span></span>
<span id="cb4-267"><a href="#cb4-267" aria-hidden="true" tabindex="-1"></a><span class="in">                  annotate(geom="text",x=847,y=1.05,label="Varied",size=3.1,fontface="plain"),</span></span>
<span id="cb4-268"><a href="#cb4-268" aria-hidden="true" tabindex="-1"></a><span class="in">                  annotate(geom="text",x=850,y=1.02,label="Training",size=3.1,fontface="plain"),</span></span>
<span id="cb4-269"><a href="#cb4-269" aria-hidden="true" tabindex="-1"></a><span class="in">                  theme(panel.border = element_rect(colour = "black", fill=NA, size=1),</span></span>
<span id="cb4-270"><a href="#cb4-270" aria-hidden="true" tabindex="-1"></a><span class="in">                        legend.position="none"))</span></span>
<span id="cb4-271"><a href="#cb4-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-272"><a href="#cb4-272" aria-hidden="true" tabindex="-1"></a><span class="in">ip1 &lt;- simdat  %&gt;% ggplot(aes(x,y=genGauss,group=condit,col=condit))+plotSpecs+ylab("")</span></span>
<span id="cb4-273"><a href="#cb4-273" aria-hidden="true" tabindex="-1"></a><span class="in">ip2 &lt;- simdat %&gt;%  ggplot(aes(x,y=genLinear,group=condit,col=condit))+plotSpecs+ylab("Amount of Generalization")</span></span>
<span id="cb4-274"><a href="#cb4-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-275"><a href="#cb4-275" aria-hidden="true" tabindex="-1"></a><span class="in">#gridExtra::grid.arrange(ip2,ip1,ncol=2)</span></span>
<span id="cb4-276"><a href="#cb4-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-277"><a href="#cb4-277" aria-hidden="true" tabindex="-1"></a><span class="in">gtitle="Figure 1"</span></span>
<span id="cb4-278"><a href="#cb4-278" aria-hidden="true" tabindex="-1"></a><span class="in">title = ggdraw()+draw_label(gtitle,fontface = 'bold',x=0,hjust=0,size=11)+theme(plot.margin = margin(0, 0, 0, 1))</span></span>
<span id="cb4-279"><a href="#cb4-279" aria-hidden="true" tabindex="-1"></a><span class="in">captionText=str_wrap("Figure 1. Left panel: Generalization predicted from a simple model that assumes a linear generalization function. A varied group (red vertical lines indicate the 2 training locations) trained from positions 400 and 800, and a constant group (blue vertical line), trained from position 600. Right panel: if a Gaussian generalization function is assumed, then varied training (400, 800) is predicted to result in better generalization to positions close to 400 and 800 than does constant training at 600. ",200)</span></span>
<span id="cb4-280"><a href="#cb4-280" aria-hidden="true" tabindex="-1"></a><span class="in">capt=ggdraw()+draw_label(captionText,fontface = 'italic',x=0,hjust=0,size=11)+theme(plot.margin = margin(0, 0, 0, 1))</span></span>
<span id="cb4-281"><a href="#cb4-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-282"><a href="#cb4-282" aria-hidden="true" tabindex="-1"></a><span class="in">plot_grid(title,NULL,ip1,ip2,capt,NULL,ncol=2,rel_heights=c(.1,1,.15))</span></span>
<span id="cb4-283"><a href="#cb4-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-284"><a href="#cb4-284" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-285"><a href="#cb4-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-286"><a href="#cb4-286" aria-hidden="true" tabindex="-1"></a>In addition to largely overlooking the potential for non-linear</span>
<span id="cb4-287"><a href="#cb4-287" aria-hidden="true" tabindex="-1"></a>generalization to confound interpretations of training manipulations,</span>
<span id="cb4-288"><a href="#cb4-288" aria-hidden="true" tabindex="-1"></a>the visuomotor skill learning literature also rarely considers</span>
<span id="cb4-289"><a href="#cb4-289" aria-hidden="true" tabindex="-1"></a>alternatives to schema representations <span class="co">[</span><span class="ot">@chamberlinMemoryRepresentationMotor1992</span><span class="co">]</span>.</span>
<span id="cb4-290"><a href="#cb4-290" aria-hidden="true" tabindex="-1"></a>Although schema-theory remains influential within certain literatures,</span>
<span id="cb4-291"><a href="#cb4-291" aria-hidden="true" tabindex="-1"></a>instance or exemplar-based models have accounted for human behavior</span>
<span id="cb4-292"><a href="#cb4-292" aria-hidden="true" tabindex="-1"></a>across myriad domains <span class="co">[</span><span class="ot">@jamiesonInstanceTheoryDomaingeneral2022; @loganInstanceTheoryAttention2002a</span><span class="co">]</span>. As mentioned above, instance based accounts have been shown to perform well on a</span>
<span id="cb4-293"><a href="#cb4-293" aria-hidden="true" tabindex="-1"></a>variety of different tasks with motoric components <span class="co">[</span><span class="ot">@crumpEpisodicContributionsSequential2010;@gandolfoMotorLearningField1996a;  @meighWhatMemoryRepresentation2018; @rosenbaumPlanningReachesEvaluating1995; @vandamMappingShapeVisuomotor2015</span><span class="co">]</span>. However, such accounts have received little</span>
<span id="cb4-294"><a href="#cb4-294" aria-hidden="true" tabindex="-1"></a>attention within the subdomain of visuomotor skill learning focused on</span>
<span id="cb4-295"><a href="#cb4-295" aria-hidden="true" tabindex="-1"></a>the benefits of varied training.</span>
<span id="cb4-296"><a href="#cb4-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-297"><a href="#cb4-297" aria-hidden="true" tabindex="-1"></a>The present work examines whether the commonly observed benefits of</span>
<span id="cb4-298"><a href="#cb4-298" aria-hidden="true" tabindex="-1"></a>varied training can be accounted for by between-group differences in</span>
<span id="cb4-299"><a href="#cb4-299" aria-hidden="true" tabindex="-1"></a>similarity between training and testing throws. We first attempt to</span>
<span id="cb4-300"><a href="#cb4-300" aria-hidden="true" tabindex="-1"></a>replicate previous work finding an advantage of varied training over</span>
<span id="cb4-301"><a href="#cb4-301" aria-hidden="true" tabindex="-1"></a>constant training in a projectile launching task. We then examine the</span>
<span id="cb4-302"><a href="#cb4-302" aria-hidden="true" tabindex="-1"></a>extent to which this advantage can be explained by an instance-based</span>
<span id="cb4-303"><a href="#cb4-303" aria-hidden="true" tabindex="-1"></a>similarity model.</span>
<span id="cb4-304"><a href="#cb4-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-305"><a href="#cb4-305" aria-hidden="true" tabindex="-1"></a><span class="fu"># Experiment 1</span></span>
<span id="cb4-306"><a href="#cb4-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-307"><a href="#cb4-307" aria-hidden="true" tabindex="-1"></a><span class="fu">## Methods</span></span>
<span id="cb4-308"><a href="#cb4-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-309"><a href="#cb4-309" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sample Size Estimation</span></span>
<span id="cb4-310"><a href="#cb4-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-311"><a href="#cb4-311" aria-hidden="true" tabindex="-1"></a>To obtain an independent estimate of effect size, we identified previous</span>
<span id="cb4-312"><a href="#cb4-312" aria-hidden="true" tabindex="-1"></a>investigations which included between-subjects contrasts of varied and</span>
<span id="cb4-313"><a href="#cb4-313" aria-hidden="true" tabindex="-1"></a>constant conditions following training on an accuracy based projectile</span>
<span id="cb4-314"><a href="#cb4-314" aria-hidden="true" tabindex="-1"></a>launching task <span class="co">[</span><span class="ot">@chuaPracticeVariabilityPromotes2019; @goodwinEffectDifferentQuantities1998; @kerrSpecificVariedPractice1978; @wulfEffectTypePractice1991</span><span class="co">]</span>. We then averaged effects across these studies,</span>
<span id="cb4-315"><a href="#cb4-315" aria-hidden="true" tabindex="-1"></a>yielding a Cohens f =.43. The GPower 3.1 software package <span class="co">[</span><span class="ot">@faulStatisticalPowerAnalyses2009</span><span class="co">]</span>,</span>
<span id="cb4-316"><a href="#cb4-316" aria-hidden="true" tabindex="-1"></a>2009) was then used to determine that a power of 80% requires a sample</span>
<span id="cb4-317"><a href="#cb4-317" aria-hidden="true" tabindex="-1"></a>size of at least 23 participants per condition. All experiments reported</span>
<span id="cb4-318"><a href="#cb4-318" aria-hidden="true" tabindex="-1"></a>in the present manuscript exceed this minimum number of participants per</span>
<span id="cb4-319"><a href="#cb4-319" aria-hidden="true" tabindex="-1"></a>condition.</span>
<span id="cb4-320"><a href="#cb4-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-321"><a href="#cb4-321" aria-hidden="true" tabindex="-1"></a><span class="fu">### Participants</span></span>
<span id="cb4-322"><a href="#cb4-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-323"><a href="#cb4-323" aria-hidden="true" tabindex="-1"></a>Participants were recruited from an undergraduate population that is 63%</span>
<span id="cb4-324"><a href="#cb4-324" aria-hidden="true" tabindex="-1"></a>female and consists almost entirely of individuals aged 18-22 years. A</span>
<span id="cb4-325"><a href="#cb4-325" aria-hidden="true" tabindex="-1"></a>total of 110 Indiana University psychology students participated in</span>
<span id="cb4-326"><a href="#cb4-326" aria-hidden="true" tabindex="-1"></a>Experiment 1. We subsequently excluded 34 participants poor performance</span>
<span id="cb4-327"><a href="#cb4-327" aria-hidden="true" tabindex="-1"></a>at one of the dependent measures of the task (2.5-3 standard deviations</span>
<span id="cb4-328"><a href="#cb4-328" aria-hidden="true" tabindex="-1"></a>worse than the median subject at the task) or for displaying a pattern</span>
<span id="cb4-329"><a href="#cb4-329" aria-hidden="true" tabindex="-1"></a>of responses that was clearly indicative of a lack of engagement with</span>
<span id="cb4-330"><a href="#cb4-330" aria-hidden="true" tabindex="-1"></a>the task (e.g. simply dropping the ball on each trial rather than</span>
<span id="cb4-331"><a href="#cb4-331" aria-hidden="true" tabindex="-1"></a>throwing it at the target), or for reporting that they completed the</span>
<span id="cb4-332"><a href="#cb4-332" aria-hidden="true" tabindex="-1"></a>experiment on a phone or tablet device, despite the instructions not to</span>
<span id="cb4-333"><a href="#cb4-333" aria-hidden="true" tabindex="-1"></a>use one of these devices. A total of 74 participants were retained for</span>
<span id="cb4-334"><a href="#cb4-334" aria-hidden="true" tabindex="-1"></a>the final analyses, 35 in the varied group and 39 in the constant group.</span>
<span id="cb4-335"><a href="#cb4-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-336"><a href="#cb4-336" aria-hidden="true" tabindex="-1"></a><span class="fu">### Task</span></span>
<span id="cb4-337"><a href="#cb4-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-338"><a href="#cb4-338" aria-hidden="true" tabindex="-1"></a>The experimental task was programmed in JavaScript, using packages from</span>
<span id="cb4-339"><a href="#cb4-339" aria-hidden="true" tabindex="-1"></a>the Phaser physics engine (https://phaser.io) and the jsPsych library</span>
<span id="cb4-340"><a href="#cb4-340" aria-hidden="true" tabindex="-1"></a>(de Leeuw, 2015). The stimuli, presented on a black background,</span>
<span id="cb4-341"><a href="#cb4-341" aria-hidden="true" tabindex="-1"></a>consisted of a circular blue ball -- controlled by the participant via</span>
<span id="cb4-342"><a href="#cb4-342" aria-hidden="true" tabindex="-1"></a>the mouse or trackpad cursor; a rectangular green target; a red</span>
<span id="cb4-343"><a href="#cb4-343" aria-hidden="true" tabindex="-1"></a>rectangular barrier located between the ball and the target; and an</span>
<span id="cb4-344"><a href="#cb4-344" aria-hidden="true" tabindex="-1"></a>orange square within which the participant could control the ball before</span>
<span id="cb4-345"><a href="#cb4-345" aria-hidden="true" tabindex="-1"></a>releasing it in a throw towards the target. Because the task was</span>
<span id="cb4-346"><a href="#cb4-346" aria-hidden="true" tabindex="-1"></a>administered online, the absolute distance between stimuli could vary</span>
<span id="cb4-347"><a href="#cb4-347" aria-hidden="true" tabindex="-1"></a>depending on the size of the computer monitor being used, but the</span>
<span id="cb4-348"><a href="#cb4-348" aria-hidden="true" tabindex="-1"></a>relative distance between the stimuli was held constant. Likewise, the</span>
<span id="cb4-349"><a href="#cb4-349" aria-hidden="true" tabindex="-1"></a>distance between the center of the target, and the training and testing</span>
<span id="cb4-350"><a href="#cb4-350" aria-hidden="true" tabindex="-1"></a>locations was scaled such that relative distances were preserved</span>
<span id="cb4-351"><a href="#cb4-351" aria-hidden="true" tabindex="-1"></a>regardless of screen size. For the sake of brevity, subsequent mentions</span>
<span id="cb4-352"><a href="#cb4-352" aria-hidden="true" tabindex="-1"></a>of this relative distance between stimuli, or the position where the</span>
<span id="cb4-353"><a href="#cb4-353" aria-hidden="true" tabindex="-1"></a>ball landed in relation to the center of the target, will be referred to</span>
<span id="cb4-354"><a href="#cb4-354" aria-hidden="true" tabindex="-1"></a>simply as distance. Methods Figure 2 displays the layout of the task, as</span>
<span id="cb4-355"><a href="#cb4-355" aria-hidden="true" tabindex="-1"></a>it would appear to a participant at the start of a trial, with the ball</span>
<span id="cb4-356"><a href="#cb4-356" aria-hidden="true" tabindex="-1"></a>appearing in the center of the orange square. Using a mouse or trackpad,</span>
<span id="cb4-357"><a href="#cb4-357" aria-hidden="true" tabindex="-1"></a>participants click down on the ball to take control of the ball,</span>
<span id="cb4-358"><a href="#cb4-358" aria-hidden="true" tabindex="-1"></a>connecting the movement of the ball to the movement of the cursor.</span>
<span id="cb4-359"><a href="#cb4-359" aria-hidden="true" tabindex="-1"></a>Participants can then "wind up" the ball by dragging it (within the</span>
<span id="cb4-360"><a href="#cb4-360" aria-hidden="true" tabindex="-1"></a>confines of the orange square) and then launch the ball by releasing the</span>
<span id="cb4-361"><a href="#cb4-361" aria-hidden="true" tabindex="-1"></a>cursor. If the ball does not land on the target, participants are</span>
<span id="cb4-362"><a href="#cb4-362" aria-hidden="true" tabindex="-1"></a>presented with feedback in red text at the top right of the screen, on</span>
<span id="cb4-363"><a href="#cb4-363" aria-hidden="true" tabindex="-1"></a>how many units away they were from the center of the target. If the ball</span>
<span id="cb4-364"><a href="#cb4-364" aria-hidden="true" tabindex="-1"></a>was thrown outside of the boundary of the screen participants are given</span>
<span id="cb4-365"><a href="#cb4-365" aria-hidden="true" tabindex="-1"></a>feedback as to how far away from the target center the ball would have</span>
<span id="cb4-366"><a href="#cb4-366" aria-hidden="true" tabindex="-1"></a>been if it had continued its trajectory. If the ball strikes the barrier</span>
<span id="cb4-367"><a href="#cb4-367" aria-hidden="true" tabindex="-1"></a>(from the side or by landing on top), feedback is presented telling</span>
<span id="cb4-368"><a href="#cb4-368" aria-hidden="true" tabindex="-1"></a>participants to avoid hitting the barrier. If participants drag the ball</span>
<span id="cb4-369"><a href="#cb4-369" aria-hidden="true" tabindex="-1"></a>outside of the orange square before releasing it, the trial terminates,</span>
<span id="cb4-370"><a href="#cb4-370" aria-hidden="true" tabindex="-1"></a>and they are reminded to release the ball within the orange square. If</span>
<span id="cb4-371"><a href="#cb4-371" aria-hidden="true" tabindex="-1"></a>the ball lands on the target, feedback is presented in green text,</span>
<span id="cb4-372"><a href="#cb4-372" aria-hidden="true" tabindex="-1"></a>confirming that the target was hit, and presenting additional feedback</span>
<span id="cb4-373"><a href="#cb4-373" aria-hidden="true" tabindex="-1"></a>on how many units away the ball was from the exact center of the target.</span>
<span id="cb4-374"><a href="#cb4-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-375"><a href="#cb4-375" aria-hidden="true" tabindex="-1"></a>[Link to abbrevaited example of</span>
<span id="cb4-376"><a href="#cb4-376" aria-hidden="true" tabindex="-1"></a>task](https://pcl.sitehost.iu.edu/tg/demos/igas_expt1_demo.html){target="_blank"}.</span>
<span id="cb4-377"><a href="#cb4-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-378"><a href="#cb4-378" aria-hidden="true" tabindex="-1"></a><span class="in">```{r Figure 2, echo=FALSE,fig.height=5.8, fig.width=10.1}</span></span>
<span id="cb4-379"><a href="#cb4-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-380"><a href="#cb4-380" aria-hidden="true" tabindex="-1"></a><span class="in">#mf &lt;- png::readPNG("Assets/methodsFig1.png")</span></span>
<span id="cb4-381"><a href="#cb4-381" aria-hidden="true" tabindex="-1"></a><span class="in">#ggplot()+annotation_raster(mf,xmin = 0, xmax = 486, ymin = 0, ymax = 196)</span></span>
<span id="cb4-382"><a href="#cb4-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-383"><a href="#cb4-383" aria-hidden="true" tabindex="-1"></a><span class="in">gtitle="Figure 2"</span></span>
<span id="cb4-384"><a href="#cb4-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-385"><a href="#cb4-385" aria-hidden="true" tabindex="-1"></a><span class="in">title = ggdraw()+draw_label(gtitle,fontface = 'bold',y=Inf, x=0,hjust=0,vjust=5.5,size=11)+theme(plot.margin = margin(0, 0, 0, 0))</span></span>
<span id="cb4-386"><a href="#cb4-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-387"><a href="#cb4-387" aria-hidden="true" tabindex="-1"></a><span class="in">captionText=str_wrap("Figure 2: The stimuli of the task consisted of a blue ball, which the participants would launch at the green target, while avoiding the red barrier. On each trial, the ball would appear in the center of the orange square, with the position of the orange square varying between experimental conditions. Participants were constrained to release the ball within the square. ",150)</span></span>
<span id="cb4-388"><a href="#cb4-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-389"><a href="#cb4-389" aria-hidden="true" tabindex="-1"></a><span class="in">capt&lt;-ggdraw()+draw_label(captionText,fontface = 'italic',x=0,hjust=0,size=11)+ </span></span>
<span id="cb4-390"><a href="#cb4-390" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(plot.margin = margin(0, 0, 0, 1))</span></span>
<span id="cb4-391"><a href="#cb4-391" aria-hidden="true" tabindex="-1"></a><span class="in">  #theme(plot.margin = unit(c(0, 0, 0, 1), "cm"))</span></span>
<span id="cb4-392"><a href="#cb4-392" aria-hidden="true" tabindex="-1"></a><span class="in">mf &lt;- cowplot::ggdraw()+cowplot::draw_image("Assets/methodsFig1.png",hjust=0)+theme(plot.margin = margin(0, 0, 0, 0))</span></span>
<span id="cb4-393"><a href="#cb4-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-394"><a href="#cb4-394" aria-hidden="true" tabindex="-1"></a><span class="in">plot_grid(title,mf,capt,ncol=1,rel_heights = c(.1,1,.1))</span></span>
<span id="cb4-395"><a href="#cb4-395" aria-hidden="true" tabindex="-1"></a><span class="in">#plot_grid(mf,capt,ncol=1,rel_widths=c(1,.01))</span></span>
<span id="cb4-396"><a href="#cb4-396" aria-hidden="true" tabindex="-1"></a><span class="in"># plot_grid(capt,capt,ncol=1)</span></span>
<span id="cb4-397"><a href="#cb4-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-398"><a href="#cb4-398" aria-hidden="true" tabindex="-1"></a><span class="in"># capt</span></span>
<span id="cb4-399"><a href="#cb4-399" aria-hidden="true" tabindex="-1"></a><span class="in"># # c2 = ggdraw()+draw_label("testing_text out",x=0,hjust=0,vjust=0,size=11)+ theme(plot.margin = unit(c(0, 0, 0, 0), "pt"))</span></span>
<span id="cb4-400"><a href="#cb4-400" aria-hidden="true" tabindex="-1"></a><span class="in"># # c2</span></span>
<span id="cb4-401"><a href="#cb4-401" aria-hidden="true" tabindex="-1"></a><span class="in"># plot_grid(capt,capt,ncol=1,rel_heights =c(1,.2))</span></span>
<span id="cb4-402"><a href="#cb4-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-403"><a href="#cb4-403" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-404"><a href="#cb4-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-405"><a href="#cb4-405" aria-hidden="true" tabindex="-1"></a><span class="fu">## Results</span></span>
<span id="cb4-406"><a href="#cb4-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-407"><a href="#cb4-407" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data Processing and Statistical Packages</span></span>
<span id="cb4-408"><a href="#cb4-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-409"><a href="#cb4-409" aria-hidden="true" tabindex="-1"></a>To prepare the data, we first removed trials that were not easily</span>
<span id="cb4-410"><a href="#cb4-410" aria-hidden="true" tabindex="-1"></a>interpretable as performance indicators in our task. Removed trials</span>
<span id="cb4-411"><a href="#cb4-411" aria-hidden="true" tabindex="-1"></a>included: 1) those in which participants dragged the ball outside of the</span>
<span id="cb4-412"><a href="#cb4-412" aria-hidden="true" tabindex="-1"></a>orange starting box without releasing it, 2) trials in which</span>
<span id="cb4-413"><a href="#cb4-413" aria-hidden="true" tabindex="-1"></a>participants clicked on the ball, and then immediately released it,</span>
<span id="cb4-414"><a href="#cb4-414" aria-hidden="true" tabindex="-1"></a>causing the ball to drop straight down, 3) outlier trials in which the</span>
<span id="cb4-415"><a href="#cb4-415" aria-hidden="true" tabindex="-1"></a>ball was thrown more than 2.5 standard deviations further than the</span>
<span id="cb4-416"><a href="#cb4-416" aria-hidden="true" tabindex="-1"></a>average throw (calculated separately for each throwing position), and 4)</span>
<span id="cb4-417"><a href="#cb4-417" aria-hidden="true" tabindex="-1"></a>trials in which the ball struck the barrier. The primary measure of</span>
<span id="cb4-418"><a href="#cb4-418" aria-hidden="true" tabindex="-1"></a>performance used in all analyses was the absolute distance away from the</span>
<span id="cb4-419"><a href="#cb4-419" aria-hidden="true" tabindex="-1"></a>center of the target. The absolute distance was calculated on every</span>
<span id="cb4-420"><a href="#cb4-420" aria-hidden="true" tabindex="-1"></a>trial, and then averaged within each subject to yield a single</span>
<span id="cb4-421"><a href="#cb4-421" aria-hidden="true" tabindex="-1"></a>performance score, for each position. A consistent pattern across</span>
<span id="cb4-422"><a href="#cb4-422" aria-hidden="true" tabindex="-1"></a>training and testing phases in both experiments was for participants to</span>
<span id="cb4-423"><a href="#cb4-423" aria-hidden="true" tabindex="-1"></a>perform worse from throwing positions further away from the target -- a</span>
<span id="cb4-424"><a href="#cb4-424" aria-hidden="true" tabindex="-1"></a>pattern which we refer to as the difficulty of the positions. However,</span>
<span id="cb4-425"><a href="#cb4-425" aria-hidden="true" tabindex="-1"></a>there were no interactions between throwing position and training</span>
<span id="cb4-426"><a href="#cb4-426" aria-hidden="true" tabindex="-1"></a>conditions, allowing us to collapse across positions in cases where</span>
<span id="cb4-427"><a href="#cb4-427" aria-hidden="true" tabindex="-1"></a>contrasts for specific positions were not of interest. All data</span>
<span id="cb4-428"><a href="#cb4-428" aria-hidden="true" tabindex="-1"></a>processing and statistical analyses were performed in R version 4.03 (R</span>
<span id="cb4-429"><a href="#cb4-429" aria-hidden="true" tabindex="-1"></a>Core Team, 2020). ANOVAs for group comparisons were performed using the</span>
<span id="cb4-430"><a href="#cb4-430" aria-hidden="true" tabindex="-1"></a>rstatix package (Kassambara, 2021)****.</span>
<span id="cb4-431"><a href="#cb4-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-432"><a href="#cb4-432" aria-hidden="true" tabindex="-1"></a><span class="fu">## Training Phase</span></span>
<span id="cb4-433"><a href="#cb4-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-434"><a href="#cb4-434" aria-hidden="true" tabindex="-1"></a>Figure 3 below shows aggregate training performance binned into three</span>
<span id="cb4-435"><a href="#cb4-435" aria-hidden="true" tabindex="-1"></a>stages representing the beginning, middle, and end of the training</span>
<span id="cb4-436"><a href="#cb4-436" aria-hidden="true" tabindex="-1"></a>phase. Because the two conditions trained from target distances that</span>
<span id="cb4-437"><a href="#cb4-437" aria-hidden="true" tabindex="-1"></a>were not equally difficult, it was not possible to directly compare</span>
<span id="cb4-438"><a href="#cb4-438" aria-hidden="true" tabindex="-1"></a>performance between conditions in the training phase. Our focus for the</span>
<span id="cb4-439"><a href="#cb4-439" aria-hidden="true" tabindex="-1"></a>training data analysis was instead to establish that participants did</span>
<span id="cb4-440"><a href="#cb4-440" aria-hidden="true" tabindex="-1"></a>improve their performance over the course of training, and to examine</span>
<span id="cb4-441"><a href="#cb4-441" aria-hidden="true" tabindex="-1"></a>whether there was any interaction between training stage and condition.</span>
<span id="cb4-442"><a href="#cb4-442" aria-hidden="true" tabindex="-1"></a>Descriptive statistics for the intermittent testing phase are provided</span>
<span id="cb4-443"><a href="#cb4-443" aria-hidden="true" tabindex="-1"></a>in the supplementary materials.</span>
<span id="cb4-444"><a href="#cb4-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-445"><a href="#cb4-445" aria-hidden="true" tabindex="-1"></a>We performed an ANOVA comparison with stage as a within-group factor and</span>
<span id="cb4-446"><a href="#cb4-446" aria-hidden="true" tabindex="-1"></a>condition as between-group factor. The analysis revealed a significant</span>
<span id="cb4-447"><a href="#cb4-447" aria-hidden="true" tabindex="-1"></a>effect of training stage F(2,142)=62.4, p<span class="sc">\&lt;</span>.001, $\eta^{2}_G$ = .17,</span>
<span id="cb4-448"><a href="#cb4-448" aria-hidden="true" tabindex="-1"></a>such that performance improved over the course of training There was no</span>
<span id="cb4-449"><a href="#cb4-449" aria-hidden="true" tabindex="-1"></a>significant effect of condition F(1,71)=1.42, p=.24, $\eta^{2}_G$ = .02,</span>
<span id="cb4-450"><a href="#cb4-450" aria-hidden="true" tabindex="-1"></a>and no significant interaction between condition and training stage,</span>
<span id="cb4-451"><a href="#cb4-451" aria-hidden="true" tabindex="-1"></a>F(2,142)=.10, p=.91, $\eta^{2}_G$ <span class="sc">\&lt;</span> .01.</span>
<span id="cb4-452"><a href="#cb4-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-453"><a href="#cb4-453" aria-hidden="true" tabindex="-1"></a><span class="in">```{r Training1, echo=FALSE,fig.height=5.0, fig.width=7}</span></span>
<span id="cb4-454"><a href="#cb4-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-455"><a href="#cb4-455" aria-hidden="true" tabindex="-1"></a><span class="in">exp1TrainPosition &lt;- e1 %&gt;% filter(stage!="Transfer",mode==1) %&gt;%ungroup() %&gt;% </span></span>
<span id="cb4-456"><a href="#cb4-456" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,Group,conditType,trainHalf,positionX) %&gt;% </span></span>
<span id="cb4-457"><a href="#cb4-457" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDistance=mean(AbsDistFromCenter),.groups = 'keep')</span></span>
<span id="cb4-458"><a href="#cb4-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-459"><a href="#cb4-459" aria-hidden="true" tabindex="-1"></a><span class="in">exp1TrainPosition3 &lt;- e1 %&gt;% filter(stage!="Transfer",mode==1) %&gt;%ungroup() %&gt;% </span></span>
<span id="cb4-460"><a href="#cb4-460" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,Group,conditType,stage,positionX) %&gt;% </span></span>
<span id="cb4-461"><a href="#cb4-461" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDistance=mean(AbsDistFromCenter),.groups = 'keep')</span></span>
<span id="cb4-462"><a href="#cb4-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-463"><a href="#cb4-463" aria-hidden="true" tabindex="-1"></a><span class="in">exp1Train &lt;- e1 %&gt;% filter(stage!="Transfer",mode==1)  %&gt;%</span></span>
<span id="cb4-464"><a href="#cb4-464" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,Group,conditType,trainHalf) %&gt;% </span></span>
<span id="cb4-465"><a href="#cb4-465" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDistance=mean(AbsDistFromCenter),.groups = 'keep')</span></span>
<span id="cb4-466"><a href="#cb4-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-467"><a href="#cb4-467" aria-hidden="true" tabindex="-1"></a><span class="in">exp1Train3 &lt;- e1 %&gt;% filter(stage!="Transfer",mode==1)  %&gt;%</span></span>
<span id="cb4-468"><a href="#cb4-468" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,Group,conditType,stage) %&gt;% </span></span>
<span id="cb4-469"><a href="#cb4-469" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDistance=mean(AbsDistFromCenter),.groups = 'keep')</span></span>
<span id="cb4-470"><a href="#cb4-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-471"><a href="#cb4-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-472"><a href="#cb4-472" aria-hidden="true" tabindex="-1"></a><span class="in">e1train2 &lt;- exp1TrainPosition3 %&gt;% ggplot(aes(x=positionX,y=MeanTargetDistance))+</span></span>
<span id="cb4-473"><a href="#cb4-473" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_bar(aes(group=stage,fill=stage),stat="summary",fun=mean,position=dodge)+</span></span>
<span id="cb4-474"><a href="#cb4-474" aria-hidden="true" tabindex="-1"></a><span class="in">  facet_wrap(~conditType,ncol=2)+</span></span>
<span id="cb4-475"><a href="#cb4-475" aria-hidden="true" tabindex="-1"></a><span class="in">  stat_summary(aes(x=positionX,group=stage),fun.data=mean_se,geom="errorbar",position=dodge,width=.8)+</span></span>
<span id="cb4-476"><a href="#cb4-476" aria-hidden="true" tabindex="-1"></a><span class="in">  ylab("Mean Distance From Center Of Target")+</span></span>
<span id="cb4-477"><a href="#cb4-477" aria-hidden="true" tabindex="-1"></a><span class="in">  xlab("Training Location(s)")+theme(plot.title = element_text(hjust = 0.5))+</span></span>
<span id="cb4-478"><a href="#cb4-478" aria-hidden="true" tabindex="-1"></a><span class="in">  guides(fill=guide_legend(title="Training Stage"))+theme(legend.title.align=.25)</span></span>
<span id="cb4-479"><a href="#cb4-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-480"><a href="#cb4-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-481"><a href="#cb4-481" aria-hidden="true" tabindex="-1"></a><span class="in">gtitle="Figure 3"</span></span>
<span id="cb4-482"><a href="#cb4-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-483"><a href="#cb4-483" aria-hidden="true" tabindex="-1"></a><span class="in">title = ggdraw()+draw_label(gtitle,fontface = 'bold',y=Inf, x=0,hjust=0,vjust=5.5,size=11)+theme(plot.margin = margin(0, 0, 0, 0))</span></span>
<span id="cb4-484"><a href="#cb4-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-485"><a href="#cb4-485" aria-hidden="true" tabindex="-1"></a><span class="in">captionText=str_wrap("Training performance for varied and constant participants binned into three stages. Shorter bars indicate better performance (ball landing closer to the center of the target). Error bars indicate standard error of the mean. ",145)</span></span>
<span id="cb4-486"><a href="#cb4-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-487"><a href="#cb4-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-488"><a href="#cb4-488" aria-hidden="true" tabindex="-1"></a><span class="in">capt&lt;-ggdraw()+draw_label(captionText,fontface = 'italic',x=0,hjust=0,size=11)+ </span></span>
<span id="cb4-489"><a href="#cb4-489" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(plot.margin = margin(0, 0, 0, 1))</span></span>
<span id="cb4-490"><a href="#cb4-490" aria-hidden="true" tabindex="-1"></a><span class="in">  #theme(plot.margin = unit(c(0, 0, 0, 1), "cm"))</span></span>
<span id="cb4-491"><a href="#cb4-491" aria-hidden="true" tabindex="-1"></a><span class="in">plot_grid(title,e1train2,capt,ncol=1,rel_heights=c(.18,1,.15))</span></span>
<span id="cb4-492"><a href="#cb4-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-493"><a href="#cb4-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-494"><a href="#cb4-494" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-495"><a href="#cb4-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-496"><a href="#cb4-496" aria-hidden="true" tabindex="-1"></a><span class="fu">## Testing Phase</span></span>
<span id="cb4-497"><a href="#cb4-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-498"><a href="#cb4-498" aria-hidden="true" tabindex="-1"></a>In Experiment 1, a single constant-trained group was compared against a</span>
<span id="cb4-499"><a href="#cb4-499" aria-hidden="true" tabindex="-1"></a>single varied-trained group. At the transfer phase, all participants</span>
<span id="cb4-500"><a href="#cb4-500" aria-hidden="true" tabindex="-1"></a>were tested from 3 positions: 1) the positions(s) from their own</span>
<span id="cb4-501"><a href="#cb4-501" aria-hidden="true" tabindex="-1"></a>training, 2) the training position(s) of the other group, and 3) a</span>
<span id="cb4-502"><a href="#cb4-502" aria-hidden="true" tabindex="-1"></a>position novel to both groups. Overall, group performance was compared</span>
<span id="cb4-503"><a href="#cb4-503" aria-hidden="true" tabindex="-1"></a>with a mixed type III ANOVA, with condition (varied vs. constant) as a</span>
<span id="cb4-504"><a href="#cb4-504" aria-hidden="true" tabindex="-1"></a>between-subject factor and throwing location as a within-subject</span>
<span id="cb4-505"><a href="#cb4-505" aria-hidden="true" tabindex="-1"></a>variable. The effect of throwing position was strong, F(3,213) = 56.12,</span>
<span id="cb4-506"><a href="#cb4-506" aria-hidden="true" tabindex="-1"></a>p<span class="sc">\&lt;</span>.001, η2G = .23. The effect of training condition was significant</span>
<span id="cb4-507"><a href="#cb4-507" aria-hidden="true" tabindex="-1"></a>F(1,71)=8.19, p<span class="sc">\&lt;</span>.01, η2G = .07. There was no significant interaction</span>
<span id="cb4-508"><a href="#cb4-508" aria-hidden="true" tabindex="-1"></a>between group and position, F(3,213)=1.81, p=.15, η2G = .01.</span>
<span id="cb4-509"><a href="#cb4-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-510"><a href="#cb4-510" aria-hidden="true" tabindex="-1"></a><span class="in">```{r e1Test, echo=FALSE,fig.width=9.5, fig.height = 6.5 }</span></span>
<span id="cb4-511"><a href="#cb4-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-512"><a href="#cb4-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-513"><a href="#cb4-513" aria-hidden="true" tabindex="-1"></a><span class="in">exp1.Test &lt;- e1 %&gt;% filter(stage=="Transfer") %&gt;% select(-trainHalf)%&gt;% group_by(positionX) %&gt;% </span></span>
<span id="cb4-514"><a href="#cb4-514" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(globalAvg=mean(AbsDistFromCenter),globalSd=sd(AbsDistFromCenter)) %&gt;% </span></span>
<span id="cb4-515"><a href="#cb4-515" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,positionX) %&gt;% </span></span>
<span id="cb4-516"><a href="#cb4-516" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(scaledDev = scaleVar(globalAvg,globalSd,AbsDistFromCenter)) %&gt;%</span></span>
<span id="cb4-517"><a href="#cb4-517" aria-hidden="true" tabindex="-1"></a><span class="in">  ungroup() %&gt;% group_by(sbjCode,conditType,positionX,ThrowPosition) %&gt;%</span></span>
<span id="cb4-518"><a href="#cb4-518" aria-hidden="true" tabindex="-1"></a><span class="in">summarise(MeanTargetDeviance = mean(AbsDistFromCenter),MeanScaleDev = mean(scaledDev),.groups="keep")%&gt;% as.data.frame()</span></span>
<span id="cb4-519"><a href="#cb4-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-520"><a href="#cb4-520" aria-hidden="true" tabindex="-1"></a><span class="in">#manuscript plot</span></span>
<span id="cb4-521"><a href="#cb4-521" aria-hidden="true" tabindex="-1"></a><span class="in">e1test1=exp1.Test %&gt;% ggplot(aes(x=positionX,y=MeanTargetDeviance,group=conditType,fill=conditType))+</span></span>
<span id="cb4-522"><a href="#cb4-522" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_bar(stat="summary",fun=mean,position=dodge)+ stat_summary(fun.data=mean_se,geom="errorbar",position=dodge,width=.5)+ylab("Mean Distance From Center Of Target") +xlab("Testing Location")+theme(plot.title = element_text(hjust = 0.5))+guides(fill=guide_legend(title="Training Condition"))+theme(legend.title.align=.25)+scale_x_discrete(name="Testing Location",labels=e1Labels)</span></span>
<span id="cb4-523"><a href="#cb4-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-524"><a href="#cb4-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-525"><a href="#cb4-525" aria-hidden="true" tabindex="-1"></a><span class="in">gtitle="Figure 4"</span></span>
<span id="cb4-526"><a href="#cb4-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-527"><a href="#cb4-527" aria-hidden="true" tabindex="-1"></a><span class="in">title = ggdraw()+draw_label(gtitle,fontface = 'bold',y=Inf, x=0,hjust=0,vjust=5.5,size=11)+theme(plot.margin = margin(0, 0, 0, 0))</span></span>
<span id="cb4-528"><a href="#cb4-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-529"><a href="#cb4-529" aria-hidden="true" tabindex="-1"></a><span class="in">captionText=str_wrap("Testing performance for each of the 4 testing positions, compared between training conditions. Positions 610 and 910 were trained on by the varied group, and novel for the constant group. Position 760 was trained on by the constant group, and novel for the varied group. Position 835 was novel for both groups. Shorter bars are indicative of better performance (the ball landing closer to the center of the target). Error bars indicate standard error of the mean. ",130)</span></span>
<span id="cb4-530"><a href="#cb4-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-531"><a href="#cb4-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-532"><a href="#cb4-532" aria-hidden="true" tabindex="-1"></a><span class="in">capt&lt;-ggdraw()+draw_label(captionText,fontface = 'italic',x=0,hjust=0,size=11)+ </span></span>
<span id="cb4-533"><a href="#cb4-533" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(plot.margin = margin(0, 0, 0, 1))</span></span>
<span id="cb4-534"><a href="#cb4-534" aria-hidden="true" tabindex="-1"></a><span class="in">  #theme(plot.margin = unit(c(0, 0, 0, 1), "cm"))</span></span>
<span id="cb4-535"><a href="#cb4-535" aria-hidden="true" tabindex="-1"></a><span class="in">plot_grid(title,e1test1,capt,ncol=1,rel_heights=c(.18,1,.15))</span></span>
<span id="cb4-536"><a href="#cb4-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-537"><a href="#cb4-537" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-538"><a href="#cb4-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-539"><a href="#cb4-539" aria-hidden="true" tabindex="-1"></a>\</span>
<span id="cb4-540"><a href="#cb4-540" aria-hidden="true" tabindex="-1"></a>\</span>
<span id="cb4-541"><a href="#cb4-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-542"><a href="#cb4-542" aria-hidden="true" tabindex="-1"></a><span class="in">```{r e1Table, echo=FALSE }</span></span>
<span id="cb4-543"><a href="#cb4-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-544"><a href="#cb4-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-545"><a href="#cb4-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-546"><a href="#cb4-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-547"><a href="#cb4-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-548"><a href="#cb4-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-549"><a href="#cb4-549" aria-hidden="true" tabindex="-1"></a><span class="in">exp1.Test &lt;- e1 %&gt;% filter(stage=="Transfer") %&gt;% select(-trainHalf)%&gt;% group_by(positionX) %&gt;% </span></span>
<span id="cb4-550"><a href="#cb4-550" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(globalAvg=mean(AbsDistFromCenter),globalSd=sd(AbsDistFromCenter)) %&gt;% </span></span>
<span id="cb4-551"><a href="#cb4-551" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,positionX) %&gt;% </span></span>
<span id="cb4-552"><a href="#cb4-552" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(scaledDev = scaleVar(globalAvg,globalSd,AbsDistFromCenter)) %&gt;%</span></span>
<span id="cb4-553"><a href="#cb4-553" aria-hidden="true" tabindex="-1"></a><span class="in">  ungroup() %&gt;% group_by(sbjCode,conditType,positionX,ThrowPosition) %&gt;%</span></span>
<span id="cb4-554"><a href="#cb4-554" aria-hidden="true" tabindex="-1"></a><span class="in">summarise(MeanTargetDeviance = mean(AbsDistFromCenter),MeanScaleDev = mean(scaledDev),.groups="keep")%&gt;% as.data.frame()</span></span>
<span id="cb4-555"><a href="#cb4-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-556"><a href="#cb4-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-557"><a href="#cb4-557" aria-hidden="true" tabindex="-1"></a><span class="in">test= exp1.Test %&gt;% dplyr::rename(Condition="conditType") %&gt;% group_by(Condition,positionX) %&gt;%</span></span>
<span id="cb4-558"><a href="#cb4-558" aria-hidden="true" tabindex="-1"></a><span class="in">   summarise(Mean=round(mean(MeanTargetDeviance),2),sd=round(sd(MeanTargetDeviance),2),.groups="keep")</span></span>
<span id="cb4-559"><a href="#cb4-559" aria-hidden="true" tabindex="-1"></a><span class="in"> test=test %&gt;% group_by(Condition) %&gt;% mutate(GroupAvg=round(mean(Mean),2),groupSd=round(sd(Mean),2))</span></span>
<span id="cb4-560"><a href="#cb4-560" aria-hidden="true" tabindex="-1"></a><span class="in"> test = test %&gt;% mutate(msd=paste(Mean,"(",sd,")",sep=""),gsd=paste(GroupAvg,"(",groupSd,")",sep="")) %&gt;% select(positionX,Condition,msd,gsd)%&gt;%pivot_wider(names_from = Condition,values_from=c(msd,gsd))</span></span>
<span id="cb4-561"><a href="#cb4-561" aria-hidden="true" tabindex="-1"></a><span class="in"> test=test[,1:3]</span></span>
<span id="cb4-562"><a href="#cb4-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-563"><a href="#cb4-563" aria-hidden="true" tabindex="-1"></a><span class="in">captionText="Table 1. Testing performance for varied and constant groups in experiment 1. Mean absolute deviation from the center of the target, with standard deviations in parenthesis." </span></span>
<span id="cb4-564"><a href="#cb4-564" aria-hidden="true" tabindex="-1"></a><span class="in"> </span></span>
<span id="cb4-565"><a href="#cb4-565" aria-hidden="true" tabindex="-1"></a><span class="in">kable(test,escape=FALSE,booktabs=TRUE,col.names=c("Position","Constant","Varied"),align=c("l"))  %&gt;% kableExtra::kable_styling(position="left") %&gt;%   kable_classic() %&gt;% kableExtra::footnote(general=captionText,general_title = "")</span></span>
<span id="cb4-566"><a href="#cb4-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-567"><a href="#cb4-567" aria-hidden="true" tabindex="-1"></a><span class="in"># </span></span>
<span id="cb4-568"><a href="#cb4-568" aria-hidden="true" tabindex="-1"></a><span class="in"># colnames(test) &lt;- c("Position","Constant","Varied")</span></span>
<span id="cb4-569"><a href="#cb4-569" aria-hidden="true" tabindex="-1"></a><span class="in"># ft1=flextable(test,col_keys = c("Position","Constant","Varied"))</span></span>
<span id="cb4-570"><a href="#cb4-570" aria-hidden="true" tabindex="-1"></a><span class="in"># ft1 &lt;- flextable::set_caption(ft1,captionText)</span></span>
<span id="cb4-571"><a href="#cb4-571" aria-hidden="true" tabindex="-1"></a><span class="in"># ft1</span></span>
<span id="cb4-572"><a href="#cb4-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-573"><a href="#cb4-573" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-574"><a href="#cb4-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-575"><a href="#cb4-575" aria-hidden="true" tabindex="-1"></a><span class="fu">## Discussion</span></span>
<span id="cb4-576"><a href="#cb4-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-577"><a href="#cb4-577" aria-hidden="true" tabindex="-1"></a>In Experiment 1, we found that varied training resulted in superior</span>
<span id="cb4-578"><a href="#cb4-578" aria-hidden="true" tabindex="-1"></a>testing performance than constant training, from both a position novel</span>
<span id="cb4-579"><a href="#cb4-579" aria-hidden="true" tabindex="-1"></a>to both groups, and from the position at which the constant group was</span>
<span id="cb4-580"><a href="#cb4-580" aria-hidden="true" tabindex="-1"></a>trained, which was novel to the varied condition. The superiority of</span>
<span id="cb4-581"><a href="#cb4-581" aria-hidden="true" tabindex="-1"></a>varied training over constant training even at the constant training</span>
<span id="cb4-582"><a href="#cb4-582" aria-hidden="true" tabindex="-1"></a>position is of particular note, given that testing at this position</span>
<span id="cb4-583"><a href="#cb4-583" aria-hidden="true" tabindex="-1"></a>should have been highly similar for participants in the constant</span>
<span id="cb4-584"><a href="#cb4-584" aria-hidden="true" tabindex="-1"></a>condition. It should also be noted, though, that testing at the constant</span>
<span id="cb4-585"><a href="#cb4-585" aria-hidden="true" tabindex="-1"></a>trained position is not exactly identical to training from that</span>
<span id="cb4-586"><a href="#cb4-586" aria-hidden="true" tabindex="-1"></a>position, given that the context of testing is different in several ways</span>
<span id="cb4-587"><a href="#cb4-587" aria-hidden="true" tabindex="-1"></a>from that of training, such as the testing trials from the different</span>
<span id="cb4-588"><a href="#cb4-588" aria-hidden="true" tabindex="-1"></a>positions being intermixed, as well as a simple change in context as a</span>
<span id="cb4-589"><a href="#cb4-589" aria-hidden="true" tabindex="-1"></a>function of time. Such contextual differences will be further considered</span>
<span id="cb4-590"><a href="#cb4-590" aria-hidden="true" tabindex="-1"></a>in the General Discussion.</span>
<span id="cb4-591"><a href="#cb4-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-592"><a href="#cb4-592" aria-hidden="true" tabindex="-1"></a>In addition to the variation of throwing position during training, the</span>
<span id="cb4-593"><a href="#cb4-593" aria-hidden="true" tabindex="-1"></a>participants in the varied condition of Experiment 1 also received</span>
<span id="cb4-594"><a href="#cb4-594" aria-hidden="true" tabindex="-1"></a>training practice from the closest/easiest position, as well as from the</span>
<span id="cb4-595"><a href="#cb4-595" aria-hidden="true" tabindex="-1"></a>furthest/most difficult position that would later be encountered by all</span>
<span id="cb4-596"><a href="#cb4-596" aria-hidden="true" tabindex="-1"></a>participants during testing. The varied condition also had the potential</span>
<span id="cb4-597"><a href="#cb4-597" aria-hidden="true" tabindex="-1"></a>advantage of interpolating both of the novel positions from which they</span>
<span id="cb4-598"><a href="#cb4-598" aria-hidden="true" tabindex="-1"></a>would later be tested. Experiment 2 thus sought to address these issues</span>
<span id="cb4-599"><a href="#cb4-599" aria-hidden="true" tabindex="-1"></a>by comparing a varied condition to multiple constant conditions.</span>
<span id="cb4-600"><a href="#cb4-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-601"><a href="#cb4-601" aria-hidden="true" tabindex="-1"></a><span class="fu"># Experiment 2</span></span>
<span id="cb4-602"><a href="#cb4-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-603"><a href="#cb4-603" aria-hidden="true" tabindex="-1"></a>In Experiment 2, we sought to replicate our findings from Experiment 1</span>
<span id="cb4-604"><a href="#cb4-604" aria-hidden="true" tabindex="-1"></a>with a new sample of participants, while also addressing the possibility</span>
<span id="cb4-605"><a href="#cb4-605" aria-hidden="true" tabindex="-1"></a>of the pattern of results in Experiment 1 being explained by some</span>
<span id="cb4-606"><a href="#cb4-606" aria-hidden="true" tabindex="-1"></a>idiosyncrasy of the particular training location of the constant group</span>
<span id="cb4-607"><a href="#cb4-607" aria-hidden="true" tabindex="-1"></a>relative to the varied group. To this end, Experiment 2 employed the</span>
<span id="cb4-608"><a href="#cb4-608" aria-hidden="true" tabindex="-1"></a>same basic procedure as Experiment 1, but was designed with six separate</span>
<span id="cb4-609"><a href="#cb4-609" aria-hidden="true" tabindex="-1"></a>constant groups each trained from one of six different locations (400,</span>
<span id="cb4-610"><a href="#cb4-610" aria-hidden="true" tabindex="-1"></a>500, 625, 675, 800, or 900), and a varied group trained from two</span>
<span id="cb4-611"><a href="#cb4-611" aria-hidden="true" tabindex="-1"></a>locations (500 and 800). Participants in all seven groups were then</span>
<span id="cb4-612"><a href="#cb4-612" aria-hidden="true" tabindex="-1"></a>tested from each of the 6 unique positions.</span>
<span id="cb4-613"><a href="#cb4-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-614"><a href="#cb4-614" aria-hidden="true" tabindex="-1"></a><span class="fu">## Methods</span></span>
<span id="cb4-615"><a href="#cb4-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-616"><a href="#cb4-616" aria-hidden="true" tabindex="-1"></a><span class="fu">### Participants</span></span>
<span id="cb4-617"><a href="#cb4-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-618"><a href="#cb4-618" aria-hidden="true" tabindex="-1"></a>A total of 306 Indiana University psychology students participated in</span>
<span id="cb4-619"><a href="#cb4-619" aria-hidden="true" tabindex="-1"></a>Experiment 2, which was also conducted online. As was the case in</span>
<span id="cb4-620"><a href="#cb4-620" aria-hidden="true" tabindex="-1"></a>experiment 1, the undergraduate population from which we recruited</span>
<span id="cb4-621"><a href="#cb4-621" aria-hidden="true" tabindex="-1"></a>participants was 63% female and primarily composed of 18--22-year-old</span>
<span id="cb4-622"><a href="#cb4-622" aria-hidden="true" tabindex="-1"></a>individuals. Using the same procedure as experiment 1, we excluded 98</span>
<span id="cb4-623"><a href="#cb4-623" aria-hidden="true" tabindex="-1"></a>participants for exceptionally poor performance at one of the dependent</span>
<span id="cb4-624"><a href="#cb4-624" aria-hidden="true" tabindex="-1"></a>measures of the task, or for displaying a pattern of responses</span>
<span id="cb4-625"><a href="#cb4-625" aria-hidden="true" tabindex="-1"></a>indicative of a lack of engagement with the task. A total of 208</span>
<span id="cb4-626"><a href="#cb4-626" aria-hidden="true" tabindex="-1"></a>participants were included in the final analyses with 31 in the varied</span>
<span id="cb4-627"><a href="#cb4-627" aria-hidden="true" tabindex="-1"></a>group and 32, 28, 37, 25, 29, 26 participants in the constant groups</span>
<span id="cb4-628"><a href="#cb4-628" aria-hidden="true" tabindex="-1"></a>training from location 400, 500, 625, 675, 800, and 900, respectively.</span>
<span id="cb4-629"><a href="#cb4-629" aria-hidden="true" tabindex="-1"></a>All participants were compensated with course credit.</span>
<span id="cb4-630"><a href="#cb4-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-631"><a href="#cb4-631" aria-hidden="true" tabindex="-1"></a><span class="fu">### Task and Procedure</span></span>
<span id="cb4-632"><a href="#cb4-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-633"><a href="#cb4-633" aria-hidden="true" tabindex="-1"></a>The task of Experiment 2 was identical to that of Experiment 1, in all</span>
<span id="cb4-634"><a href="#cb4-634" aria-hidden="true" tabindex="-1"></a>but some minor adjustments to the height of the barrier, and the</span>
<span id="cb4-635"><a href="#cb4-635" aria-hidden="true" tabindex="-1"></a>relative distance between the barrier and the target. Additionally, the</span>
<span id="cb4-636"><a href="#cb4-636" aria-hidden="true" tabindex="-1"></a>intermittent testing trials featured in experiment 1 were not utilized</span>
<span id="cb4-637"><a href="#cb4-637" aria-hidden="true" tabindex="-1"></a>in experiment 2, and all training and testing trials were presented with</span>
<span id="cb4-638"><a href="#cb4-638" aria-hidden="true" tabindex="-1"></a>feedback. An abbreviated demo of the task used for Experiment 2 can be</span>
<span id="cb4-639"><a href="#cb4-639" aria-hidden="true" tabindex="-1"></a>found at (https://pcl.sitehost.iu.edu/tg/demos/igas_expt2_demo.html).</span>
<span id="cb4-640"><a href="#cb4-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-641"><a href="#cb4-641" aria-hidden="true" tabindex="-1"></a>The procedure for Experiment 2 was also quite similar to experiment 1.</span>
<span id="cb4-642"><a href="#cb4-642" aria-hidden="true" tabindex="-1"></a>Participants completed 140 training trials, all of which were from the</span>
<span id="cb4-643"><a href="#cb4-643" aria-hidden="true" tabindex="-1"></a>same position for the constant groups and split evenly (70 trials each -</span>
<span id="cb4-644"><a href="#cb4-644" aria-hidden="true" tabindex="-1"></a>randomized) for the varied group. In the testing phase, participants</span>
<span id="cb4-645"><a href="#cb4-645" aria-hidden="true" tabindex="-1"></a>completed 30 trials from each of the six locations that had been used</span>
<span id="cb4-646"><a href="#cb4-646" aria-hidden="true" tabindex="-1"></a>separately across each of the constant groups during training. Each of</span>
<span id="cb4-647"><a href="#cb4-647" aria-hidden="true" tabindex="-1"></a>the constant groups thus experience one trained location and five novel</span>
<span id="cb4-648"><a href="#cb4-648" aria-hidden="true" tabindex="-1"></a>throwing locations in the testing phase, while the varied group</span>
<span id="cb4-649"><a href="#cb4-649" aria-hidden="true" tabindex="-1"></a>experiences 2 previously trained, and 4 novel locations.</span>
<span id="cb4-650"><a href="#cb4-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-651"><a href="#cb4-651" aria-hidden="true" tabindex="-1"></a><span class="fu">## Results</span></span>
<span id="cb4-652"><a href="#cb4-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-653"><a href="#cb4-653" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Processing and Statistical Packages</span></span>
<span id="cb4-654"><a href="#cb4-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-655"><a href="#cb4-655" aria-hidden="true" tabindex="-1"></a>After confirming that condition and throwing position did not have any</span>
<span id="cb4-656"><a href="#cb4-656" aria-hidden="true" tabindex="-1"></a>significant interactions, we standardized performance within each</span>
<span id="cb4-657"><a href="#cb4-657" aria-hidden="true" tabindex="-1"></a>position, and then average across position to yield a single performance</span>
<span id="cb4-658"><a href="#cb4-658" aria-hidden="true" tabindex="-1"></a>measure per participant. This standardization did not influence our</span>
<span id="cb4-659"><a href="#cb4-659" aria-hidden="true" tabindex="-1"></a>pattern of results. As in experiment 1, we performed type III ANOVA's</span>
<span id="cb4-660"><a href="#cb4-660" aria-hidden="true" tabindex="-1"></a>due to our unbalanced design, however the pattern of results presented</span>
<span id="cb4-661"><a href="#cb4-661" aria-hidden="true" tabindex="-1"></a>below is not altered if type 1 or type III tests are used instead. The</span>
<span id="cb4-662"><a href="#cb4-662" aria-hidden="true" tabindex="-1"></a>statistical software for the primary analyses was the same as for</span>
<span id="cb4-663"><a href="#cb4-663" aria-hidden="true" tabindex="-1"></a>experiment 1. Individual learning rates in the testing phase, compared</span>
<span id="cb4-664"><a href="#cb4-664" aria-hidden="true" tabindex="-1"></a>between groups in the supplementary analyses, were fit using the TEfit</span>
<span id="cb4-665"><a href="#cb4-665" aria-hidden="true" tabindex="-1"></a>package in R <span class="co">[</span><span class="ot">@cochraneTEfitsNonlinearRegression2020</span><span class="co">]</span>.</span>
<span id="cb4-666"><a href="#cb4-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-667"><a href="#cb4-667" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training Phase</span></span>
<span id="cb4-668"><a href="#cb4-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-669"><a href="#cb4-669" aria-hidden="true" tabindex="-1"></a>The different training conditions trained from positions that were not</span>
<span id="cb4-670"><a href="#cb4-670" aria-hidden="true" tabindex="-1"></a>equivalently difficult and are thus not easily amenable to comparison.</span>
<span id="cb4-671"><a href="#cb4-671" aria-hidden="true" tabindex="-1"></a>As previously stated, the primary interest of the training data is</span>
<span id="cb4-672"><a href="#cb4-672" aria-hidden="true" tabindex="-1"></a>confirmation that some learning did occur. Figure 5 depicts the training</span>
<span id="cb4-673"><a href="#cb4-673" aria-hidden="true" tabindex="-1"></a>performance of the varied group alongside that of the aggregate of the</span>
<span id="cb4-674"><a href="#cb4-674" aria-hidden="true" tabindex="-1"></a>six constant groups (5a), and each of the 6 separate constant groups</span>
<span id="cb4-675"><a href="#cb4-675" aria-hidden="true" tabindex="-1"></a>(5b). An ANOVA comparison with training stage (beginning, middle, end)</span>
<span id="cb4-676"><a href="#cb4-676" aria-hidden="true" tabindex="-1"></a>as a within-group factor and group (the varied condition vs. the 6</span>
<span id="cb4-677"><a href="#cb4-677" aria-hidden="true" tabindex="-1"></a>constant conditions collapsed together) as a between-subject factor</span>
<span id="cb4-678"><a href="#cb4-678" aria-hidden="true" tabindex="-1"></a>revealed no significant effect of group on training performance,</span>
<span id="cb4-679"><a href="#cb4-679" aria-hidden="true" tabindex="-1"></a>F(1,206)=.55,p=.49, $\eta^{2}_G$ <span class="sc">\&lt;</span>.01, a significant effect of training</span>
<span id="cb4-680"><a href="#cb4-680" aria-hidden="true" tabindex="-1"></a>stage F(2,412)=77.91, p<span class="sc">\&lt;</span>.001, $\eta^{2}_G$ =.05, and no significant</span>
<span id="cb4-681"><a href="#cb4-681" aria-hidden="true" tabindex="-1"></a>interaction between group and training stage, F(2,412)=.489 p=.61,</span>
<span id="cb4-682"><a href="#cb4-682" aria-hidden="true" tabindex="-1"></a>$\eta^{2}_G$ <span class="sc">\&lt;</span>.01. We also tested for a difference in training</span>
<span id="cb4-683"><a href="#cb4-683" aria-hidden="true" tabindex="-1"></a>performance between the varied group and the two constant groups that</span>
<span id="cb4-684"><a href="#cb4-684" aria-hidden="true" tabindex="-1"></a>trained matching throwing positions (i.e., the constant groups training</span>
<span id="cb4-685"><a href="#cb4-685" aria-hidden="true" tabindex="-1"></a>from position 500, and position 800). The results of our ANOVA on this</span>
<span id="cb4-686"><a href="#cb4-686" aria-hidden="true" tabindex="-1"></a>limited dataset mirrors that of the full-group analysis, with no</span>
<span id="cb4-687"><a href="#cb4-687" aria-hidden="true" tabindex="-1"></a>significant effect of group F(1,86)=.48, p=.49, $\eta^{2}_G$ <span class="sc">\&lt;</span>.01, a</span>
<span id="cb4-688"><a href="#cb4-688" aria-hidden="true" tabindex="-1"></a>significant effect of training stage F(2,172)=56.29, p<span class="sc">\&lt;</span>.001,</span>
<span id="cb4-689"><a href="#cb4-689" aria-hidden="true" tabindex="-1"></a>$\eta^{2}_G$ =.11, and no significant interaction between group and</span>
<span id="cb4-690"><a href="#cb4-690" aria-hidden="true" tabindex="-1"></a>training stage, F(2,172)=.341 p=.71, $\eta^{2}_G$ <span class="sc">\&lt;</span>.01.</span>
<span id="cb4-691"><a href="#cb4-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-692"><a href="#cb4-692" aria-hidden="true" tabindex="-1"></a><span class="in">```{r,echo=FALSE, include=FALSE }</span></span>
<span id="cb4-693"><a href="#cb4-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-694"><a href="#cb4-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-695"><a href="#cb4-695" aria-hidden="true" tabindex="-1"></a><span class="in">e2$stage &lt;- factor(e2$stage, levels = c("Beginning", "Middle", "End","Transfer"),ordered = TRUE)</span></span>
<span id="cb4-696"><a href="#cb4-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-697"><a href="#cb4-697" aria-hidden="true" tabindex="-1"></a><span class="in">exp2TrainPosition &lt;- e2  %&gt;% filter(stage!="Transfer") %&gt;%ungroup() %&gt;% </span></span>
<span id="cb4-698"><a href="#cb4-698" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,Group2,conditType,trainHalf,positionX) %&gt;% </span></span>
<span id="cb4-699"><a href="#cb4-699" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDistance=mean(AbsDistFromCenter))%&gt;% as.data.frame()</span></span>
<span id="cb4-700"><a href="#cb4-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-701"><a href="#cb4-701" aria-hidden="true" tabindex="-1"></a><span class="in">exp2TrainPosition3 &lt;- e2  %&gt;% filter(stage!="Transfer") %&gt;%ungroup() %&gt;% </span></span>
<span id="cb4-702"><a href="#cb4-702" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(globalAvg=mean(AbsDistFromCenter),globalSd=sd(AbsDistFromCenter)) %&gt;% </span></span>
<span id="cb4-703"><a href="#cb4-703" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,positionX) %&gt;% mutate(scaledDev = scaleVar(globalAvg,globalSd,AbsDistFromCenter)) %&gt;%ungroup() %&gt;%</span></span>
<span id="cb4-704"><a href="#cb4-704" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,Group2,conditType,stage,positionX) %&gt;% </span></span>
<span id="cb4-705"><a href="#cb4-705" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDistance=mean(AbsDistFromCenter),MeanScaledDev=mean(scaledDev,trim=.05))%&gt;% as.data.frame()</span></span>
<span id="cb4-706"><a href="#cb4-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-707"><a href="#cb4-707" aria-hidden="true" tabindex="-1"></a><span class="in">exp2Train &lt;- e2  %&gt;% filter(stage!="Transfer")  %&gt;% </span></span>
<span id="cb4-708"><a href="#cb4-708" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,Group2,conditType,trainHalf) %&gt;% </span></span>
<span id="cb4-709"><a href="#cb4-709" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDistance=mean(AbsDistFromCenter)) %&gt;% as.data.frame()</span></span>
<span id="cb4-710"><a href="#cb4-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-711"><a href="#cb4-711" aria-hidden="true" tabindex="-1"></a><span class="in">exp2Train3 &lt;- e2  %&gt;% filter(stage!="Transfer")  %&gt;% ungroup() %&gt;% </span></span>
<span id="cb4-712"><a href="#cb4-712" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(globalAvg=mean(AbsDistFromCenter),globalSd=sd(AbsDistFromCenter)) %&gt;% </span></span>
<span id="cb4-713"><a href="#cb4-713" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,positionX) %&gt;% mutate(scaledDev = scaleVar(globalAvg,globalSd,AbsDistFromCenter)) %&gt;%ungroup() %&gt;%</span></span>
<span id="cb4-714"><a href="#cb4-714" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,Group2,conditType,stage) %&gt;% </span></span>
<span id="cb4-715"><a href="#cb4-715" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDistance=mean(AbsDistFromCenter),MeanScaledDev=mean(scaledDev,trim=.05)) %&gt;% as.data.frame()</span></span>
<span id="cb4-716"><a href="#cb4-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-717"><a href="#cb4-717" aria-hidden="true" tabindex="-1"></a><span class="in">transfer &lt;- filter(e2, stage=="Transfer") %&gt;% droplevels() %&gt;% select(-trainHalf,-initialVelocityY,ThrowPosition2)%&gt;% ungroup()</span></span>
<span id="cb4-718"><a href="#cb4-718" aria-hidden="true" tabindex="-1"></a><span class="in">transfer &lt;- transfer %&gt;% group_by(positionX) %&gt;% mutate(globalAvg=mean(AbsDistFromCenter),globalSd=sd(AbsDistFromCenter)) %&gt;% </span></span>
<span id="cb4-719"><a href="#cb4-719" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,positionX) %&gt;% mutate(scaledDev = scaleVar(globalAvg,globalSd,AbsDistFromCenter)) %&gt;%ungroup()</span></span>
<span id="cb4-720"><a href="#cb4-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-721"><a href="#cb4-721" aria-hidden="true" tabindex="-1"></a><span class="in">transfer &lt;- transfer %&gt;% group_by(sbjCode,positionX) %&gt;% mutate(ind=1,testPosIndex=cumsum(ind),posN=max(testPosIndex)) %&gt;%</span></span>
<span id="cb4-722"><a href="#cb4-722" aria-hidden="true" tabindex="-1"></a><span class="in">  select(-ind) %&gt;% mutate(testHalf = case_when(testPosIndex&lt;15 ~"1st Half",testPosIndex&gt;=15 ~"2nd Half")) %&gt;% convert_as_factor(testHalf)</span></span>
<span id="cb4-723"><a href="#cb4-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-724"><a href="#cb4-724" aria-hidden="true" tabindex="-1"></a><span class="in">variedTest &lt;- transfer %&gt;% filter(condit==7) %&gt;% mutate(extrapolate=ifelse(positionX=="900" | positionX=="400","extrapolation","interpolation")) </span></span>
<span id="cb4-725"><a href="#cb4-725" aria-hidden="true" tabindex="-1"></a><span class="in">constantTest &lt;- transfer %&gt;% filter(condit!=7) %&gt;% mutate(extrapolate=ifelse(distFromTrain==0,"interpolation","extrapolation"))</span></span>
<span id="cb4-726"><a href="#cb4-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-727"><a href="#cb4-727" aria-hidden="true" tabindex="-1"></a><span class="in">transfer &lt;- rbind(variedTest,constantTest)</span></span>
<span id="cb4-728"><a href="#cb4-728" aria-hidden="true" tabindex="-1"></a><span class="in">transfer&lt;- transfer %&gt;% mutate(novel=ifelse(distFromTrain3==0,"trainedLocation","novelLocation"))%&gt;% convert_as_factor(novel,extrapolate)</span></span>
<span id="cb4-729"><a href="#cb4-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-730"><a href="#cb4-730" aria-hidden="true" tabindex="-1"></a><span class="in">transfer &lt;- transfer %&gt;% relocate(sbjCode,condit2,Group,conditType2,stage,trial,novel,extrapolate,positionX,AbsDistFromCenter,globalAvg,globalSd,scaledDev,distFromTrain3) %&gt;% ungroup()</span></span>
<span id="cb4-731"><a href="#cb4-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-732"><a href="#cb4-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-733"><a href="#cb4-733" aria-hidden="true" tabindex="-1"></a><span class="in"># novelAll &lt;- transfer %&gt;% filter(distFromTrain!=0, distFromTrain3!=0) %&gt;% select(-globalAvg,-globalSd,-scaledDev)%&gt;% droplevels() %&gt;% ungroup()</span></span>
<span id="cb4-734"><a href="#cb4-734" aria-hidden="true" tabindex="-1"></a><span class="in"># novelAll &lt;- novelAll %&gt;% group_by(positionX) %&gt;%</span></span>
<span id="cb4-735"><a href="#cb4-735" aria-hidden="true" tabindex="-1"></a><span class="in">#  mutate(globalAvg=mean(AbsDistFromCenter),globalSd=sd(AbsDistFromCenter)) %&gt;% </span></span>
<span id="cb4-736"><a href="#cb4-736" aria-hidden="true" tabindex="-1"></a><span class="in">#   group_by(sbjCode,positionX) %&gt;% mutate(scaledDev = scaleVar(globalAvg,globalSd,AbsDistFromCenter)) %&gt;%ungroup()</span></span>
<span id="cb4-737"><a href="#cb4-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-738"><a href="#cb4-738" aria-hidden="true" tabindex="-1"></a><span class="in">novelAll &lt;- transfer %&gt;% filter(distFromTrain!=0, distFromTrain3!=0)</span></span>
<span id="cb4-739"><a href="#cb4-739" aria-hidden="true" tabindex="-1"></a><span class="in">novelAllMatched &lt;- novelAll %&gt;% filter(condit!=5,condit!=2)</span></span>
<span id="cb4-740"><a href="#cb4-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-741"><a href="#cb4-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-742"><a href="#cb4-742" aria-hidden="true" tabindex="-1"></a><span class="in">constantIden &lt;- transfer %&gt;% filter(condit !=7,distFromTrain==0) # only constant groups from their training position</span></span>
<span id="cb4-743"><a href="#cb4-743" aria-hidden="true" tabindex="-1"></a><span class="in">variedTest &lt;- transfer %&gt;% filter(condit==7) # only varied testing</span></span>
<span id="cb4-744"><a href="#cb4-744" aria-hidden="true" tabindex="-1"></a><span class="in">variedVsIden &lt;- rbind(constantIden,variedTest) # all varied combined with constant identity</span></span>
<span id="cb4-745"><a href="#cb4-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-746"><a href="#cb4-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-747"><a href="#cb4-747" aria-hidden="true" tabindex="-1"></a><span class="in">variedNovel &lt;- variedTest %&gt;% filter(distFromTrain3 !=0) # removes 500 and 800 from varied</span></span>
<span id="cb4-748"><a href="#cb4-748" aria-hidden="true" tabindex="-1"></a><span class="in">constantIden2 &lt;- transfer %&gt;% filter(condit !=7,condit!=5,condit!=2,distFromTrain==0) # only constant groups from training position 400,625,675,900</span></span>
<span id="cb4-749"><a href="#cb4-749" aria-hidden="true" tabindex="-1"></a><span class="in">variedVsNovelIden &lt;- rbind(constantIden2,variedNovel) # novel positions for varied, trained for constant</span></span>
<span id="cb4-750"><a href="#cb4-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-751"><a href="#cb4-751" aria-hidden="true" tabindex="-1"></a><span class="in">exp2.Test &lt;- transfer %&gt;%group_by(sbjCode,conditType,positionX,ThrowPosition)%&gt;%</span></span>
<span id="cb4-752"><a href="#cb4-752" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDeviance = mean(AbsDistFromCenter,trim=.05),MeanScaledDev=mean(scaledDev,trim=.05)) %&gt;%ungroup() %&gt;% as.data.frame()</span></span>
<span id="cb4-753"><a href="#cb4-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-754"><a href="#cb4-754" aria-hidden="true" tabindex="-1"></a><span class="in">exp2.Test2 &lt;- exp2.Test %&gt;% group_by(sbjCode,conditType)%&gt;%</span></span>
<span id="cb4-755"><a href="#cb4-755" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDeviance = mean(MeanTargetDeviance),MeanScaledDev=mean(MeanScaledDev)) %&gt;%ungroup() %&gt;% as.data.frame()</span></span>
<span id="cb4-756"><a href="#cb4-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-757"><a href="#cb4-757" aria-hidden="true" tabindex="-1"></a><span class="in">exp2.Test7 &lt;- transfer %&gt;%group_by(Group2,sbjCode,positionX,Group,conditType,ThrowPosition4) %&gt;% </span></span>
<span id="cb4-758"><a href="#cb4-758" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDeviance = mean(AbsDistFromCenter,trim=.05),MeanScaledDev=mean(scaledDev,trim=.05)) %&gt;% as.data.frame()</span></span>
<span id="cb4-759"><a href="#cb4-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-760"><a href="#cb4-760" aria-hidden="true" tabindex="-1"></a><span class="in">exp2.Test7.agg &lt;- exp2.Test7  %&gt;%group_by(Group2,sbjCode,Group,conditType) %&gt;% </span></span>
<span id="cb4-761"><a href="#cb4-761" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDeviance = mean(MeanTargetDeviance),MeanScaledDev=mean(MeanScaledDev)) %&gt;% as.data.frame()</span></span>
<span id="cb4-762"><a href="#cb4-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-763"><a href="#cb4-763" aria-hidden="true" tabindex="-1"></a><span class="in">exp2.Test7.agg2 &lt;- exp2.Test7  %&gt;%group_by(sbjCode,conditType) %&gt;% </span></span>
<span id="cb4-764"><a href="#cb4-764" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDeviance = mean(MeanTargetDeviance),MeanScaledDev=mean(MeanScaledDev)) %&gt;% as.data.frame()</span></span>
<span id="cb4-765"><a href="#cb4-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-766"><a href="#cb4-766" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-767"><a href="#cb4-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-768"><a href="#cb4-768" aria-hidden="true" tabindex="-1"></a><span class="in">```{r e2train, echo=FALSE,fig.height=12.5, fig.width=9}</span></span>
<span id="cb4-769"><a href="#cb4-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-770"><a href="#cb4-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-771"><a href="#cb4-771" aria-hidden="true" tabindex="-1"></a><span class="in">### New - 3 stage</span></span>
<span id="cb4-772"><a href="#cb4-772" aria-hidden="true" tabindex="-1"></a><span class="in">e2train1&lt;-exp2TrainPosition3 %&gt;% ggplot(aes(x=stage,y=MeanTargetDistance))+</span></span>
<span id="cb4-773"><a href="#cb4-773" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_bar(aes(group=stage,fill=stage),stat="summary",position=dodge,fun="mean")+</span></span>
<span id="cb4-774"><a href="#cb4-774" aria-hidden="true" tabindex="-1"></a><span class="in">  stat_summary(aes(x=stage,group=stage),fun.data=mean_se,geom="errorbar",position=dodge,width=.8)+facet_wrap(~conditType,ncol=2)+</span></span>
<span id="cb4-775"><a href="#cb4-775" aria-hidden="true" tabindex="-1"></a><span class="in">  ylab("Mean Distance From Center Of Target") +xlab("Training Stage")+</span></span>
<span id="cb4-776"><a href="#cb4-776" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(plot.title = element_text(face="bold",hjust = 0.0,size=9),</span></span>
<span id="cb4-777"><a href="#cb4-777" aria-hidden="true" tabindex="-1"></a><span class="in">        plot.title.position = "plot")+</span></span>
<span id="cb4-778"><a href="#cb4-778" aria-hidden="true" tabindex="-1"></a><span class="in">  guides(fill=guide_legend(title="Training Stage"))+theme(legend.title.align=.25)+ggtitle("A")</span></span>
<span id="cb4-779"><a href="#cb4-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-780"><a href="#cb4-780" aria-hidden="true" tabindex="-1"></a><span class="in">e2train2&lt;-exp2TrainPosition3 %&gt;% ggplot(aes(x=positionX,y=MeanTargetDistance))+</span></span>
<span id="cb4-781"><a href="#cb4-781" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_bar(aes(group=stage,fill=stage),stat="summary",position=dodge,fun="mean")+</span></span>
<span id="cb4-782"><a href="#cb4-782" aria-hidden="true" tabindex="-1"></a><span class="in">  facet_wrap(~conditType,ncol=2)+stat_summary(aes(x=positionX,group=stage),fun.data=mean_se,geom="errorbar",position=dodge,width=.8)+ylab("Mean Distance From Center Of Target") +xlab("Training Location(s)")+</span></span>
<span id="cb4-783"><a href="#cb4-783" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(plot.title = element_text(face="bold",hjust = 0,size=9),</span></span>
<span id="cb4-784"><a href="#cb4-784" aria-hidden="true" tabindex="-1"></a><span class="in">        plot.title.position = "plot")+</span></span>
<span id="cb4-785"><a href="#cb4-785" aria-hidden="true" tabindex="-1"></a><span class="in">  guides(fill=guide_legend(title="Training Stage"))+theme(legend.title.align=.25)+ggtitle("B")</span></span>
<span id="cb4-786"><a href="#cb4-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-787"><a href="#cb4-787" aria-hidden="true" tabindex="-1"></a><span class="in">#plot_grid(e2train1,e2train2,ncol=1)</span></span>
<span id="cb4-788"><a href="#cb4-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-789"><a href="#cb4-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-790"><a href="#cb4-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-791"><a href="#cb4-791" aria-hidden="true" tabindex="-1"></a><span class="in">gtitle="Figure 5"</span></span>
<span id="cb4-792"><a href="#cb4-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-793"><a href="#cb4-793" aria-hidden="true" tabindex="-1"></a><span class="in">title = ggdraw()+draw_label(gtitle,fontface = 'bold',y=Inf, x=0,hjust=0,vjust=5.5,size=11)+theme(plot.margin = margin(0, 0, 0, 0))</span></span>
<span id="cb4-794"><a href="#cb4-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-795"><a href="#cb4-795" aria-hidden="true" tabindex="-1"></a><span class="in">captionText=str_wrap("Training performance for the six constant conditions, and the varied condition, binned into three stages. In Figure 5a, the six constant groups are averaged together, as are the two training positions for the varied group. In Figure 5b the six constant groups are shown separately, with each set of bars representing the beginning, middle, and end of training for a single constant group that trained from the position indicated on the x-axis. Figure 5b also shows training performance separately for both of the throwing locations trained by the varied group. Error bars indicate standard error of the mean. ",130)</span></span>
<span id="cb4-796"><a href="#cb4-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-797"><a href="#cb4-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-798"><a href="#cb4-798" aria-hidden="true" tabindex="-1"></a><span class="in">capt&lt;-ggdraw()+draw_label(captionText,fontface = 'italic',x=0,hjust=0,size=11)+ </span></span>
<span id="cb4-799"><a href="#cb4-799" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(plot.margin = margin(0, 0, 0, 1))</span></span>
<span id="cb4-800"><a href="#cb4-800" aria-hidden="true" tabindex="-1"></a><span class="in">  #theme(plot.margin = unit(c(0, 0, 0, 1), "cm"))</span></span>
<span id="cb4-801"><a href="#cb4-801" aria-hidden="true" tabindex="-1"></a><span class="in">plot_grid(title,e2train1,e2train2,capt,ncol=1,rel_heights=c(.18,1,1,.15))</span></span>
<span id="cb4-802"><a href="#cb4-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-803"><a href="#cb4-803" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-804"><a href="#cb4-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-805"><a href="#cb4-805" aria-hidden="true" tabindex="-1"></a><span class="fu">### Testing Phase</span></span>
<span id="cb4-806"><a href="#cb4-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-807"><a href="#cb4-807" aria-hidden="true" tabindex="-1"></a>In Experiment 2, a single varied condition (trained from two positions,</span>
<span id="cb4-808"><a href="#cb4-808" aria-hidden="true" tabindex="-1"></a>500 and 800), was compared against six separate constant groups (trained</span>
<span id="cb4-809"><a href="#cb4-809" aria-hidden="true" tabindex="-1"></a>from a single position, 400, 500, 625, 675, 800 or 900). For the testing</span>
<span id="cb4-810"><a href="#cb4-810" aria-hidden="true" tabindex="-1"></a>phase, all participants were tested from all six positions, four of</span>
<span id="cb4-811"><a href="#cb4-811" aria-hidden="true" tabindex="-1"></a>which were novel for the varied condition, and five of which were novel</span>
<span id="cb4-812"><a href="#cb4-812" aria-hidden="true" tabindex="-1"></a>for each of the constant groups. For a general comparison, we took the</span>
<span id="cb4-813"><a href="#cb4-813" aria-hidden="true" tabindex="-1"></a>absolute deviations for each throwing position and computed standardized</span>
<span id="cb4-814"><a href="#cb4-814" aria-hidden="true" tabindex="-1"></a>scores across all participants, and then averaged across throwing</span>
<span id="cb4-815"><a href="#cb4-815" aria-hidden="true" tabindex="-1"></a>position. The six constant groups were then collapsed together allowing</span>
<span id="cb4-816"><a href="#cb4-816" aria-hidden="true" tabindex="-1"></a>us to make a simple comparison between training conditions (constant vs.</span>
<span id="cb4-817"><a href="#cb4-817" aria-hidden="true" tabindex="-1"></a>varied). A type III between-subjects ANOVA was performed, yielding a</span>
<span id="cb4-818"><a href="#cb4-818" aria-hidden="true" tabindex="-1"></a>significant effect of condition F(1,206)=4.33, p=.039, $\eta^{2}_G$</span>
<span id="cb4-819"><a href="#cb4-819" aria-hidden="true" tabindex="-1"></a>=.02. Descriptive statistics for each condition are shown in table 2.</span>
<span id="cb4-820"><a href="#cb4-820" aria-hidden="true" tabindex="-1"></a>Figure 6A visualizes the consistent advantage of the varied condition</span>
<span id="cb4-821"><a href="#cb4-821" aria-hidden="true" tabindex="-1"></a>over the constant groups across the testing positions. Figure 6b shows</span>
<span id="cb4-822"><a href="#cb4-822" aria-hidden="true" tabindex="-1"></a>performance between the varied condition and the individual constant</span>
<span id="cb4-823"><a href="#cb4-823" aria-hidden="true" tabindex="-1"></a>groups.</span>
<span id="cb4-824"><a href="#cb4-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-825"><a href="#cb4-825" aria-hidden="true" tabindex="-1"></a><span class="in">```{r e2test1, echo=FALSE,fig.height=12.5, fig.width=10.5 }</span></span>
<span id="cb4-826"><a href="#cb4-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-827"><a href="#cb4-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-828"><a href="#cb4-828" aria-hidden="true" tabindex="-1"></a><span class="in"># manuscript plot</span></span>
<span id="cb4-829"><a href="#cb4-829" aria-hidden="true" tabindex="-1"></a><span class="in">e2test1&lt;-exp2.Test %&gt;% ggplot(aes(x=ThrowPosition,y=MeanTargetDeviance,group=conditType,fill=conditType))+geom_bar(stat="summary",position=dodge,fun="mean")+ stat_summary(fun.data=mean_se,geom="errorbar",position=dodge,width=.5)+ylab("Mean Distance From Center Of Target") +xlab("Testing Location")+guides(fill=guide_legend(title="Training Condition"))+</span></span>
<span id="cb4-830"><a href="#cb4-830" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(plot.title=element_text(face="bold",size=9),</span></span>
<span id="cb4-831"><a href="#cb4-831" aria-hidden="true" tabindex="-1"></a><span class="in">        plot.title.position = "plot",</span></span>
<span id="cb4-832"><a href="#cb4-832" aria-hidden="true" tabindex="-1"></a><span class="in">        legend.title.align=.25)+</span></span>
<span id="cb4-833"><a href="#cb4-833" aria-hidden="true" tabindex="-1"></a><span class="in">  ggtitle("A")</span></span>
<span id="cb4-834"><a href="#cb4-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-835"><a href="#cb4-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-836"><a href="#cb4-836" aria-hidden="true" tabindex="-1"></a><span class="in">e2test2&lt;-exp2.Test7 %&gt;% </span></span>
<span id="cb4-837"><a href="#cb4-837" aria-hidden="true" tabindex="-1"></a><span class="in">  ggplot(aes(x=Group,y=MeanTargetDeviance,group=conditType,fill=conditType))+</span></span>
<span id="cb4-838"><a href="#cb4-838" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_bar(stat="summary",position=position_dodge(),fun="mean")+ </span></span>
<span id="cb4-839"><a href="#cb4-839" aria-hidden="true" tabindex="-1"></a><span class="in">  stat_summary(fun.data=mean_se,geom="errorbar",position=position_dodge())+</span></span>
<span id="cb4-840"><a href="#cb4-840" aria-hidden="true" tabindex="-1"></a><span class="in">  facet_wrap(~ThrowPosition4)+</span></span>
<span id="cb4-841"><a href="#cb4-841" aria-hidden="true" tabindex="-1"></a><span class="in">  ylab("Mean Distance From Center Of Target")+</span></span>
<span id="cb4-842"><a href="#cb4-842" aria-hidden="true" tabindex="-1"></a><span class="in">  guides(fill=guide_legend(title="Training Condition"))+</span></span>
<span id="cb4-843"><a href="#cb4-843" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(plot.title=element_text(face="bold",size=9),</span></span>
<span id="cb4-844"><a href="#cb4-844" aria-hidden="true" tabindex="-1"></a><span class="in">        plot.title.position = "plot",</span></span>
<span id="cb4-845"><a href="#cb4-845" aria-hidden="true" tabindex="-1"></a><span class="in">        legend.title.align=.25,</span></span>
<span id="cb4-846"><a href="#cb4-846" aria-hidden="true" tabindex="-1"></a><span class="in">        axis.text.x = element_text(size = 7,angle=45,hjust=1))+</span></span>
<span id="cb4-847"><a href="#cb4-847" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_x_discrete(name=" Training Group",labels=e2Labels)+ggtitle("B")</span></span>
<span id="cb4-848"><a href="#cb4-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-849"><a href="#cb4-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-850"><a href="#cb4-850" aria-hidden="true" tabindex="-1"></a><span class="in">gtitle="Figure 6"</span></span>
<span id="cb4-851"><a href="#cb4-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-852"><a href="#cb4-852" aria-hidden="true" tabindex="-1"></a><span class="in">title = ggdraw()+draw_label(gtitle,fontface = 'bold',y=Inf, x=0,hjust=0,vjust=5.5,size=11)+theme(plot.margin = margin(0, 0, 0, 0))</span></span>
<span id="cb4-853"><a href="#cb4-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-854"><a href="#cb4-854" aria-hidden="true" tabindex="-1"></a><span class="in">captionText=str_wrap("Testing phase performance from each of the six testing positions. The six constant conditions are averaged together into a single constant group, compared against the single varied-trained group.B) Transfer performance from each of the 6 throwing locations from which all participants were tested. Each bar represents performance from one of seven distinct training groups (six constant groups in red, one varied group in blue). The x axis labels indicate the location(s) from which each group trained. Lower values along the y axis reflect better performance at the task (closer distance to target center). Error bars indicate standard error of the mean. ",140)</span></span>
<span id="cb4-855"><a href="#cb4-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-856"><a href="#cb4-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-857"><a href="#cb4-857" aria-hidden="true" tabindex="-1"></a><span class="in">capt&lt;-ggdraw()+draw_label(captionText,fontface = 'italic',x=0,hjust=0,size=11)+ </span></span>
<span id="cb4-858"><a href="#cb4-858" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(plot.margin = margin(0, 0, 0, 1))</span></span>
<span id="cb4-859"><a href="#cb4-859" aria-hidden="true" tabindex="-1"></a><span class="in">  #theme(plot.margin = unit(c(0, 0, 0, 1), "cm"))</span></span>
<span id="cb4-860"><a href="#cb4-860" aria-hidden="true" tabindex="-1"></a><span class="in">plot_grid(title,e2test1,e2test2,capt,ncol=1,rel_heights=c(.18,1,1,.15))</span></span>
<span id="cb4-861"><a href="#cb4-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-862"><a href="#cb4-862" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-863"><a href="#cb4-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-864"><a href="#cb4-864" aria-hidden="true" tabindex="-1"></a>\</span>
<span id="cb4-865"><a href="#cb4-865" aria-hidden="true" tabindex="-1"></a>\</span>
<span id="cb4-866"><a href="#cb4-866" aria-hidden="true" tabindex="-1"></a>\</span>
<span id="cb4-867"><a href="#cb4-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-868"><a href="#cb4-868" aria-hidden="true" tabindex="-1"></a><span class="in">```{r e2table1, echo=FALSE }</span></span>
<span id="cb4-869"><a href="#cb4-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-870"><a href="#cb4-870" aria-hidden="true" tabindex="-1"></a><span class="in">tab2= exp2.Test %&gt;% rename(Condition="conditType") %&gt;% group_by(Condition,positionX) %&gt;%</span></span>
<span id="cb4-871"><a href="#cb4-871" aria-hidden="true" tabindex="-1"></a><span class="in">   summarise(Mean=round(mean(MeanTargetDeviance),2),sd=round(sd(MeanTargetDeviance),2),.groups="keep")</span></span>
<span id="cb4-872"><a href="#cb4-872" aria-hidden="true" tabindex="-1"></a><span class="in"> tab2=tab2 %&gt;% group_by(Condition) %&gt;% mutate(GroupAvg=round(mean(Mean),2),groupSd=round(sd(Mean),2))</span></span>
<span id="cb4-873"><a href="#cb4-873" aria-hidden="true" tabindex="-1"></a><span class="in"> tab2 = tab2 %&gt;% mutate(msd=paste(Mean,"(",sd,")",sep=""),gsd=paste(GroupAvg,"(",groupSd,")",sep="")) %&gt;% </span></span>
<span id="cb4-874"><a href="#cb4-874" aria-hidden="true" tabindex="-1"></a><span class="in">   select(positionX,Condition,msd,gsd)%&gt;%pivot_wider(names_from = Condition,values_from=c(msd,gsd))</span></span>
<span id="cb4-875"><a href="#cb4-875" aria-hidden="true" tabindex="-1"></a><span class="in"> tab2=tab2[,1:3]</span></span>
<span id="cb4-876"><a href="#cb4-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-877"><a href="#cb4-877" aria-hidden="true" tabindex="-1"></a><span class="in"> captionText="Table 2. Transfer performance from each of the 6 throwing locations from which all participants were tested. Each bar represents performance from one of seven distinct training groups (six constant groups in red, one varied group in blue). The x axis labels indicate the location(s) from which each group trained. Lower values along the y axis reflect better performance at the task (closer distance to target center). Error bars indicate standard error of the mean. "</span></span>
<span id="cb4-878"><a href="#cb4-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-879"><a href="#cb4-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-880"><a href="#cb4-880" aria-hidden="true" tabindex="-1"></a><span class="in">kable(tab2,escape=FALSE,booktabs=TRUE,col.names=c("Position","Constant","Varied"),align=c("l"))  %&gt;% kableExtra::kable_styling(position="left") %&gt;% kable_classic() %&gt;% footnote(general=captionText,general_title = "")</span></span>
<span id="cb4-881"><a href="#cb4-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-882"><a href="#cb4-882" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-883"><a href="#cb4-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-884"><a href="#cb4-884" aria-hidden="true" tabindex="-1"></a>Next, we compared the testing performance of constant and varied groups</span>
<span id="cb4-885"><a href="#cb4-885" aria-hidden="true" tabindex="-1"></a>from only positions that participants had not encountered during</span>
<span id="cb4-886"><a href="#cb4-886" aria-hidden="true" tabindex="-1"></a>training. Constant participants each had 5 novel positions, whereas</span>
<span id="cb4-887"><a href="#cb4-887" aria-hidden="true" tabindex="-1"></a>varied participants tested from 4 novel positions (400,625,675,900). We</span>
<span id="cb4-888"><a href="#cb4-888" aria-hidden="true" tabindex="-1"></a>first standardized performance within in each position, and then</span>
<span id="cb4-889"><a href="#cb4-889" aria-hidden="true" tabindex="-1"></a>averaged across positions. Here again, we found a significant effect of</span>
<span id="cb4-890"><a href="#cb4-890" aria-hidden="true" tabindex="-1"></a>condition (constant vs. varied): F(1,206)=4.30, p=.039, $\eta^{2}_G$ =</span>
<span id="cb4-891"><a href="#cb4-891" aria-hidden="true" tabindex="-1"></a>.02 .</span>
<span id="cb4-892"><a href="#cb4-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-893"><a href="#cb4-893" aria-hidden="true" tabindex="-1"></a><span class="in">```{r e2table3, echo=FALSE }</span></span>
<span id="cb4-894"><a href="#cb4-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-895"><a href="#cb4-895" aria-hidden="true" tabindex="-1"></a><span class="in">sum.novelAll &lt;- novelAll %&gt;% group_by(sbjCode,conditType,positionX) %&gt;% </span></span>
<span id="cb4-896"><a href="#cb4-896" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDev=mean(AbsDistFromCenter,trim=.05),MeanScaledDev=mean(scaledDev,trim=.05),.groups="keep") %&gt;% as.data.frame()</span></span>
<span id="cb4-897"><a href="#cb4-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-898"><a href="#cb4-898" aria-hidden="true" tabindex="-1"></a><span class="in">tab3=sum.novelAll %&gt;% rename(Condition="conditType") %&gt;% group_by(Condition,positionX) %&gt;%</span></span>
<span id="cb4-899"><a href="#cb4-899" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(Mean=round(mean(MeanTargetDev),2),sd=round(sd(MeanTargetDev),2),.groups="keep")</span></span>
<span id="cb4-900"><a href="#cb4-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-901"><a href="#cb4-901" aria-hidden="true" tabindex="-1"></a><span class="in"> tab3=tab3 %&gt;% group_by(Condition) %&gt;% mutate(GroupAvg=round(mean(Mean),2),groupSd=round(sd(Mean),2))</span></span>
<span id="cb4-902"><a href="#cb4-902" aria-hidden="true" tabindex="-1"></a><span class="in"> </span></span>
<span id="cb4-903"><a href="#cb4-903" aria-hidden="true" tabindex="-1"></a><span class="in"> tab3 = tab3 %&gt;% </span></span>
<span id="cb4-904"><a href="#cb4-904" aria-hidden="true" tabindex="-1"></a><span class="in">   mutate(msd=paste(Mean,"(",sd,")",sep=""),gsd=paste(GroupAvg,"(",groupSd,")",sep="")) %&gt;% select(positionX,Condition,msd,gsd)%&gt;%pivot_wider(names_from = Condition,values_from=c(msd,gsd))</span></span>
<span id="cb4-905"><a href="#cb4-905" aria-hidden="true" tabindex="-1"></a><span class="in"> tab3=tab3[,1:3]</span></span>
<span id="cb4-906"><a href="#cb4-906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-907"><a href="#cb4-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-908"><a href="#cb4-908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-909"><a href="#cb4-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-910"><a href="#cb4-910" aria-hidden="true" tabindex="-1"></a><span class="in"> captionText="Table 3. Testing performance from novel positions. Includes data only from positions that were not encountered during the training stage (e.g. excludes positions 500 and 800 for the varied group, and one of the six locations for each of the constant groups). Table presents Mean absolute deviations from the center of the target, and standard deviations in parenthesis. "</span></span>
<span id="cb4-911"><a href="#cb4-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-912"><a href="#cb4-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-913"><a href="#cb4-913" aria-hidden="true" tabindex="-1"></a><span class="in">kable(tab3,escape=FALSE,booktabs=TRUE,col.names=c("Position","Constant","Varied"),align=c("l"))  %&gt;% kableExtra::kable_styling(position="left") %&gt;% kable_classic() %&gt;% footnote(general=captionText,general_title = "")</span></span>
<span id="cb4-914"><a href="#cb4-914" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-915"><a href="#cb4-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-916"><a href="#cb4-916" aria-hidden="true" tabindex="-1"></a>Finally, corresponding to the comparison of position 760 from experiment</span>
<span id="cb4-917"><a href="#cb4-917" aria-hidden="true" tabindex="-1"></a>1, we compared the test performance of the varied group against the</span>
<span id="cb4-918"><a href="#cb4-918" aria-hidden="true" tabindex="-1"></a>constant group from only the positions that the constant groups trained.</span>
<span id="cb4-919"><a href="#cb4-919" aria-hidden="true" tabindex="-1"></a>Such positions were novel to the varied group (thus this analysis</span>
<span id="cb4-920"><a href="#cb4-920" aria-hidden="true" tabindex="-1"></a>omitted two constant groups that trained from positions 500 or 800 as</span>
<span id="cb4-921"><a href="#cb4-921" aria-hidden="true" tabindex="-1"></a>those positions were not novel to the varied group). Figure 7 displays</span>
<span id="cb4-922"><a href="#cb4-922" aria-hidden="true" tabindex="-1"></a>the particular subset of comparisons utilized for this analysis. Again,</span>
<span id="cb4-923"><a href="#cb4-923" aria-hidden="true" tabindex="-1"></a>we standardized performance within each position before performing the</span>
<span id="cb4-924"><a href="#cb4-924" aria-hidden="true" tabindex="-1"></a>analyses on the aggregated data. In this case, the effect of condition</span>
<span id="cb4-925"><a href="#cb4-925" aria-hidden="true" tabindex="-1"></a>did not reach statistical significance F(1,149)=3.14, p=.079,</span>
<span id="cb4-926"><a href="#cb4-926" aria-hidden="true" tabindex="-1"></a>$\eta^{2}_G$ = .02. Table 4 provides descriptive statistics.</span>
<span id="cb4-927"><a href="#cb4-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-928"><a href="#cb4-928" aria-hidden="true" tabindex="-1"></a><span class="in">```{r e2test2, echo=FALSE,fig.height=6.0, fig.width=7, warning=FALSE}</span></span>
<span id="cb4-929"><a href="#cb4-929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-930"><a href="#cb4-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-931"><a href="#cb4-931" aria-hidden="true" tabindex="-1"></a><span class="in">sum.variedVsNovelIden &lt;- variedVsNovelIden  %&gt;%</span></span>
<span id="cb4-932"><a href="#cb4-932" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(sbjCode,conditType,positionX) %&gt;% </span></span>
<span id="cb4-933"><a href="#cb4-933" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(MeanTargetDev=mean(AbsDistFromCenter,trim=.05),MeanScaledDev=mean(scaledDev,trim=.05),.groups="keep") %&gt;% as.data.frame()</span></span>
<span id="cb4-934"><a href="#cb4-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-935"><a href="#cb4-935" aria-hidden="true" tabindex="-1"></a><span class="in">e2Test2 &lt;- sum.variedVsNovelIden %&gt;% ggplot(aes(x=positionX,y=MeanTargetDev,group=conditType,fill=conditType))+geom_bar(stat="summary",position=dodge,fun="mean")+ stat_summary(fun.data=mean_se,geom="errorbar",position=dodge,width=.5)+ylab("Mean Distance From Center Of Target") +xlab("Testing Location")+theme(plot.title = element_text(hjust = 0.5))+guides(fill=guide_legend(title="Training Condition"))+theme(legend.title.align=.25)</span></span>
<span id="cb4-936"><a href="#cb4-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-937"><a href="#cb4-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-938"><a href="#cb4-938" aria-hidden="true" tabindex="-1"></a><span class="in">gtitle="Figure 7"</span></span>
<span id="cb4-939"><a href="#cb4-939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-940"><a href="#cb4-940" aria-hidden="true" tabindex="-1"></a><span class="in">title = ggdraw()+draw_label(gtitle,fontface = 'bold',y=Inf, x=0,hjust=0,vjust=5.5,size=11)+theme(plot.margin = margin(0, 0, 0, 0))</span></span>
<span id="cb4-941"><a href="#cb4-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-942"><a href="#cb4-942" aria-hidden="true" tabindex="-1"></a><span class="in">captionText=str_wrap("A comparison of throwing location that are identical to those trained by the constant participants (e.g. constant participants trained at position 900, tested from position 900), which are also novel to the varied-trained participants (thus excluding positions 500 and 800). Error bars indicate standard error of the mean. ",145)</span></span>
<span id="cb4-943"><a href="#cb4-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-944"><a href="#cb4-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-945"><a href="#cb4-945" aria-hidden="true" tabindex="-1"></a><span class="in">capt&lt;-ggdraw()+draw_label(captionText,fontface = 'italic',x=0,hjust=0,size=11)+ </span></span>
<span id="cb4-946"><a href="#cb4-946" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(plot.margin = margin(0, 0, 0, 1))</span></span>
<span id="cb4-947"><a href="#cb4-947" aria-hidden="true" tabindex="-1"></a><span class="in">  #theme(plot.margin = unit(c(0, 0, 0, 1), "cm"))</span></span>
<span id="cb4-948"><a href="#cb4-948" aria-hidden="true" tabindex="-1"></a><span class="in">plot_grid(title,e2Test2,capt,ncol=1,rel_heights=c(.18,1,.15))</span></span>
<span id="cb4-949"><a href="#cb4-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-950"><a href="#cb4-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-951"><a href="#cb4-951" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-952"><a href="#cb4-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-953"><a href="#cb4-953" aria-hidden="true" tabindex="-1"></a>\</span>
<span id="cb4-954"><a href="#cb4-954" aria-hidden="true" tabindex="-1"></a>\</span>
<span id="cb4-955"><a href="#cb4-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-956"><a href="#cb4-956" aria-hidden="true" tabindex="-1"></a><span class="in">```{r e2tab3,echo=FALSE, warning=FALSE}</span></span>
<span id="cb4-957"><a href="#cb4-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-958"><a href="#cb4-958" aria-hidden="true" tabindex="-1"></a><span class="in">tab4=sum.variedVsNovelIden %&gt;% rename(Condition="conditType") %&gt;% group_by(Condition,positionX) %&gt;%</span></span>
<span id="cb4-959"><a href="#cb4-959" aria-hidden="true" tabindex="-1"></a><span class="in">  summarise(Mean=round(mean(MeanTargetDev),2),sd=round(sd(MeanTargetDev),2),.groups="keep")</span></span>
<span id="cb4-960"><a href="#cb4-960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-961"><a href="#cb4-961" aria-hidden="true" tabindex="-1"></a><span class="in"> tab4=tab4 %&gt;% group_by(Condition) %&gt;% </span></span>
<span id="cb4-962"><a href="#cb4-962" aria-hidden="true" tabindex="-1"></a><span class="in">   mutate(GroupAvg=round(mean(Mean),2),groupSd=round(sd(Mean),2))</span></span>
<span id="cb4-963"><a href="#cb4-963" aria-hidden="true" tabindex="-1"></a><span class="in">tab4 = tab4 %&gt;% mutate(msd=paste(Mean,"(",sd,")",sep=""),gsd=paste(GroupAvg,"(",groupSd,")",sep="")) %&gt;% </span></span>
<span id="cb4-964"><a href="#cb4-964" aria-hidden="true" tabindex="-1"></a><span class="in">   select(positionX,Condition,msd,gsd)%&gt;%pivot_wider(names_from = Condition,values_from=c(msd,gsd))</span></span>
<span id="cb4-965"><a href="#cb4-965" aria-hidden="true" tabindex="-1"></a><span class="in"> tab4=tab4[,1:3]</span></span>
<span id="cb4-966"><a href="#cb4-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-967"><a href="#cb4-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-968"><a href="#cb4-968" aria-hidden="true" tabindex="-1"></a><span class="in"> captionText="Table 5. Testing performance from the locations trained by constant participants and novel to varied participants. Locations 500 and 800 are not included as these were trained by the varied participants. Table presents Mean absolute deviation from the center of the target, and standard deviations in parenthesis. "</span></span>
<span id="cb4-969"><a href="#cb4-969" aria-hidden="true" tabindex="-1"></a><span class="in"> </span></span>
<span id="cb4-970"><a href="#cb4-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-971"><a href="#cb4-971" aria-hidden="true" tabindex="-1"></a><span class="in">kable(tab4,escape=FALSE,booktabs=TRUE,col.names=c("Position","Constant","Varied"),align=c("l"))  %&gt;% kableExtra::kable_styling(position="left") %&gt;% kable_classic() %&gt;% footnote(general=captionText,general_title = "")</span></span>
<span id="cb4-972"><a href="#cb4-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-973"><a href="#cb4-973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-974"><a href="#cb4-974" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-975"><a href="#cb4-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-976"><a href="#cb4-976" aria-hidden="true" tabindex="-1"></a><span class="fu">## Discussion</span></span>
<span id="cb4-977"><a href="#cb4-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-978"><a href="#cb4-978" aria-hidden="true" tabindex="-1"></a>The results of experiment 2 largely conform to the findings of</span>
<span id="cb4-979"><a href="#cb4-979" aria-hidden="true" tabindex="-1"></a>experiment 1. Participants in both varied and constant conditions</span>
<span id="cb4-980"><a href="#cb4-980" aria-hidden="true" tabindex="-1"></a>improved at the task during the training phase. We did not observe the</span>
<span id="cb4-981"><a href="#cb4-981" aria-hidden="true" tabindex="-1"></a>common finding of training under varied conditions producing worse</span>
<span id="cb4-982"><a href="#cb4-982" aria-hidden="true" tabindex="-1"></a>performance during acquisition than training under constant conditions <span class="co">[</span><span class="ot">@catalanoDistantTransferCoincident1984a; @wrisbergVariabilityPracticeHypothesis1987</span><span class="co">]</span>, which has been</span>
<span id="cb4-983"><a href="#cb4-983" aria-hidden="true" tabindex="-1"></a>suggested to relate to the subsequent benefits of varied training in</span>
<span id="cb4-984"><a href="#cb4-984" aria-hidden="true" tabindex="-1"></a>retention and generalization testing <span class="co">[</span><span class="ot">@soderstromLearningPerformanceIntegrative2015</span><span class="co">]</span>. However</span>
<span id="cb4-985"><a href="#cb4-985" aria-hidden="true" tabindex="-1"></a>our finding of no difference in training performance between constant</span>
<span id="cb4-986"><a href="#cb4-986" aria-hidden="true" tabindex="-1"></a>and varied groups has been observed in previous work <span class="co">[</span><span class="ot">@chuaPracticeVariabilityPromotes2019; @moxleySchemaVariabilityPractice1979; @pigottMotorSchemaStructure1984</span><span class="co">]</span>.</span>
<span id="cb4-987"><a href="#cb4-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-988"><a href="#cb4-988" aria-hidden="true" tabindex="-1"></a>In the testing phase, our varied group significantly outperformed the</span>
<span id="cb4-989"><a href="#cb4-989" aria-hidden="true" tabindex="-1"></a>constant conditions in both a general comparison, and in an analysis</span>
<span id="cb4-990"><a href="#cb4-990" aria-hidden="true" tabindex="-1"></a>limited to novel throwing positions. The observed benefit of varied over</span>
<span id="cb4-991"><a href="#cb4-991" aria-hidden="true" tabindex="-1"></a>constant training echoes the findings of many previous visuomotor skill</span>
<span id="cb4-992"><a href="#cb4-992" aria-hidden="true" tabindex="-1"></a>learning studies that have continued to emerge since the introduction of</span>
<span id="cb4-993"><a href="#cb4-993" aria-hidden="true" tabindex="-1"></a>Schmidt's influential Schema Theory <span class="co">[</span><span class="ot">@catalanoDistantTransferCoincident1984a; @chuaPracticeVariabilityPromotes2019; @goodwinEffectDifferentQuantities1998; @mccrackenTestSchemaTheory1977; @moxleySchemaVariabilityPractice1979; @newellVariabilityPracticeTransfer1976; @pigottMotorSchemaStructure1984; @rollerVariablePracticeLenses2001; @schmidtSchemaTheoryDiscrete1975; @willeyLongtermMotorLearning2018; @wrisbergVariabilityPracticeHypothesis1987; @wulfEffectTypePractice1991</span><span class="co">]</span>. We also join a much smaller set of research to observe this</span>
<span id="cb4-994"><a href="#cb4-994" aria-hidden="true" tabindex="-1"></a>pattern in a computerized task <span class="co">[</span><span class="ot">@seowTransferEffectsVaried2019</span><span class="co">]</span>. One departure from</span>
<span id="cb4-995"><a href="#cb4-995" aria-hidden="true" tabindex="-1"></a>the experiment 1 findings concerns the pattern wherein the varied group</span>
<span id="cb4-996"><a href="#cb4-996" aria-hidden="true" tabindex="-1"></a>outperformed the constant group even from the training position of the</span>
<span id="cb4-997"><a href="#cb4-997" aria-hidden="true" tabindex="-1"></a>constant group, which was significant in experiment 1, but did not reach</span>
<span id="cb4-998"><a href="#cb4-998" aria-hidden="true" tabindex="-1"></a>significance in experiment 2. Although this pattern has been observed</span>
<span id="cb4-999"><a href="#cb4-999" aria-hidden="true" tabindex="-1"></a>elsewhere in the literature <span class="co">[</span><span class="ot">@goodeSuperiorityVariableRepeated2008; @kerrSpecificVariedPractice1978</span><span class="co">]</span>, </span>
<span id="cb4-1000"><a href="#cb4-1000" aria-hidden="true" tabindex="-1"></a>the overall evidence for this effect appears to be far weaker than for</span>
<span id="cb4-1001"><a href="#cb4-1001" aria-hidden="true" tabindex="-1"></a>the more general benefit of varied training in conditions novel to all</span>
<span id="cb4-1002"><a href="#cb4-1002" aria-hidden="true" tabindex="-1"></a>training groups.</span>
<span id="cb4-1003"><a href="#cb4-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1004"><a href="#cb4-1004" aria-hidden="true" tabindex="-1"></a><span class="fu"># Computational Model</span></span>
<span id="cb4-1005"><a href="#cb4-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1006"><a href="#cb4-1006" aria-hidden="true" tabindex="-1"></a>Controlling for the similarity between training and testing The primary</span>
<span id="cb4-1007"><a href="#cb4-1007" aria-hidden="true" tabindex="-1"></a>goal of Experiment 2 was to examine whether the benefits of variability</span>
<span id="cb4-1008"><a href="#cb4-1008" aria-hidden="true" tabindex="-1"></a>would persist after accounting for individual differences in the</span>
<span id="cb4-1009"><a href="#cb4-1009" aria-hidden="true" tabindex="-1"></a>similarity between trained and tested throwing locations. To this end,</span>
<span id="cb4-1010"><a href="#cb4-1010" aria-hidden="true" tabindex="-1"></a>we modelled each throw as a two-dimensional point in the space of x and</span>
<span id="cb4-1011"><a href="#cb4-1011" aria-hidden="true" tabindex="-1"></a>y velocities applied to the projectile at the moment of release. For</span>
<span id="cb4-1012"><a href="#cb4-1012" aria-hidden="true" tabindex="-1"></a>each participant, we took each individual training throw, and computed</span>
<span id="cb4-1013"><a href="#cb4-1013" aria-hidden="true" tabindex="-1"></a>the similarity between that throw and the entire population of throws</span>
<span id="cb4-1014"><a href="#cb4-1014" aria-hidden="true" tabindex="-1"></a>within the solution space for each of the 6 testing positions. We</span>
<span id="cb4-1015"><a href="#cb4-1015" aria-hidden="true" tabindex="-1"></a>defined the solution space empirically as the set of all combinations of</span>
<span id="cb4-1016"><a href="#cb4-1016" aria-hidden="true" tabindex="-1"></a>x and y throw velocities that resulted in hitting the target. We then</span>
<span id="cb4-1017"><a href="#cb4-1017" aria-hidden="true" tabindex="-1"></a>summed each of the trial-level similarities to produce a single</span>
<span id="cb4-1018"><a href="#cb4-1018" aria-hidden="true" tabindex="-1"></a>similarity for each testing position score relating how the participant</span>
<span id="cb4-1019"><a href="#cb4-1019" aria-hidden="true" tabindex="-1"></a>threw the ball during training and the solutions that would result in</span>
<span id="cb4-1020"><a href="#cb4-1020" aria-hidden="true" tabindex="-1"></a>target hits from each of the six testing positions -- thus resulting in</span>
<span id="cb4-1021"><a href="#cb4-1021" aria-hidden="true" tabindex="-1"></a>six separate similarity scores for each participant. Figure 8a</span>
<span id="cb4-1022"><a href="#cb4-1022" aria-hidden="true" tabindex="-1"></a>visualizes the solution space for each location and illustrates how</span>
<span id="cb4-1023"><a href="#cb4-1023" aria-hidden="true" tabindex="-1"></a>different combinations of x and y velocity result in successfully</span>
<span id="cb4-1024"><a href="#cb4-1024" aria-hidden="true" tabindex="-1"></a>striking the target from different launching positions. As illustrated</span>
<span id="cb4-1025"><a href="#cb4-1025" aria-hidden="true" tabindex="-1"></a>in Figure 8b, the solution throws represent just a small fraction of the</span>
<span id="cb4-1026"><a href="#cb4-1026" aria-hidden="true" tabindex="-1"></a>entire space of velocity combinations used by participants throughout</span>
<span id="cb4-1027"><a href="#cb4-1027" aria-hidden="true" tabindex="-1"></a>the experiment.</span>
<span id="cb4-1028"><a href="#cb4-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1029"><a href="#cb4-1029" aria-hidden="true" tabindex="-1"></a>(ref:taskSpace) Figure 8a is a visual representation of the combinations</span>
<span id="cb4-1030"><a href="#cb4-1030" aria-hidden="true" tabindex="-1"></a>of throw parameters (x and y velocities applied to the ball at launch),</span>
<span id="cb4-1031"><a href="#cb4-1031" aria-hidden="true" tabindex="-1"></a>which resulted in target hits during the testing phase. This empirical</span>
<span id="cb4-1032"><a href="#cb4-1032" aria-hidden="true" tabindex="-1"></a>solution space was compiled from all of the participants in experiment</span>
<span id="cb4-1033"><a href="#cb4-1033" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Figure 8b shows the solution space within the context of all of the</span>
<span id="cb4-1034"><a href="#cb4-1034" aria-hidden="true" tabindex="-1"></a>throws made throughout the testing phase of the experiment.</span>
<span id="cb4-1035"><a href="#cb4-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1036"><a href="#cb4-1036" aria-hidden="true" tabindex="-1"></a><span class="in">```{r taskSpace, echo=FALSE,fig.height=9.0, fig.width=10}</span></span>
<span id="cb4-1037"><a href="#cb4-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1038"><a href="#cb4-1038" aria-hidden="true" tabindex="-1"></a><span class="in">library("RColorBrewer")</span></span>
<span id="cb4-1039"><a href="#cb4-1039" aria-hidden="true" tabindex="-1"></a><span class="in">taskspace &lt;- e2 %&gt;% filter(AbsDistFromCenter&lt;900)</span></span>
<span id="cb4-1040"><a href="#cb4-1040" aria-hidden="true" tabindex="-1"></a><span class="in">taskspace$hitOrMiss &lt;- ifelse(taskspace$trialType==11,"Hit Target","Missed Target")</span></span>
<span id="cb4-1041"><a href="#cb4-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1042"><a href="#cb4-1042" aria-hidden="true" tabindex="-1"></a><span class="in">solSpace &lt;- e2 %&gt;% filter(trialType==11)</span></span>
<span id="cb4-1043"><a href="#cb4-1043" aria-hidden="true" tabindex="-1"></a><span class="in">#solSpace %&gt;% ggplot(aes(x=X_Velocity,y=Y_Velocity)) + geom_point(aes(colour=ThrowPosition),alpha=0.58) + ggtitle("") </span></span>
<span id="cb4-1044"><a href="#cb4-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1045"><a href="#cb4-1045" aria-hidden="true" tabindex="-1"></a><span class="in">solSpace$Result = ifelse(solSpace$ThrowPosition==400,"400",solSpace$ThrowPosition)</span></span>
<span id="cb4-1046"><a href="#cb4-1046" aria-hidden="true" tabindex="-1"></a><span class="in">solSpace$Result = ifelse(solSpace$ThrowPosition==500,"500",solSpace$Result)</span></span>
<span id="cb4-1047"><a href="#cb4-1047" aria-hidden="true" tabindex="-1"></a><span class="in">solSpace$Result= ifelse(solSpace$ThrowPosition==625,"625",solSpace$Result)</span></span>
<span id="cb4-1048"><a href="#cb4-1048" aria-hidden="true" tabindex="-1"></a><span class="in">solSpace$Result = ifelse(solSpace$ThrowPosition==675,"675",solSpace$Result)</span></span>
<span id="cb4-1049"><a href="#cb4-1049" aria-hidden="true" tabindex="-1"></a><span class="in">solSpace$Result = ifelse(solSpace$ThrowPosition==800,"800",solSpace$Result)</span></span>
<span id="cb4-1050"><a href="#cb4-1050" aria-hidden="true" tabindex="-1"></a><span class="in">solSpace$Result = ifelse(solSpace$ThrowPosition==900,"900",solSpace$Result)</span></span>
<span id="cb4-1051"><a href="#cb4-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1052"><a href="#cb4-1052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1053"><a href="#cb4-1053" aria-hidden="true" tabindex="-1"></a><span class="in">missSpace &lt;- e2 %&gt;% filter(trialType !=11)</span></span>
<span id="cb4-1054"><a href="#cb4-1054" aria-hidden="true" tabindex="-1"></a><span class="in">missSpace$Result = "Missed Target"</span></span>
<span id="cb4-1055"><a href="#cb4-1055" aria-hidden="true" tabindex="-1"></a><span class="in">solSpace$Result &lt;- solSpace$Result</span></span>
<span id="cb4-1056"><a href="#cb4-1056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1057"><a href="#cb4-1057" aria-hidden="true" tabindex="-1"></a><span class="in"># the usual method of changing the legend title does not seem to work after the colours are manually scaled. </span></span>
<span id="cb4-1058"><a href="#cb4-1058" aria-hidden="true" tabindex="-1"></a><span class="in"># multiplied velocoties by -1 to make the axes less confusing</span></span>
<span id="cb4-1059"><a href="#cb4-1059" aria-hidden="true" tabindex="-1"></a><span class="in">ss=solSpace %&gt;% ggplot(aes(x=X_Velocity*-1,y=Y_Velocity*-1)) + </span></span>
<span id="cb4-1060"><a href="#cb4-1060" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point(aes(colour=Result),alpha=0.6) + </span></span>
<span id="cb4-1061"><a href="#cb4-1061" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_color_manual(values =brewer.pal(n=6,name="Set1"))+</span></span>
<span id="cb4-1062"><a href="#cb4-1062" aria-hidden="true" tabindex="-1"></a><span class="in">  labs(colour="Target Hit Thrown from Position:") + xlab("X Release Velocity") + ylab("Y Release Velocity")+ggtitle("A")</span></span>
<span id="cb4-1063"><a href="#cb4-1063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1064"><a href="#cb4-1064" aria-hidden="true" tabindex="-1"></a><span class="in">fullSpace &lt;- rbind(missSpace,solSpace)</span></span>
<span id="cb4-1065"><a href="#cb4-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1066"><a href="#cb4-1066" aria-hidden="true" tabindex="-1"></a><span class="in">fs&lt;- fullSpace %&gt;% ggplot(aes(x=X_Velocity*-1,y=Y_Velocity*-1,colour=Result)) + </span></span>
<span id="cb4-1067"><a href="#cb4-1067" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point(aes(),alpha=0.6) + scale_color_manual(values =brewer.pal(n=7,name="Set1"))+</span></span>
<span id="cb4-1068"><a href="#cb4-1068" aria-hidden="true" tabindex="-1"></a><span class="in">  labs(colour="Target Hit or Miss From Position:") + xlab("X Release Velocity") + ylab("Y Release Velocity") +ggtitle("B")</span></span>
<span id="cb4-1069"><a href="#cb4-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1070"><a href="#cb4-1070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1071"><a href="#cb4-1071" aria-hidden="true" tabindex="-1"></a><span class="in">gtitle="Figure 8"</span></span>
<span id="cb4-1072"><a href="#cb4-1072" aria-hidden="true" tabindex="-1"></a><span class="in">title = ggdraw()+draw_label(gtitle,fontface = 'bold',y=Inf, x=0,hjust=0,vjust=5.5,size=11)+theme(plot.margin = margin(0, 0, 0, 0))</span></span>
<span id="cb4-1073"><a href="#cb4-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1074"><a href="#cb4-1074" aria-hidden="true" tabindex="-1"></a><span class="in">captionText=str_wrap("Figure 8A is a visual representation of the combinations of throw parameters (x and y velocities applied to the ball at launch), which resulted in target hits during the testing phase. This empirical solution space was compiled from all of the participants in experiment 2. Figure 8B shows the solution space within the context of all of the throws made throughout the testing phase of the experiment.",145)</span></span>
<span id="cb4-1075"><a href="#cb4-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1076"><a href="#cb4-1076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1077"><a href="#cb4-1077" aria-hidden="true" tabindex="-1"></a><span class="in">capt&lt;-ggdraw()+draw_label(captionText,fontface = 'italic',x=0,hjust=0,size=11)+ </span></span>
<span id="cb4-1078"><a href="#cb4-1078" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(plot.margin = margin(0, 0, 0, 1))</span></span>
<span id="cb4-1079"><a href="#cb4-1079" aria-hidden="true" tabindex="-1"></a><span class="in">  #theme(plot.margin = unit(c(0, 0, 0, 1), "cm"))</span></span>
<span id="cb4-1080"><a href="#cb4-1080" aria-hidden="true" tabindex="-1"></a><span class="in">plot_grid(title,ss,fs,capt,ncol=1,rel_heights=c(.18,1,1,.15))</span></span>
<span id="cb4-1081"><a href="#cb4-1081" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-1082"><a href="#cb4-1082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1083"><a href="#cb4-1083" aria-hidden="true" tabindex="-1"></a>For each individual trial, the Euclidean distance (Equation 1) was</span>
<span id="cb4-1084"><a href="#cb4-1084" aria-hidden="true" tabindex="-1"></a>computed between the velocity components (x and y) of that trial and the</span>
<span id="cb4-1085"><a href="#cb4-1085" aria-hidden="true" tabindex="-1"></a>velocity components of each individual solution throw for each of the 6</span>
<span id="cb4-1086"><a href="#cb4-1086" aria-hidden="true" tabindex="-1"></a>positions from which participants would be tested in the final phase of</span>
<span id="cb4-1087"><a href="#cb4-1087" aria-hidden="true" tabindex="-1"></a>the study. The P parameter in Equation 1 is set equal to 2, reflecting a</span>
<span id="cb4-1088"><a href="#cb4-1088" aria-hidden="true" tabindex="-1"></a>Gaussian similarity gradient. Then, as per an instance-based model of</span>
<span id="cb4-1089"><a href="#cb4-1089" aria-hidden="true" tabindex="-1"></a>similarity <span class="co">[</span><span class="ot">@loganInstanceTheoryAttention2002a; @nosofskySimilarityScalingCognitive1992</span><span class="co">]</span>, these distances were</span>
<span id="cb4-1090"><a href="#cb4-1090" aria-hidden="true" tabindex="-1"></a>multiplied by a sensitivity parameter, c, and then exponentiated to</span>
<span id="cb4-1091"><a href="#cb4-1091" aria-hidden="true" tabindex="-1"></a>yield a similarity value. The parameter c controls the rate with which</span>
<span id="cb4-1092"><a href="#cb4-1092" aria-hidden="true" tabindex="-1"></a>similarity-based generalization drops off as the Euclidean distance</span>
<span id="cb4-1093"><a href="#cb4-1093" aria-hidden="true" tabindex="-1"></a>between two throws in x- and y-velocity space increases. If c has a</span>
<span id="cb4-1094"><a href="#cb4-1094" aria-hidden="true" tabindex="-1"></a>large value, then even a small difference between two throws' velocities</span>
<span id="cb4-1095"><a href="#cb4-1095" aria-hidden="true" tabindex="-1"></a>greatly decreases the extent of generalization from one to the other. A</span>
<span id="cb4-1096"><a href="#cb4-1096" aria-hidden="true" tabindex="-1"></a>small value for c produces broad generalization from one throw to</span>
<span id="cb4-1097"><a href="#cb4-1097" aria-hidden="true" tabindex="-1"></a>another despite relatively large differences in their velocities. The</span>
<span id="cb4-1098"><a href="#cb4-1098" aria-hidden="true" tabindex="-1"></a>similarity values for each training individual throw made by a given</span>
<span id="cb4-1099"><a href="#cb4-1099" aria-hidden="true" tabindex="-1"></a>participant were then summed to yield a final similarity score, with a</span>
<span id="cb4-1100"><a href="#cb4-1100" aria-hidden="true" tabindex="-1"></a>separate score computed for each of the 6 testing positions. The final</span>
<span id="cb4-1101"><a href="#cb4-1101" aria-hidden="true" tabindex="-1"></a>similarity score is construable as index of how accurate the throws a</span>
<span id="cb4-1102"><a href="#cb4-1102" aria-hidden="true" tabindex="-1"></a>participant made during the training phase would be for each of the</span>
<span id="cb4-1103"><a href="#cb4-1103" aria-hidden="true" tabindex="-1"></a>testing positions.</span>
<span id="cb4-1104"><a href="#cb4-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1105"><a href="#cb4-1105" aria-hidden="true" tabindex="-1"></a>**Equation 1:** <span class="sc">\[</span> Similarity<span class="sc">\_</span>{I,J} = \sum*{i = I}*\sum{j=J}</span>
<span id="cb4-1106"><a href="#cb4-1106" aria-hidden="true" tabindex="-1"></a>e^{-c^\cdot dp<span class="sc">\_</span>{i,j}} <span class="sc">\]</span></span>
<span id="cb4-1107"><a href="#cb4-1107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1108"><a href="#cb4-1108" aria-hidden="true" tabindex="-1"></a>**Equation 2:**</span>
<span id="cb4-1109"><a href="#cb4-1109" aria-hidden="true" tabindex="-1"></a>$$ d_{i,j} = \sqrt{(x_{Train_i}-x_{Solution_j})^2 + (y_{Train_i}-y_{Solution_j})^2 } $$</span>
<span id="cb4-1110"><a href="#cb4-1110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1111"><a href="#cb4-1111" aria-hidden="true" tabindex="-1"></a>A simple linear regression revealed that these similarity scores were</span>
<span id="cb4-1112"><a href="#cb4-1112" aria-hidden="true" tabindex="-1"></a>significantly predictive of performance in the transfer stage, t</span>
<span id="cb4-1113"><a href="#cb4-1113" aria-hidden="true" tabindex="-1"></a>=-15.88, p<span class="sc">\&lt;</span>.01, $r^2$=.17, such that greater similarity between</span>
<span id="cb4-1114"><a href="#cb4-1114" aria-hidden="true" tabindex="-1"></a>training throws and solution spaces for each of the test locations</span>
<span id="cb4-1115"><a href="#cb4-1115" aria-hidden="true" tabindex="-1"></a>resulted in better performance. We then repeated the group comparisons</span>
<span id="cb4-1116"><a href="#cb4-1116" aria-hidden="true" tabindex="-1"></a>above while including similarity as a covariate in the model. Comparing</span>
<span id="cb4-1117"><a href="#cb4-1117" aria-hidden="true" tabindex="-1"></a>the varied and constant groups in testing performance from all testing</span>
<span id="cb4-1118"><a href="#cb4-1118" aria-hidden="true" tabindex="-1"></a>positions yielded a significant effect of similarity, F(1, 205)=85.66,</span>
<span id="cb4-1119"><a href="#cb4-1119" aria-hidden="true" tabindex="-1"></a>p<span class="sc">\&lt;</span>.001, $\eta^{2}_G$ =.29, and also a significant effect of condition</span>
<span id="cb4-1120"><a href="#cb4-1120" aria-hidden="true" tabindex="-1"></a>(varied vs. constant), F(1, 205)=6.03, p=.015, $\eta^{2}_G$ =.03. The</span>
<span id="cb4-1121"><a href="#cb4-1121" aria-hidden="true" tabindex="-1"></a>group comparison limited to only novel locations for the varied group</span>
<span id="cb4-1122"><a href="#cb4-1122" aria-hidden="true" tabindex="-1"></a>pit against trained location for the constant group resulted in a</span>
<span id="cb4-1123"><a href="#cb4-1123" aria-hidden="true" tabindex="-1"></a>significant effect of similarity, F(1,148)=31.12, p<span class="sc">\&lt;</span>.001, $\eta^{2}_G$</span>
<span id="cb4-1124"><a href="#cb4-1124" aria-hidden="true" tabindex="-1"></a>=.18 as well as for condition F(1,148)=11.55, p<span class="sc">\&lt;</span>.001, $\eta^{2}_G$</span>
<span id="cb4-1125"><a href="#cb4-1125" aria-hidden="true" tabindex="-1"></a>=.07. For all comparisons, the pattern of results was consistent with</span>
<span id="cb4-1126"><a href="#cb4-1126" aria-hidden="true" tabindex="-1"></a>the initial findings from experiment 2, with the varied group still</span>
<span id="cb4-1127"><a href="#cb4-1127" aria-hidden="true" tabindex="-1"></a>performing significantly better than the constant group.</span>
<span id="cb4-1128"><a href="#cb4-1128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1129"><a href="#cb4-1129" aria-hidden="true" tabindex="-1"></a><span class="fu">## Fitting model parameters separately by group</span></span>
<span id="cb4-1130"><a href="#cb4-1130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1131"><a href="#cb4-1131" aria-hidden="true" tabindex="-1"></a>To directly control for similarity in Experiment 2, we developed a</span>
<span id="cb4-1132"><a href="#cb4-1132" aria-hidden="true" tabindex="-1"></a>model-based measure of the similarity between training throws and</span>
<span id="cb4-1133"><a href="#cb4-1133" aria-hidden="true" tabindex="-1"></a>testing conditions. This similarity measure was a significant predictor</span>
<span id="cb4-1134"><a href="#cb4-1134" aria-hidden="true" tabindex="-1"></a>of testing performance, e.g., participants whose training throws were</span>
<span id="cb4-1135"><a href="#cb4-1135" aria-hidden="true" tabindex="-1"></a>more similar to throws that resulted in target hits from the testing</span>
<span id="cb4-1136"><a href="#cb4-1136" aria-hidden="true" tabindex="-1"></a>positions, tended to perform better during the testing phase.</span>
<span id="cb4-1137"><a href="#cb4-1137" aria-hidden="true" tabindex="-1"></a>Importantly, the similarity measure did not explain away the group-level</span>
<span id="cb4-1138"><a href="#cb4-1138" aria-hidden="true" tabindex="-1"></a>benefits of varied training, which remained significant in our linear</span>
<span id="cb4-1139"><a href="#cb4-1139" aria-hidden="true" tabindex="-1"></a>model predicting testing performance after similarity was added to the</span>
<span id="cb4-1140"><a href="#cb4-1140" aria-hidden="true" tabindex="-1"></a>model. However, previous research has suggested that participants may</span>
<span id="cb4-1141"><a href="#cb4-1141" aria-hidden="true" tabindex="-1"></a>differ in their level of generalization as a function of prior</span>
<span id="cb4-1142"><a href="#cb4-1142" aria-hidden="true" tabindex="-1"></a>experience, and that such differences in generalization gradients can be</span>
<span id="cb4-1143"><a href="#cb4-1143" aria-hidden="true" tabindex="-1"></a>captured by fitting the generalization parameter of an instance-based</span>
<span id="cb4-1144"><a href="#cb4-1144" aria-hidden="true" tabindex="-1"></a>model separately to each group <span class="co">[</span><span class="ot">@hahnEffectsCategoryDiversity2005; @lambertsFlexibleTuningSimilarity1994</span><span class="co">]</span>.</span>
<span id="cb4-1145"><a href="#cb4-1145" aria-hidden="true" tabindex="-1"></a>Relatedly, the influential Bayesian generalization model developed by @tenenbaumGeneralizationSimilarityBayesian2001a predicts that the breadth of generalization</span>
<span id="cb4-1146"><a href="#cb4-1146" aria-hidden="true" tabindex="-1"></a>will increase when a rational agent encounters a wider variety of</span>
<span id="cb4-1147"><a href="#cb4-1147" aria-hidden="true" tabindex="-1"></a>examples. Following these leads, we assume that in addition to learning</span>
<span id="cb4-1148"><a href="#cb4-1148" aria-hidden="true" tabindex="-1"></a>the task itself, participants are also adjusting how generalizable their</span>
<span id="cb4-1149"><a href="#cb4-1149" aria-hidden="true" tabindex="-1"></a>experience should be. Varied versus constant participants may be</span>
<span id="cb4-1150"><a href="#cb4-1150" aria-hidden="true" tabindex="-1"></a>expected to learn to generalize their experience to different degrees.</span>
<span id="cb4-1151"><a href="#cb4-1151" aria-hidden="true" tabindex="-1"></a>To accommodate this difference, the generalization parameter of the</span>
<span id="cb4-1152"><a href="#cb4-1152" aria-hidden="true" tabindex="-1"></a>instance-based model (in the present case, the c parameter) can be</span>
<span id="cb4-1153"><a href="#cb4-1153" aria-hidden="true" tabindex="-1"></a>allowed to vary between the two groups to reflect the tendency of</span>
<span id="cb4-1154"><a href="#cb4-1154" aria-hidden="true" tabindex="-1"></a>learners to adaptively tune the extent of their generalization. One</span>
<span id="cb4-1155"><a href="#cb4-1155" aria-hidden="true" tabindex="-1"></a>specific hypothesis is that people adaptively set a value of c to fit</span>
<span id="cb4-1156"><a href="#cb4-1156" aria-hidden="true" tabindex="-1"></a>the variability of their training experience <span class="co">[</span><span class="ot">@nosofskyExemplarbasedAccountsMultiplesystem2000; @sakamotoTrackingVariabilityLearning2006</span><span class="co">]</span>. If one's training experience is relatively</span>
<span id="cb4-1157"><a href="#cb4-1157" aria-hidden="true" tabindex="-1"></a>variable, as with the variable training condition, then one might infer</span>
<span id="cb4-1158"><a href="#cb4-1158" aria-hidden="true" tabindex="-1"></a>that future test situations will also be variable, in which case a low</span>
<span id="cb4-1159"><a href="#cb4-1159" aria-hidden="true" tabindex="-1"></a>value of c will allow better generalization because generalization will</span>
<span id="cb4-1160"><a href="#cb4-1160" aria-hidden="true" tabindex="-1"></a>drop off slowly with training-to-testing distance. Conversely, if one's</span>
<span id="cb4-1161"><a href="#cb4-1161" aria-hidden="true" tabindex="-1"></a>training experience has little variability, as found in the constant</span>
<span id="cb4-1162"><a href="#cb4-1162" aria-hidden="true" tabindex="-1"></a>training conditions, then one might adopt a high value of c so that</span>
<span id="cb4-1163"><a href="#cb4-1163" aria-hidden="true" tabindex="-1"></a>generalization falls off rapidly away from the trained positions.</span>
<span id="cb4-1164"><a href="#cb4-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1165"><a href="#cb4-1165" aria-hidden="true" tabindex="-1"></a>To address this possibility, we compared the original instance-based</span>
<span id="cb4-1166"><a href="#cb4-1166" aria-hidden="true" tabindex="-1"></a>model of similarity fit against a modified model which separately fits</span>
<span id="cb4-1167"><a href="#cb4-1167" aria-hidden="true" tabindex="-1"></a>the generalization parameter, c, to varied and constant participants. To</span>
<span id="cb4-1168"><a href="#cb4-1168" aria-hidden="true" tabindex="-1"></a>perform this parameter fitting, we used the optim function in R, and fit</span>
<span id="cb4-1169"><a href="#cb4-1169" aria-hidden="true" tabindex="-1"></a>the model to find the c value(s) that maximized the correlation between</span>
<span id="cb4-1170"><a href="#cb4-1170" aria-hidden="true" tabindex="-1"></a>similarity and testing performance.</span>
<span id="cb4-1171"><a href="#cb4-1171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1172"><a href="#cb4-1172" aria-hidden="true" tabindex="-1"></a>Both models generate distinct similarity values between training and</span>
<span id="cb4-1173"><a href="#cb4-1173" aria-hidden="true" tabindex="-1"></a>testing locations. Much like the analyses in Experiment 2, these</span>
<span id="cb4-1174"><a href="#cb4-1174" aria-hidden="true" tabindex="-1"></a>similarity values are regressed against testing performance in models of</span>
<span id="cb4-1175"><a href="#cb4-1175" aria-hidden="true" tabindex="-1"></a>the form shown below. As was the case previously, testing performance is</span>
<span id="cb4-1176"><a href="#cb4-1176" aria-hidden="true" tabindex="-1"></a>defined as the mean absolute distance from the center of the target</span>
<span id="cb4-1177"><a href="#cb4-1177" aria-hidden="true" tabindex="-1"></a>(with a separate score for each participant, from each position).</span>
<span id="cb4-1178"><a href="#cb4-1178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1179"><a href="#cb4-1179" aria-hidden="true" tabindex="-1"></a>Linear models 1 and 3 both show that similarity is a significant</span>
<span id="cb4-1180"><a href="#cb4-1180" aria-hidden="true" tabindex="-1"></a>predictor of testing performance (p<span class="sc">\&lt;</span>.01). Of greater interest is the</span>
<span id="cb4-1181"><a href="#cb4-1181" aria-hidden="true" tabindex="-1"></a>difference between linear model 2, in which similarity is computed from</span>
<span id="cb4-1182"><a href="#cb4-1182" aria-hidden="true" tabindex="-1"></a>a single c value fit from all participants (Similarity1c), with linear</span>
<span id="cb4-1183"><a href="#cb4-1183" aria-hidden="true" tabindex="-1"></a>model 4, which fits the c parameter separately between groups</span>
<span id="cb4-1184"><a href="#cb4-1184" aria-hidden="true" tabindex="-1"></a>(Similarity2c). In linear model 2, the effect of training group remains</span>
<span id="cb4-1185"><a href="#cb4-1185" aria-hidden="true" tabindex="-1"></a>significant when controlling for Similarity1c (p<span class="sc">\&lt;</span>.01), with the varied</span>
<span id="cb4-1186"><a href="#cb4-1186" aria-hidden="true" tabindex="-1"></a>group still performing significantly better. However, in linear model 4</span>
<span id="cb4-1187"><a href="#cb4-1187" aria-hidden="true" tabindex="-1"></a>the addition of the Similarity2c predictor results in the effect of</span>
<span id="cb4-1188"><a href="#cb4-1188" aria-hidden="true" tabindex="-1"></a>training group becoming nonsignificant (p=.40), suggesting that the</span>
<span id="cb4-1189"><a href="#cb4-1189" aria-hidden="true" tabindex="-1"></a>effect of varied vs. constant training is accounted for by the</span>
<span id="cb4-1190"><a href="#cb4-1190" aria-hidden="true" tabindex="-1"></a>Similarity2c predictor. Next, to further establish a difference between</span>
<span id="cb4-1191"><a href="#cb4-1191" aria-hidden="true" tabindex="-1"></a>the models, we performed nested model comparisons using ANOVA, to see if</span>
<span id="cb4-1192"><a href="#cb4-1192" aria-hidden="true" tabindex="-1"></a>the addition of the training group parameter led to a significant</span>
<span id="cb4-1193"><a href="#cb4-1193" aria-hidden="true" tabindex="-1"></a>improvement in model performance. In the first comparison, ANOVA(Linear</span>
<span id="cb4-1194"><a href="#cb4-1194" aria-hidden="true" tabindex="-1"></a>Model 1, Linear Model 2), the addition of the training group predictor</span>
<span id="cb4-1195"><a href="#cb4-1195" aria-hidden="true" tabindex="-1"></a>significantly improved the performance of the model (F=22.07, p<span class="sc">\&lt;</span>.01).</span>
<span id="cb4-1196"><a href="#cb4-1196" aria-hidden="true" tabindex="-1"></a>However, in the second model comparison, ANOVA (Linear model 3, Linear</span>
<span id="cb4-1197"><a href="#cb4-1197" aria-hidden="true" tabindex="-1"></a>Model 4) found no improvement in model performance with the addition of</span>
<span id="cb4-1198"><a href="#cb4-1198" aria-hidden="true" tabindex="-1"></a>the training group predictor (F=1.61, p=.20).</span>
<span id="cb4-1199"><a href="#cb4-1199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1200"><a href="#cb4-1200" aria-hidden="true" tabindex="-1"></a>Finally, we sought to confirm that similarity values generated from the</span>
<span id="cb4-1201"><a href="#cb4-1201" aria-hidden="true" tabindex="-1"></a>adjusted Similarity2c model had more predictive power than those</span>
<span id="cb4-1202"><a href="#cb4-1202" aria-hidden="true" tabindex="-1"></a>generated from the original Similarity1c model. Using the BIC function</span>
<span id="cb4-1203"><a href="#cb4-1203" aria-hidden="true" tabindex="-1"></a>in R, we compared BIC values between linear model 1 (BIC=14604.00) and</span>
<span id="cb4-1204"><a href="#cb4-1204" aria-hidden="true" tabindex="-1"></a>linear model 3 (BIC = 14587.64). The lower BIC value of model 3 suggests</span>
<span id="cb4-1205"><a href="#cb4-1205" aria-hidden="true" tabindex="-1"></a>a modest advantage for predicting performance using a similarity measure</span>
<span id="cb4-1206"><a href="#cb4-1206" aria-hidden="true" tabindex="-1"></a>computed with two c values over similarity computed with a single c</span>
<span id="cb4-1207"><a href="#cb4-1207" aria-hidden="true" tabindex="-1"></a>value. When fit with separate c values, the best fitting c parameters</span>
<span id="cb4-1208"><a href="#cb4-1208" aria-hidden="true" tabindex="-1"></a>for the model consistently optimized such that the c value for the</span>
<span id="cb4-1209"><a href="#cb4-1209" aria-hidden="true" tabindex="-1"></a>varied group (c=.00008) was smaller in magnitude than the c value for</span>
<span id="cb4-1210"><a href="#cb4-1210" aria-hidden="true" tabindex="-1"></a>the constant group(c= .00011). Recall that similarity decreases as a</span>
<span id="cb4-1211"><a href="#cb4-1211" aria-hidden="true" tabindex="-1"></a>Gaussian function of distance (equation 1 above), and a smaller value of</span>
<span id="cb4-1212"><a href="#cb4-1212" aria-hidden="true" tabindex="-1"></a>c will result in a more gradual drop-off in similarity as the distance</span>
<span id="cb4-1213"><a href="#cb4-1213" aria-hidden="true" tabindex="-1"></a>between training throws and testing solutions increases.</span>
<span id="cb4-1214"><a href="#cb4-1214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1215"><a href="#cb4-1215" aria-hidden="true" tabindex="-1"></a>In summary, our modeling suggests that an instance-based model which</span>
<span id="cb4-1216"><a href="#cb4-1216" aria-hidden="true" tabindex="-1"></a>assumes equivalent generalization gradients between constant and varied</span>
<span id="cb4-1217"><a href="#cb4-1217" aria-hidden="true" tabindex="-1"></a>trained participants is unable to account for the extent of benefits of</span>
<span id="cb4-1218"><a href="#cb4-1218" aria-hidden="true" tabindex="-1"></a>varied over constant training observed at testing. The evidence for this</span>
<span id="cb4-1219"><a href="#cb4-1219" aria-hidden="true" tabindex="-1"></a>in the comparative model fits is that when a varied/constant dummy-coded</span>
<span id="cb4-1220"><a href="#cb4-1220" aria-hidden="true" tabindex="-1"></a>variable for condition is explicitly added to the model, the variable</span>
<span id="cb4-1221"><a href="#cb4-1221" aria-hidden="true" tabindex="-1"></a>adds a significant contribution to the prediction of test performance,</span>
<span id="cb4-1222"><a href="#cb4-1222" aria-hidden="true" tabindex="-1"></a>with the variable condition yielding better performance than the</span>
<span id="cb4-1223"><a href="#cb4-1223" aria-hidden="true" tabindex="-1"></a>constant conditions. However, if the instance-based generalization model</span>
<span id="cb4-1224"><a href="#cb4-1224" aria-hidden="true" tabindex="-1"></a>is modified to assume that the training groups can differ in the</span>
<span id="cb4-1225"><a href="#cb4-1225" aria-hidden="true" tabindex="-1"></a>steepness of their generalization gradient, by incorporating a separate</span>
<span id="cb4-1226"><a href="#cb4-1226" aria-hidden="true" tabindex="-1"></a>generalization parameter for each group, then the instance-based model</span>
<span id="cb4-1227"><a href="#cb4-1227" aria-hidden="true" tabindex="-1"></a>can account for our experimental results without explicitly taking</span>
<span id="cb4-1228"><a href="#cb4-1228" aria-hidden="true" tabindex="-1"></a>training group into account. Henceforth this model will be referred to</span>
<span id="cb4-1229"><a href="#cb4-1229" aria-hidden="true" tabindex="-1"></a>as the Instance-based Generalization with Adaptive Similarity (IGAS)</span>
<span id="cb4-1230"><a href="#cb4-1230" aria-hidden="true" tabindex="-1"></a>model.</span>
<span id="cb4-1231"><a href="#cb4-1231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1232"><a href="#cb4-1232" aria-hidden="true" tabindex="-1"></a><span class="fu"># General Discussion</span></span>
<span id="cb4-1233"><a href="#cb4-1233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1234"><a href="#cb4-1234" aria-hidden="true" tabindex="-1"></a>Across two experiments, we found evidence in support of the benefits of</span>
<span id="cb4-1235"><a href="#cb4-1235" aria-hidden="true" tabindex="-1"></a>variability hypothesis in a simple, computerized projectile throwing</span>
<span id="cb4-1236"><a href="#cb4-1236" aria-hidden="true" tabindex="-1"></a>task. Generalization was observed in both constant and varied</span>
<span id="cb4-1237"><a href="#cb4-1237" aria-hidden="true" tabindex="-1"></a>participants, in that both groups tended to perform better at novel</span>
<span id="cb4-1238"><a href="#cb4-1238" aria-hidden="true" tabindex="-1"></a>positions in the testing phase than did participants who started with</span>
<span id="cb4-1239"><a href="#cb4-1239" aria-hidden="true" tabindex="-1"></a>those positions in the training phase. However, varied trained</span>
<span id="cb4-1240"><a href="#cb4-1240" aria-hidden="true" tabindex="-1"></a>participants consistently performed better than constant trained</span>
<span id="cb4-1241"><a href="#cb4-1241" aria-hidden="true" tabindex="-1"></a>participants, in terms of both the testing phase in general, and in a</span>
<span id="cb4-1242"><a href="#cb4-1242" aria-hidden="true" tabindex="-1"></a>comparison that only included untrained positions. We also found some</span>
<span id="cb4-1243"><a href="#cb4-1243" aria-hidden="true" tabindex="-1"></a>evidence for the less commonly observed pattern wherein varied-trained</span>
<span id="cb4-1244"><a href="#cb4-1244" aria-hidden="true" tabindex="-1"></a>participants outperform constant-trained participants even from</span>
<span id="cb4-1245"><a href="#cb4-1245" aria-hidden="true" tabindex="-1"></a>conditions identical to the constant group training <span class="co">[</span><span class="ot">@goodeSuperiorityVariableRepeated2008; @greenPracticeVariabilityTransfer1995a; @kerrSpecificVariedPractice1978</span><span class="co">]</span>. In experiment 1 varied</span>
<span id="cb4-1246"><a href="#cb4-1246" aria-hidden="true" tabindex="-1"></a>participants performed significantly better on this identity comparison.</span>
<span id="cb4-1247"><a href="#cb4-1247" aria-hidden="true" tabindex="-1"></a>In Experiment 2, the comparison was not significant initially, but</span>
<span id="cb4-1248"><a href="#cb4-1248" aria-hidden="true" tabindex="-1"></a>became significant after controlling for the similarity measure that</span>
<span id="cb4-1249"><a href="#cb4-1249" aria-hidden="true" tabindex="-1"></a>incorporates only a single value for the steepness of similarity-based</span>
<span id="cb4-1250"><a href="#cb4-1250" aria-hidden="true" tabindex="-1"></a>generalization (c). Furthermore, we showed that the general pattern of</span>
<span id="cb4-1251"><a href="#cb4-1251" aria-hidden="true" tabindex="-1"></a>results from Experiment 2 could be parsimoniously accommodated by an</span>
<span id="cb4-1252"><a href="#cb4-1252" aria-hidden="true" tabindex="-1"></a>instance-based similarity model, but only with the assumption that</span>
<span id="cb4-1253"><a href="#cb4-1253" aria-hidden="true" tabindex="-1"></a>constant and varied participants generalize their training experience to</span>
<span id="cb4-1254"><a href="#cb4-1254" aria-hidden="true" tabindex="-1"></a>different degrees. Our results thus suggest that the benefits of</span>
<span id="cb4-1255"><a href="#cb4-1255" aria-hidden="true" tabindex="-1"></a>variation cannot be explained by the varied-trained participants simply</span>
<span id="cb4-1256"><a href="#cb4-1256" aria-hidden="true" tabindex="-1"></a>covering a broader range of the task space. Rather, the modeling</span>
<span id="cb4-1257"><a href="#cb4-1257" aria-hidden="true" tabindex="-1"></a>suggests that varied participants also learn to adaptively tune their</span>
<span id="cb4-1258"><a href="#cb4-1258" aria-hidden="true" tabindex="-1"></a>generalization function such that throwing locations generalize more</span>
<span id="cb4-1259"><a href="#cb4-1259" aria-hidden="true" tabindex="-1"></a>broadly to one another than they do in the constant condition. A</span>
<span id="cb4-1260"><a href="#cb4-1260" aria-hidden="true" tabindex="-1"></a>learning system could end up adopting a higher c value in the constant</span>
<span id="cb4-1261"><a href="#cb4-1261" aria-hidden="true" tabindex="-1"></a>than variable training conditions by monitoring the trial-by-trial</span>
<span id="cb4-1262"><a href="#cb4-1262" aria-hidden="true" tabindex="-1"></a>variability of the training items. The c parameter would be adapted</span>
<span id="cb4-1263"><a href="#cb4-1263" aria-hidden="true" tabindex="-1"></a>downwards when adjacent training items are dissimilar to each other and</span>
<span id="cb4-1264"><a href="#cb4-1264" aria-hidden="true" tabindex="-1"></a>adapted upwards when adjacent training items are the same. In this</span>
<span id="cb4-1265"><a href="#cb4-1265" aria-hidden="true" tabindex="-1"></a>fashion, contextually appropriate c values could be empirically learned.</span>
<span id="cb4-1266"><a href="#cb4-1266" aria-hidden="true" tabindex="-1"></a>This learning procedure would capture the insight that if a situation</span>
<span id="cb4-1267"><a href="#cb4-1267" aria-hidden="true" tabindex="-1"></a>has a high amount variability, then the learner should be predisposed</span>
<span id="cb4-1268"><a href="#cb4-1268" aria-hidden="true" tabindex="-1"></a>toward thinking that subsequent test items will also show considerable</span>
<span id="cb4-1269"><a href="#cb4-1269" aria-hidden="true" tabindex="-1"></a>variability, in which case generalization gradients should be broad, as</span>
<span id="cb4-1270"><a href="#cb4-1270" aria-hidden="true" tabindex="-1"></a>is achieved by low values for c.</span>
<span id="cb4-1271"><a href="#cb4-1271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1272"><a href="#cb4-1272" aria-hidden="true" tabindex="-1"></a>Also of interest is whether the IGAS model can predict the pattern of</span>
<span id="cb4-1273"><a href="#cb4-1273" aria-hidden="true" tabindex="-1"></a>results wherein the varied condition outperforms the constant condition</span>
<span id="cb4-1274"><a href="#cb4-1274" aria-hidden="true" tabindex="-1"></a>even from the position on which the constant condition trained. Although</span>
<span id="cb4-1275"><a href="#cb4-1275" aria-hidden="true" tabindex="-1"></a>our models were fit using all of the Experiment 2 training and testing</span>
<span id="cb4-1276"><a href="#cb4-1276" aria-hidden="true" tabindex="-1"></a>data, not just that of the identity comparisons, in Figure 9 we</span>
<span id="cb4-1277"><a href="#cb4-1277" aria-hidden="true" tabindex="-1"></a>demonstrate how a simplified version of the IGAS model could in</span>
<span id="cb4-1278"><a href="#cb4-1278" aria-hidden="true" tabindex="-1"></a>principle produce such a pattern. In addition to the assumption of</span>
<span id="cb4-1279"><a href="#cb4-1279" aria-hidden="true" tabindex="-1"></a>differential generalization between varied and constant conditions, our</span>
<span id="cb4-1280"><a href="#cb4-1280" aria-hidden="true" tabindex="-1"></a>simplified model makes explicit an assumption that is incorporated into</span>
<span id="cb4-1281"><a href="#cb4-1281" aria-hidden="true" tabindex="-1"></a>the full IGAS model -- namely that even when being tested from a</span>
<span id="cb4-1282"><a href="#cb4-1282" aria-hidden="true" tabindex="-1"></a>position identical to that which was trained, there are always some</span>
<span id="cb4-1283"><a href="#cb4-1283" aria-hidden="true" tabindex="-1"></a>psychological contextual differences between training and testing</span>
<span id="cb4-1284"><a href="#cb4-1284" aria-hidden="true" tabindex="-1"></a>throws, resulting in a non-zero dissimilarity.</span>
<span id="cb4-1285"><a href="#cb4-1285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1288"><a href="#cb4-1288" aria-hidden="true" tabindex="-1"></a><span class="in">```{css}</span></span>
<span id="cb4-1289"><a href="#cb4-1289" aria-hidden="true" tabindex="-1"></a>caption<span class="op">,</span> <span class="fu">.caption</span>{</span>
<span id="cb4-1290"><a href="#cb4-1290" aria-hidden="true" tabindex="-1"></a>  <span class="kw">font-style</span>:<span class="dv">italic</span><span class="op">;</span></span>
<span id="cb4-1291"><a href="#cb4-1291" aria-hidden="true" tabindex="-1"></a>  <span class="kw">margin-top</span>:<span class="dv">0.5</span><span class="dt">em</span><span class="op">;</span></span>
<span id="cb4-1292"><a href="#cb4-1292" aria-hidden="true" tabindex="-1"></a>  <span class="kw">margin-bottom</span>:<span class="dv">0.5</span><span class="dt">em</span><span class="op">;</span></span>
<span id="cb4-1293"><a href="#cb4-1293" aria-hidden="true" tabindex="-1"></a>  <span class="kw">width</span>:<span class="dv">100</span><span class="dt">%</span><span class="op">;</span></span>
<span id="cb4-1294"><a href="#cb4-1294" aria-hidden="true" tabindex="-1"></a>  <span class="kw">text-align</span>: <span class="dv">left</span><span class="op">;</span></span>
<span id="cb4-1295"><a href="#cb4-1295" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-1296"><a href="#cb4-1296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1297"><a href="#cb4-1297" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb4-1298"><a href="#cb4-1298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1301"><a href="#cb4-1301" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb4-1302"><a href="#cb4-1302" aria-hidden="true" tabindex="-1"></a>#<span class="op">|</span> Toy Model 2<span class="op">,</span> fig<span class="fu">.width</span>=10<span class="op">,</span>fig<span class="fu">.height</span>=10<span class="fu">.0</span><span class="op">,</span></span>
<span id="cb4-1303"><a href="#cb4-1303" aria-hidden="true" tabindex="-1"></a>#<span class="op">|</span> fig<span class="fu">.cap</span>="Figure 9<span class="fu">.</span> A simple model depicting the necessity of both of two separately fit generalization parameters<span class="op">,</span> c<span class="op">,</span> and a positive distance between training and testing contexts<span class="op">,</span> in order for an instance model to predict a pattern of varied training from stimuli 400 and 800 outperforming constant training from position 600 at a test position of 600<span class="fu">.</span> For the top left panel<span class="op">,</span> in which the generalization model assumes a single c value (-<span class="fu">.008</span>) for  both varied and constant conditions<span class="op">,</span> and identical contexts across training and testing<span class="op">,</span> the equation which generates the varied condition is<span class="in">: Amount</span> of Generalization =  $e^{(c\\cdot<span class="op">|</span>x-800<span class="op">|</span>)}  <span class="op">+</span>e^{(c\\cdot<span class="op">|</span>x-400<span class="op">|</span>)}$<span class="op">,</span> whereas the constant group generalization is generated from $2\\cdot e^{(c\\cdot<span class="op">|</span>x-600<span class="op">|</span>)}$<span class="fu">.</span> For the top right panel<span class="op">,</span> the c constants in the original equations are different for the 2 conditions<span class="op">,</span> with $c=-<span class="fu">.002</span>$ for the varied condition<span class="op">,</span> and $c=-<span class="fu">.008</span>$ for the constant condition<span class="fu">.</span> The bottom two panels are generated from identical equations to those immediately above<span class="op">,</span> except for the addition of extra distance (100 units) to reflect the assumption of some change in context between training and testing conditions<span class="fu">.</span> Thus<span class="op">,</span> the generalization model for the varied condition in the bottom-right panel is of the form<span class="in">: Amount</span> of Generalization = $e^{(cvaried\\cdot<span class="op">|</span>x-800<span class="op">|</span>)}  <span class="op">+</span>e^{(cvaried\\cdot<span class="op">|</span>x-400<span class="op">|</span>)}$<span class="fu">.</span>"</span>
<span id="cb4-1304"><a href="#cb4-1304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1305"><a href="#cb4-1305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1306"><a href="#cb4-1306" aria-hidden="true" tabindex="-1"></a># </span>
<span id="cb4-1307"><a href="#cb4-1307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1308"><a href="#cb4-1308" aria-hidden="true" tabindex="-1"></a>p=2</span>
<span id="cb4-1309"><a href="#cb4-1309" aria-hidden="true" tabindex="-1"></a>c&lt;- <span class="fu">.000002</span></span>
<span id="cb4-1310"><a href="#cb4-1310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1311"><a href="#cb4-1311" aria-hidden="true" tabindex="-1"></a>trainingTestingDifference=2000;</span>
<span id="cb4-1312"><a href="#cb4-1312" aria-hidden="true" tabindex="-1"></a>cvaried=<span class="fu">.00002</span></span>
<span id="cb4-1313"><a href="#cb4-1313" aria-hidden="true" tabindex="-1"></a>cconstant=<span class="fu">.0005</span></span>
<span id="cb4-1314"><a href="#cb4-1314" aria-hidden="true" tabindex="-1"></a>simdat &lt;- data<span class="fu">.frame</span>(x=rep(seq(200<span class="op">,</span>1000)<span class="op">,</span>3)<span class="op">,</span>condit=c(rep("varied"<span class="op">,</span>1602)<span class="op">,</span>rep("constant"<span class="op">,</span>801))<span class="op">,</span></span>
<span id="cb4-1315"><a href="#cb4-1315" aria-hidden="true" tabindex="-1"></a>                     train<span class="fu">.position</span>=c(rep(400<span class="op">,</span>801)<span class="op">,</span>rep(800<span class="op">,</span>801)<span class="op">,</span>rep(600<span class="op">,</span>801))<span class="op">,</span>c=<span class="fu">.0002</span><span class="op">,</span>p=2) %<span class="op">&gt;</span>%</span>
<span id="cb4-1316"><a href="#cb4-1316" aria-hidden="true" tabindex="-1"></a>                     mutate(c2=ifelse(condit=="varied"<span class="op">,</span>cvaried<span class="op">,</span>cconstant)<span class="op">,</span></span>
<span id="cb4-1317"><a href="#cb4-1317" aria-hidden="true" tabindex="-1"></a>                            genGauss=exp(-c<span class="op">*</span>(abs((x-train<span class="fu">.position</span>)^p)))<span class="op">,</span></span>
<span id="cb4-1318"><a href="#cb4-1318" aria-hidden="true" tabindex="-1"></a>                            genGaussDist=exp(-c<span class="op">*</span>(trainingTestingDifference<span class="op">+</span>abs((x-train<span class="fu">.position</span>)^p)))<span class="op">,</span></span>
<span id="cb4-1319"><a href="#cb4-1319" aria-hidden="true" tabindex="-1"></a>                            genGauss2=exp(-c2<span class="op">*</span>(abs((x-train<span class="fu">.position</span>)^p)))<span class="op">,</span></span>
<span id="cb4-1320"><a href="#cb4-1320" aria-hidden="true" tabindex="-1"></a>                            genGaussDist2=exp(-c2<span class="op">*</span>(trainingTestingDifference<span class="op">+</span>abs((x-train<span class="fu">.position</span>)^p)))<span class="op">,</span></span>
<span id="cb4-1321"><a href="#cb4-1321" aria-hidden="true" tabindex="-1"></a>                            ) %<span class="op">&gt;</span>% </span>
<span id="cb4-1322"><a href="#cb4-1322" aria-hidden="true" tabindex="-1"></a>  group_by(x<span class="op">,</span>condit) %<span class="op">&gt;</span>%</span>
<span id="cb4-1323"><a href="#cb4-1323" aria-hidden="true" tabindex="-1"></a>  summarise(genGauss=mean(genGauss)<span class="op">,</span>genGauss2=mean(genGauss2)<span class="op">,</span>genGaussDist=mean(genGaussDist)<span class="op">,</span>genGaussDist2=mean(genGaussDist2)<span class="op">,</span><span class="fu">.groups</span>='keep')</span>
<span id="cb4-1324"><a href="#cb4-1324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1325"><a href="#cb4-1325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1326"><a href="#cb4-1326" aria-hidden="true" tabindex="-1"></a><span class="pp">#plot</span>(x<span class="op">,</span>exp(c<span class="op">*</span>(trainingTestingDifference<span class="op">+</span>abs(x-800)))<span class="op">+</span>exp(c<span class="op">*</span>(trainingTestingDifference<span class="op">+</span>abs(x-400)))</span>
<span id="cb4-1327"><a href="#cb4-1327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1328"><a href="#cb4-1328" aria-hidden="true" tabindex="-1"></a>colorVec=c("darkblue"<span class="op">,</span>"darkred")</span>
<span id="cb4-1329"><a href="#cb4-1329" aria-hidden="true" tabindex="-1"></a>plotSpecs &lt;- list(geom_line(alpha=<span class="fu">.7</span>)<span class="op">,</span>scale_color_manual(values=colorVec)<span class="op">,</span></span>
<span id="cb4-1330"><a href="#cb4-1330" aria-hidden="true" tabindex="-1"></a>                  geom_vline(alpha=<span class="fu">.55</span><span class="op">,</span>xintercept = c(400<span class="op">,</span>800)<span class="op">,</span>color=colorVec<span class="ex">[2]</span>)<span class="op">,</span></span>
<span id="cb4-1331"><a href="#cb4-1331" aria-hidden="true" tabindex="-1"></a>                  geom_vline(alpha=<span class="fu">.55</span><span class="op">,</span>xintercept = c(600)<span class="op">,</span>color=colorVec<span class="ex">[1]</span>)<span class="op">,</span></span>
<span id="cb4-1332"><a href="#cb4-1332" aria-hidden="true" tabindex="-1"></a>                  ylim(c(0<span class="op">,</span>1<span class="fu">.05</span>))<span class="op">,</span></span>
<span id="cb4-1333"><a href="#cb4-1333" aria-hidden="true" tabindex="-1"></a>                  <span class="pp">#xlim</span>(c(250<span class="op">,</span>950))<span class="op">,</span></span>
<span id="cb4-1334"><a href="#cb4-1334" aria-hidden="true" tabindex="-1"></a>                  scale_x_continuous(breaks=seq(200<span class="op">,</span>1000<span class="op">,</span>by=200))<span class="op">,</span></span>
<span id="cb4-1335"><a href="#cb4-1335" aria-hidden="true" tabindex="-1"></a>                  xlab("Test Stimulus")<span class="op">,</span></span>
<span id="cb4-1336"><a href="#cb4-1336" aria-hidden="true" tabindex="-1"></a>                  annotate(geom="text"<span class="op">,</span>x=455<span class="op">,</span>y=1<span class="fu">.05</span><span class="op">,</span>label="Varied"<span class="op">,</span>size=3<span class="fu">.1</span>)<span class="op">,</span></span>
<span id="cb4-1337"><a href="#cb4-1337" aria-hidden="true" tabindex="-1"></a>                  annotate(geom="text"<span class="op">,</span>x=455<span class="op">,</span>y=1<span class="fu">.01</span><span class="op">,</span>label="Training"<span class="op">,</span>size=3<span class="fu">.1</span>)<span class="op">,</span></span>
<span id="cb4-1338"><a href="#cb4-1338" aria-hidden="true" tabindex="-1"></a>                  annotate(geom="text"<span class="op">,</span>x=662<span class="op">,</span>y=1<span class="fu">.05</span><span class="op">,</span>label="Constant"<span class="op">,</span>size=3<span class="fu">.1</span>)<span class="op">,</span></span>
<span id="cb4-1339"><a href="#cb4-1339" aria-hidden="true" tabindex="-1"></a>                  annotate(geom="text"<span class="op">,</span>x=657<span class="op">,</span>y=1<span class="fu">.01</span><span class="op">,</span>label="Training"<span class="op">,</span>size=3<span class="fu">.1</span>)<span class="op">,</span></span>
<span id="cb4-1340"><a href="#cb4-1340" aria-hidden="true" tabindex="-1"></a>                  annotate(geom="text"<span class="op">,</span>x=855<span class="op">,</span>y=1<span class="fu">.05</span><span class="op">,</span>label="Varied"<span class="op">,</span>size=3<span class="fu">.1</span>)<span class="op">,</span></span>
<span id="cb4-1341"><a href="#cb4-1341" aria-hidden="true" tabindex="-1"></a>                  annotate(geom="text"<span class="op">,</span>x=855<span class="op">,</span>y=1<span class="fu">.01</span><span class="op">,</span>label="Training"<span class="op">,</span>size=3<span class="fu">.1</span>)<span class="op">,</span></span>
<span id="cb4-1342"><a href="#cb4-1342" aria-hidden="true" tabindex="-1"></a>                  theme(panel<span class="fu">.border</span> = element_rect(colour = "black"<span class="op">,</span> fill=NA<span class="op">,</span> size=1)<span class="op">,</span></span>
<span id="cb4-1343"><a href="#cb4-1343" aria-hidden="true" tabindex="-1"></a>                        legend<span class="fu">.position</span>="none"))</span>
<span id="cb4-1344"><a href="#cb4-1344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1345"><a href="#cb4-1345" aria-hidden="true" tabindex="-1"></a>ip1 &lt;- simdat  %<span class="op">&gt;</span>% ggplot(aes(x<span class="op">,</span>y=genGauss<span class="op">,</span>group=condit<span class="op">,</span>col=condit))<span class="op">+</span>plotSpecs<span class="op">+</span>ylab("Amount of Generalization")<span class="op">+</span>ggtitle("Identical context<span class="op">,</span> 1c")</span>
<span id="cb4-1346"><a href="#cb4-1346" aria-hidden="true" tabindex="-1"></a>ip2 &lt;- simdat %<span class="op">&gt;</span>%  ggplot(aes(x<span class="op">,</span>y=genGauss2<span class="op">,</span>group=condit<span class="op">,</span>col=condit))<span class="op">+</span>plotSpecs<span class="op">+</span>ylab("")<span class="op">+</span>ggtitle("Identical context<span class="op">,</span> 2c")</span>
<span id="cb4-1347"><a href="#cb4-1347" aria-hidden="true" tabindex="-1"></a>ip3 &lt;- simdat  %<span class="op">&gt;</span>% ggplot(aes(x<span class="op">,</span>y=genGaussDist<span class="op">,</span>group=condit<span class="op">,</span>col=condit))<span class="op">+</span>plotSpecs<span class="op">+</span>ylab("Amount of Generalization")<span class="op">+</span></span>
<span id="cb4-1348"><a href="#cb4-1348" aria-hidden="true" tabindex="-1"></a>  ggtitle("Added distance due to context context<span class="op">,</span> 1c")<span class="op">+</span>theme(plot<span class="fu">.margin</span> = margin(0<span class="op">,</span> 0<span class="op">,</span> 0<span class="op">,</span> 1))</span>
<span id="cb4-1349"><a href="#cb4-1349" aria-hidden="true" tabindex="-1"></a>ip4 &lt;- simdat %<span class="op">&gt;</span>%  ggplot(aes(x<span class="op">,</span>y=genGaussDist2<span class="op">,</span>group=condit<span class="op">,</span>col=condit))<span class="op">+</span>plotSpecs<span class="op">+</span>ylab("")<span class="op">+</span></span>
<span id="cb4-1350"><a href="#cb4-1350" aria-hidden="true" tabindex="-1"></a>  ggtitle("Added distance due to context context<span class="op">,</span> 2c")<span class="op">+</span>theme(plot<span class="fu">.margin</span> = margin(0<span class="op">,</span> 0<span class="op">,</span> 0<span class="op">,</span> 1))</span>
<span id="cb4-1351"><a href="#cb4-1351" aria-hidden="true" tabindex="-1"></a># gridExtra<span class="in">::grid</span><span class="fu">.arrange</span>(ip1<span class="op">,</span>ip2<span class="op">,</span>ip3<span class="op">,</span>ip4<span class="op">,</span>ncol=2)</span>
<span id="cb4-1352"><a href="#cb4-1352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1353"><a href="#cb4-1353" aria-hidden="true" tabindex="-1"></a>gtitle="Figure 9<span class="fu">.</span>"</span>
<span id="cb4-1354"><a href="#cb4-1354" aria-hidden="true" tabindex="-1"></a>title = ggdraw()<span class="op">+</span>draw_label(gtitle<span class="op">,</span>fontface = 'bold'<span class="op">,</span>x=0<span class="op">,</span>hjust=0<span class="op">,</span>size=11)<span class="op">+</span>theme(plot<span class="fu">.margin</span> = margin(0<span class="op">,</span> 0<span class="op">,</span> 0<span class="op">,</span> 1))</span>
<span id="cb4-1355"><a href="#cb4-1355" aria-hidden="true" tabindex="-1"></a>plot_grid(title<span class="op">,</span>NULL<span class="op">,</span>ip1<span class="op">,</span>ip2<span class="op">,</span>ip3<span class="op">,</span>ip4<span class="op">,</span>ncol=2<span class="op">,</span>rel_heights=c(<span class="fu">.1</span><span class="op">,</span><span class="fu">.8</span><span class="op">,</span><span class="fu">.8</span>))</span>
<span id="cb4-1356"><a href="#cb4-1356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1357"><a href="#cb4-1357" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb4-1358"><a href="#cb4-1358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1359"><a href="#cb4-1359" aria-hidden="true" tabindex="-1"></a>As mentioned above<span class="op">,</span> the idea that learners flexibly adjust their</span>
<span id="cb4-1360"><a href="#cb4-1360" aria-hidden="true" tabindex="-1"></a>generalization gradient based on prior experience does have precedent in</span>
<span id="cb4-1361"><a href="#cb4-1361" aria-hidden="true" tabindex="-1"></a>the domains of category learning <span class="ex">[@ahaConceptLearningFlexible1992; @briscoeConceptualComplexityBias2011; @hahnEffectsCategoryDiversity2005; @lambertsFlexibleTuningSimilarity1994; @opdebeeckRepresentationPerceivedShape2008]</span><span class="op">,</span> and sensorimotor adaptation <span class="ex">[@marongelliAdvantageFlexibleNeuronal2013; @taylorContextdependentGeneralization2013; @thoroughmanRapidReshapingHuman2005]</span><span class="fu">.</span> <span class="im">@lambertsFlexibleTuningSimilarity1994</span> showed</span>
<span id="cb4-1362"><a href="#cb4-1362" aria-hidden="true" tabindex="-1"></a>that a simple manipulation of <span class="cn">background</span> knowledge during a</span>
<span id="cb4-1363"><a href="#cb4-1363" aria-hidden="true" tabindex="-1"></a>categorization test resulted in participants generalizing their training</span>
<span id="cb4-1364"><a href="#cb4-1364" aria-hidden="true" tabindex="-1"></a>experience more or less broadly, <span class="kw">and</span> moreover that such a pattern could</span>
<span id="cb4-1365"><a href="#cb4-1365" aria-hidden="true" tabindex="-1"></a>be captured by allowing the generalization parameter of an</span>
<span id="cb4-1366"><a href="#cb4-1366" aria-hidden="true" tabindex="-1"></a>instance-based similarity model to be fit separately between conditions.</span>
<span id="cb4-1367"><a href="#cb4-1367" aria-hidden="true" tabindex="-1"></a>The flexible generalization parameter has also successfully accounted</span>
<span id="cb4-1368"><a href="#cb4-1368" aria-hidden="true" tabindex="-1"></a>for generalization behavior in cases where participants have been</span>
<span id="cb4-1369"><a href="#cb4-1369" aria-hidden="true" tabindex="-1"></a>trained on categories that differ in their <span class="dv">relative</span> variability [@hahnEffectsCategoryDiversity2005<span class="op">;</span> <span class="im">@sakamotoTrackingVariabilityLearning2006</span>]. However, to the best of our</span>
<span id="cb4-1370"><a href="#cb4-1370" aria-hidden="true" tabindex="-1"></a>knowledge, IGAS is the first instance-based similarity model that has</span>
<span id="cb4-1371"><a href="#cb4-1371" aria-hidden="true" tabindex="-1"></a>been put forward to account for the effect of varied training in a</span>
<span id="cb4-1372"><a href="#cb4-1372" aria-hidden="true" tabindex="-1"></a>visuomotor skill task. Although IGAS was inspired by work in the domain</span>
<span id="cb4-1373"><a href="#cb4-1373" aria-hidden="true" tabindex="-1"></a>of category learning, its success in a distinct domain may <span class="kw">not</span> be</span>
<span id="cb4-1374"><a href="#cb4-1374" aria-hidden="true" tabindex="-1"></a>surprising in <span class="dv">light</span> of the numerous prior observations that at least</span>
<span id="cb4-1375"><a href="#cb4-1375" aria-hidden="true" tabindex="-1"></a>certain aspects of learning <span class="kw">and</span> generalization may operate under common</span>
<span id="cb4-1376"><a href="#cb4-1376" aria-hidden="true" tabindex="-1"></a>principles across different tasks <span class="kw">and</span> domains [@censorCommonMechanismsHuman2012<span class="op">;</span> <span class="im">@hillsCentralExecutiveSearch2010</span><span class="op">;</span> <span class="im">@jamiesonInstanceTheoryDomaingeneral2022</span><span class="op">;</span> <span class="im">@lawSharedMechanismsPerceptual2010</span><span class="op">;</span> <span class="im">@roarkComparingPerceptualCategory2021</span><span class="op">;</span> <span class="im">@rosenbaumAcquisitionIntellectualPerceptualMotor2001a</span><span class="op">;</span> <span class="im">@vigoLearningDifficultyVisual2018</span><span class="op">;</span> <span class="im">@wallIdentifyingRelationshipsCognitive2021</span><span class="op">;</span> <span class="im">@wuSimilaritiesDifferencesSpatial2020</span><span class="op">;</span> <span class="im">@yangGeneralLearningAbility2020</span>].</span>
<span id="cb4-1377"><a href="#cb4-1377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1378"><a href="#cb4-1378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1379"><a href="#cb4-1379" aria-hidden="true" tabindex="-1"></a>Our modelling approach does differ from category learning</span>
<span id="cb4-1380"><a href="#cb4-1380" aria-hidden="true" tabindex="-1"></a>implementations of instance-based models in several ways. One such</span>
<span id="cb4-1381"><a href="#cb4-1381" aria-hidden="true" tabindex="-1"></a>difference is the nature of the training instances that are assumed to</span>
<span id="cb4-1382"><a href="#cb4-1382" aria-hidden="true" tabindex="-1"></a>be stored. In category learning studies, instances are represented as</span>
<span id="cb4-1383"><a href="#cb4-1383" aria-hidden="true" tabindex="-1"></a>points in a multidimensional space of <span class="dv">all</span> of the attributes that define</span>
<span id="cb4-1384"><a href="#cb4-1384" aria-hidden="true" tabindex="-1"></a>a category item (e.g. <span class="dv">size</span>/<span class="dv">color</span>/shape). Rather than defining instances</span>
<span id="cb4-1385"><a href="#cb4-1385" aria-hidden="true" tabindex="-1"></a>in terms of what stimuli learners experience, our approach assumes that</span>
<span id="cb4-1386"><a href="#cb4-1386" aria-hidden="true" tabindex="-1"></a>stored, motor instances reflect how they act, in terms of the velocity</span>
<span id="cb4-1387"><a href="#cb4-1387" aria-hidden="true" tabindex="-1"></a>applied to the ball on each throw. An advantage of many motor learning</span>
<span id="cb4-1388"><a href="#cb4-1388" aria-hidden="true" tabindex="-1"></a>tasks is the <span class="dv">relative</span> <span class="dv">ease</span> with which task execution variables can be</span>
<span id="cb4-1389"><a href="#cb4-1389" aria-hidden="true" tabindex="-1"></a>directly measured (e.g. movement force, velocity, angle, posture) in</span>
<span id="cb4-1390"><a href="#cb4-1390" aria-hidden="true" tabindex="-1"></a>addition to the decision <span class="kw">and</span> response time measures that typically</span>
<span id="cb4-1391"><a href="#cb4-1391" aria-hidden="true" tabindex="-1"></a>exhaust the data generated from more classical cognitive tasks. Of</span>
<span id="cb4-1392"><a href="#cb4-1392" aria-hidden="true" tabindex="-1"></a>course, whether learners actually are storing each individual motor</span>
<span id="cb4-1393"><a href="#cb4-1393" aria-hidden="true" tabindex="-1"></a>instance is a fundamental question beyond the scope of the current work</span>
<span id="cb4-1394"><a href="#cb4-1394" aria-hidden="true" tabindex="-1"></a>-- though as described in the introduction there is some evidence in</span>
<span id="cb4-1395"><a href="#cb4-1395" aria-hidden="true" tabindex="-1"></a>support of this idea [@chamberlinNoteSchemaExemplar1992<span class="op">;</span> <span class="im">@crumpEpisodicContributionsSequential2010</span><span class="op">;</span> <span class="im">@hommelEventFilesEvidence1998</span><span class="op">;</span> <span class="im">@meighWhatMemoryRepresentation2018</span><span class="op">;</span> <span class="im">@poldrackRelationshipSkillLearning1999</span>]. A particularly</span>
<span id="cb4-1396"><a href="#cb4-1396" aria-hidden="true" tabindex="-1"></a>noteworthy instance-based model of sensory-motor behavior is the</span>
<span id="cb4-1397"><a href="#cb4-1397" aria-hidden="true" tabindex="-1"></a>Knowledge II model of Rosenbaum <span class="kw">and</span> colleagues [@cohenWhereGraspsAre2004<span class="op">;</span> <span class="im">@rosenbaumPlanningReachesEvaluating1995</span>]. Knowledge II explicitly defines instances as</span>
<span id="cb4-1398"><a href="#cb4-1398" aria-hidden="true" tabindex="-1"></a>postures (joint combinations), <span class="kw">and</span> is thus far more detailed than IGAS</span>
<span id="cb4-1399"><a href="#cb4-1399" aria-hidden="true" tabindex="-1"></a>in regards to the <span class="dv">contents</span> of stored instances. Knowledge II also</span>
<span id="cb4-1400"><a href="#cb4-1400" aria-hidden="true" tabindex="-1"></a>differs from IGAS in that learning is accounted for by <span class="dv">both</span> the</span>
<span id="cb4-1401"><a href="#cb4-1401" aria-hidden="true" tabindex="-1"></a>retrieval of stored postures, <span class="kw">and</span> the generation of novel postures via</span>
<span id="cb4-1402"><a href="#cb4-1402" aria-hidden="true" tabindex="-1"></a>the modification of retrieved postures. A promising avenue for future</span>
<span id="cb4-1403"><a href="#cb4-1403" aria-hidden="true" tabindex="-1"></a>research would be to combine the adaptive similarity mechanism of IGAS</span>
<span id="cb4-1404"><a href="#cb4-1404" aria-hidden="true" tabindex="-1"></a>with the novel instance generation mechanisms of Knowledge II.</span>
<span id="cb4-1405"><a href="#cb4-1405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1406"><a href="#cb4-1406" aria-hidden="true" tabindex="-1"></a>Our findings also have some conceptual overlap with an earlier study on</span>
<span id="cb4-1407"><a href="#cb4-1407" aria-hidden="true" tabindex="-1"></a>the effects of varied training in a coincident timing task [@catalanoDistantTransferCoincident1984a].  In this task, participants observe a series of lamps</span>
<span id="cb4-1408"><a href="#cb4-1408" aria-hidden="true" tabindex="-1"></a>lighting up consecutively, <span class="kw">and</span> attempt to time a button press with the</span>
<span id="cb4-1409"><a href="#cb4-1409" aria-hidden="true" tabindex="-1"></a>onset of the final lamp. The design consisted of four <span class="dv">separate</span> constant</span>
<span id="cb4-1410"><a href="#cb4-1410" aria-hidden="true" tabindex="-1"></a>groups, each training from a single lighting velocity, <span class="kw">and</span> a single</span>
<span id="cb4-1411"><a href="#cb4-1411" aria-hidden="true" tabindex="-1"></a>varied group training with <span class="dv">all</span> four of the lighting velocities used by</span>
<span id="cb4-1412"><a href="#cb4-1412" aria-hidden="true" tabindex="-1"></a>the individual constant groups. Participants were then split into four</span>
<span id="cb4-1413"><a href="#cb4-1413" aria-hidden="true" tabindex="-1"></a><span class="dv">separate</span> testing conditions, each of which were tested from a single</span>
<span id="cb4-1414"><a href="#cb4-1414" aria-hidden="true" tabindex="-1"></a>novel lighting velocity of varying distance from the training</span>
<span id="cb4-1415"><a href="#cb4-1415" aria-hidden="true" tabindex="-1"></a>conditions. The result of primary interest was that <span class="dv">all</span> participants</span>
<span id="cb4-1416"><a href="#cb4-1416" aria-hidden="true" tabindex="-1"></a>performed worse as the distance between training <span class="kw">and</span> testing velocity</span>
<span id="cb4-1417"><a href="#cb4-1417" aria-hidden="true" tabindex="-1"></a>increased -- a typical generalization decrement. However, varied</span>
<span id="cb4-1418"><a href="#cb4-1418" aria-hidden="true" tabindex="-1"></a>participants showed less of a decrement than did constant participants.</span>
<span id="cb4-1419"><a href="#cb4-1419" aria-hidden="true" tabindex="-1"></a>The authors take this result as evidence that varied training results in</span>
<span id="cb4-1420"><a href="#cb4-1420" aria-hidden="true" tabindex="-1"></a>a less-steep generalization gradient than does constant training.</span>
<span id="cb4-1421"><a href="#cb4-1421" aria-hidden="true" tabindex="-1"></a>Although the experimental conclusions of Catalano <span class="kw">and</span> Kleiner are</span>
<span id="cb4-1422"><a href="#cb4-1422" aria-hidden="true" tabindex="-1"></a>similar to our own, our work is novel in that we account for our results</span>
<span id="cb4-1423"><a href="#cb4-1423" aria-hidden="true" tabindex="-1"></a>with a cognitive model, <span class="kw">and</span> without assuming the formation of a schema.</span>
<span id="cb4-1424"><a href="#cb4-1424" aria-hidden="true" tabindex="-1"></a>Additionally, the way in which Catalano <span class="kw">and</span> Kleiner <span class="dv">collapse</span> their</span>
<span id="cb4-1425"><a href="#cb4-1425" aria-hidden="true" tabindex="-1"></a><span class="dv">separate</span> constant groups together may result in similarity confounds</span>
<span id="cb4-1426"><a href="#cb4-1426" aria-hidden="true" tabindex="-1"></a>between varied <span class="kw">and</span> constant conditions that leaves their study <span class="dv">open</span> to</span>
<span id="cb4-1427"><a href="#cb4-1427" aria-hidden="true" tabindex="-1"></a>methodological criticisms, especially in <span class="dv">light</span> of related work which</span>
<span id="cb4-1428"><a href="#cb4-1428" aria-hidden="true" tabindex="-1"></a>demonstrated that the extent to which varied training may be beneficial</span>
<span id="cb4-1429"><a href="#cb4-1429" aria-hidden="true" tabindex="-1"></a>can depend on whether the constant group they are compared against</span>
<span id="cb4-1430"><a href="#cb4-1430" aria-hidden="true" tabindex="-1"></a>trained from similar conditions to those later tested [@wrisbergVariabilityPracticeHypothesis1987]. Our study alleviates such concerns by explicitly controlling for</span>
<span id="cb4-1431"><a href="#cb4-1431" aria-hidden="true" tabindex="-1"></a>similarity.</span>
<span id="cb4-1432"><a href="#cb4-1432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1433"><a href="#cb4-1433" aria-hidden="true" tabindex="-1"></a>## Limitations</span>
<span id="cb4-1434"><a href="#cb4-1434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1435"><a href="#cb4-1435" aria-hidden="true" tabindex="-1"></a>A limitation of this study concerns the ordering of the testing/transfer</span>
<span id="cb4-1436"><a href="#cb4-1436" aria-hidden="true" tabindex="-1"></a>trials at the conclusion of <span class="dv">both</span> experiments. Participants were tested</span>
<span id="cb4-1437"><a href="#cb4-1437" aria-hidden="true" tabindex="-1"></a>from each <span class="dv">separate</span> position (<span class="dv">4</span> in Experiment <span class="dv">1</span>, <span class="dv">6</span> in Experiment <span class="dv">2</span>) in a</span>
<span id="cb4-1438"><a href="#cb4-1438" aria-hidden="true" tabindex="-1"></a>random, intermixed order. Because the varied group was trained from two</span>
<span id="cb4-1439"><a href="#cb4-1439" aria-hidden="true" tabindex="-1"></a>positions that were also randomly ordered, they may have benefited from</span>
<span id="cb4-1440"><a href="#cb4-1440" aria-hidden="true" tabindex="-1"></a>experience with this type of sequencing, whereas the constant groups had</span>
<span id="cb4-1441"><a href="#cb4-1441" aria-hidden="true" tabindex="-1"></a>no experience with switching between positions trial to trial. This</span>
<span id="cb4-1442"><a href="#cb4-1442" aria-hidden="true" tabindex="-1"></a>concern is somewhat ameliorated by the fact that the testing phase</span>
<span id="cb4-1443"><a href="#cb4-1443" aria-hidden="true" tabindex="-1"></a>performance of the constant groups from their trained position was <span class="kw">not</span></span>
<span id="cb4-1444"><a href="#cb4-1444" aria-hidden="true" tabindex="-1"></a>significantly worse than their <span class="dv">level</span> of performance at the end of the</span>
<span id="cb4-1445"><a href="#cb4-1445" aria-hidden="true" tabindex="-1"></a>training phase, suggesting that they were <span class="kw">not</span> harmed by random ordering</span>
<span id="cb4-1446"><a href="#cb4-1446" aria-hidden="true" tabindex="-1"></a>of positions during testing. It should also be noted that the</span>
<span id="cb4-1447"><a href="#cb4-1447" aria-hidden="true" tabindex="-1"></a>computerized task utilized in the present work is relatively simple</span>
<span id="cb4-1448"><a href="#cb4-1448" aria-hidden="true" tabindex="-1"></a>compared to many of the real-world tasks utilized in prior research. It</span>
<span id="cb4-1449"><a href="#cb4-1449" aria-hidden="true" tabindex="-1"></a>is thus conceivable that the effect of variability in more complex tasks</span>
<span id="cb4-1450"><a href="#cb4-1450" aria-hidden="true" tabindex="-1"></a>is distinct from the process put forward in the present work. An</span>
<span id="cb4-1451"><a href="#cb4-1451" aria-hidden="true" tabindex="-1"></a>important challenge for future work will be to assess the extent to</span>
<span id="cb4-1452"><a href="#cb4-1452" aria-hidden="true" tabindex="-1"></a>which IGAS can account for generalization in relatively complex tasks</span>
<span id="cb4-1453"><a href="#cb4-1453" aria-hidden="true" tabindex="-1"></a>with far more degrees of freedom.</span>
<span id="cb4-1454"><a href="#cb4-1454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1455"><a href="#cb4-1455" aria-hidden="true" tabindex="-1"></a>It is common for psychological process models of categorization learning</span>
<span id="cb4-1456"><a href="#cb4-1456" aria-hidden="true" tabindex="-1"></a>to use an approach such as multidimensional scaling so as to transform</span>
<span id="cb4-1457"><a href="#cb4-1457" aria-hidden="true" tabindex="-1"></a>the stimuli from the physical dimensions used in the particular task</span>
<span id="cb4-1458"><a href="#cb4-1458" aria-hidden="true" tabindex="-1"></a>into the psychological dimensions more reflective of the actual human</span>
<span id="cb4-1459"><a href="#cb4-1459" aria-hidden="true" tabindex="-1"></a>representations [@nosofskySimilarityScalingCognitive1992<span class="op">;</span> <span class="im">@shepardUniversalLawGeneralization1987</span>]. Such scaling typically entails having participants rate the similarity between individual items</span>
<span id="cb4-1460"><a href="#cb4-1460" aria-hidden="true" tabindex="-1"></a><span class="kw">and</span> using these similarity judgements to then compute the psychological</span>
<span id="cb4-1461"><a href="#cb4-1461" aria-hidden="true" tabindex="-1"></a>distances between stimuli, which can then be fed into a subsequent</span>
<span id="cb4-1462"><a href="#cb4-1462" aria-hidden="true" tabindex="-1"></a>model. In the present investigation, there was no such way to scale the</span>
<span id="cb4-1463"><a href="#cb4-1463" aria-hidden="true" tabindex="-1"></a>x <span class="kw">and</span> y velocity components in terms of the psychological similarity,</span>
<span id="cb4-1464"><a href="#cb4-1464" aria-hidden="true" tabindex="-1"></a><span class="kw">and</span> thus our modelling does rely on the assumption that the</span>
<span id="cb4-1465"><a href="#cb4-1465" aria-hidden="true" tabindex="-1"></a>psychological distances between the different throwing positions are</span>
<span id="cb4-1466"><a href="#cb4-1466" aria-hidden="true" tabindex="-1"></a>proportional to <span class="dv">absolute</span> distances in the metric space of the task (e.g.</span>
<span id="cb4-1467"><a href="#cb4-1467" aria-hidden="true" tabindex="-1"></a>the <span class="dv">relative</span> distance between positions <span class="dv">400</span> <span class="kw">and</span> <span class="dv">500</span> is equivalent to</span>
<span id="cb4-1468"><a href="#cb4-1468" aria-hidden="true" tabindex="-1"></a>that between <span class="dv">800</span> <span class="kw">and</span> <span class="dv">900</span>). However, an advantage of our approach is that</span>
<span id="cb4-1469"><a href="#cb4-1469" aria-hidden="true" tabindex="-1"></a>we are measuring similarity in terms of how participants behave</span>
<span id="cb4-1470"><a href="#cb4-1470" aria-hidden="true" tabindex="-1"></a>(applying a velocity to the ball), rather than the metric features of</span>
<span id="cb4-1471"><a href="#cb4-1471" aria-hidden="true" tabindex="-1"></a>the task stimuli.</span>
<span id="cb4-1472"><a href="#cb4-1472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1473"><a href="#cb4-1473" aria-hidden="true" tabindex="-1"></a>## Conclusion</span>
<span id="cb4-1474"><a href="#cb4-1474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1475"><a href="#cb4-1475" aria-hidden="true" tabindex="-1"></a>Our experiments demonstrate a reliable benefit of varied training in a</span>
<span id="cb4-1476"><a href="#cb4-1476" aria-hidden="true" tabindex="-1"></a>simple projectile launching task. Such results were accounted for by an</span>
<span id="cb4-1477"><a href="#cb4-1477" aria-hidden="true" tabindex="-1"></a>instance-based model that assumes that varied training results in the</span>
<span id="cb4-1478"><a href="#cb4-1478" aria-hidden="true" tabindex="-1"></a>computation of a broader similarity-based generalization gradient.</span>
<span id="cb4-1479"><a href="#cb4-1479" aria-hidden="true" tabindex="-1"></a>Instance-based models augmented with this assumption may be a valuable</span>
<span id="cb4-1480"><a href="#cb4-1480" aria-hidden="true" tabindex="-1"></a>approach towards better understanding skill generalization <span class="kw">and</span> transfer.</span>
<span id="cb4-1481"><a href="#cb4-1481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1482"><a href="#cb4-1482" aria-hidden="true" tabindex="-1"></a>## References</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>