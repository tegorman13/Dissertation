<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.28">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Dissertation – introduction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../Sections/IGAS.html" rel="next">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../Assets/Style/calloutTG.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../Sections/Introduction.html">Intro</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Dissertation</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tegorman13/Dissertation" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dissertation</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../paper.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dissertation Manuscript</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Sections/full.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Full Dissertation</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Sections/Introduction.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Intro</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Sections/IGAS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">IGAS Project</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Sections/HTW.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">HTW Project</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Sections/Discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">General Discussion</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    <div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="d_intro_hugo.md"><i class="bi bi-file-code"></i>CommonMark (hugo)</a></li><li><a href="d_into_gfm.md"><i class="bi bi-file-code"></i>Github (GFM)</a></li></ul></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">




<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The past century of research on human learning has produced ample evidence that although learners can improve at almost any task, such improvements are often specific to the trained task, with unreliable or even nonexistent transfer or generalization to novel tasks or conditions <span class="citation" data-cites="barnettWhenWhereWe2002 dettermanCaseProsecutionTransfer1993">(<a href="#ref-barnettWhenWhereWe2002" role="doc-biblioref">Barnett &amp; Ceci, 2002</a>; <a href="#ref-dettermanCaseProsecutionTransfer1993" role="doc-biblioref">Detterman, 1993</a>)</span>. Such generalization challenges are of noteworthy practical relevance, given that educators, trainers, and rehabilitators typically intend for their students to be able to apply what they have learned to new situations. It is therefore important to better understand the factors that influence generalization, and to develop cognitive models that can predict when generalization is likely to occur. Such characteristics have included training difficulty, spacing, temporal order, feedback schedules, and the primary focus of the current work - the variability of training examples.</p>
<section id="the-study-of-variability" class="level2">
<h2 class="anchored" data-anchor-id="the-study-of-variability">The study of variability</h2>
<p>Varied training has been shown to influence learning in wide array of different tasks and domains, including categorization <span class="citation" data-cites="hahnEffectsCategoryDiversity2005 maddoxStimulusRangeDiscontinuity2011 posnerGenesisAbstractIdeas1968 nosofskyModelguidedSearchOptimal2019">(<a href="#ref-hahnEffectsCategoryDiversity2005" role="doc-biblioref">Hahn et al., 2005</a>; <a href="#ref-maddoxStimulusRangeDiscontinuity2011" role="doc-biblioref">Maddox &amp; Filoteo, 2011</a>; <a href="#ref-nosofskyModelguidedSearchOptimal2019" role="doc-biblioref">Nosofsky et al., 2019</a>; <a href="#ref-posnerGenesisAbstractIdeas1968" role="doc-biblioref">Posner &amp; Keele, 1968</a>)</span>, language learning <span class="citation" data-cites="jonesDensityDistinctivenessEarly2020 perryLearnLocallyThink2010 twomeyAllRightNoises2018 wonnacottInputEffectsAcquisition2012">(<a href="#ref-jonesDensityDistinctivenessEarly2020" role="doc-biblioref">Jones &amp; Brandt, 2020</a>; <a href="#ref-perryLearnLocallyThink2010" role="doc-biblioref">Perry et al., 2010</a>; <a href="#ref-twomeyAllRightNoises2018" role="doc-biblioref">Twomey et al., 2018</a>; <a href="#ref-wonnacottInputEffectsAcquisition2012" role="doc-biblioref">Wonnacott et al., 2012</a>)</span>, anagram completion <span class="citation" data-cites="goodeSuperiorityVariableRepeated2008">(<a href="#ref-goodeSuperiorityVariableRepeated2008" role="doc-biblioref">Goode et al., 2008</a>)</span>, trajectory extrapolation <span class="citation" data-cites="fulvioTaskSpecificResponseStrategy2014">(<a href="#ref-fulvioTaskSpecificResponseStrategy2014" role="doc-biblioref">Fulvio et al., 2014</a>)</span>, task switching <span class="citation" data-cites="sabahWhenLessMore2019">(<a href="#ref-sabahWhenLessMore2019" role="doc-biblioref">Sabah et al., 2019</a>)</span>, associative learning <span class="citation" data-cites="leeEvidentialDiversityIncreases2019">(<a href="#ref-leeEvidentialDiversityIncreases2019" role="doc-biblioref">J. C. Lee et al., 2019</a>)</span>, visual search <span class="citation" data-cites="georgeStimulusVariabilityTask2021 gonzalezDiversityTrainingEnhances2011 kelleyLearningAttendEffects2009">(<a href="#ref-georgeStimulusVariabilityTask2021" role="doc-biblioref">George &amp; Egner, 2021</a>; <a href="#ref-gonzalezDiversityTrainingEnhances2011" role="doc-biblioref">Gonzalez &amp; Madhavan, 2011</a>; <a href="#ref-kelleyLearningAttendEffects2009" role="doc-biblioref">Kelley &amp; Yantis, 2009</a>)</span>, voice identity learning <span class="citation" data-cites="lavanEffectsHighVariability2019">(<a href="#ref-lavanEffectsHighVariability2019" role="doc-biblioref">Lavan et al., 2019</a>)</span>, simple motor learning <span class="citation" data-cites="braunMotorTaskVariation2009 kerrSpecificVariedPractice1978 rollerVariablePracticeLenses2001 willeyLimitedGeneralizationVaried2018">(<a href="#ref-braunMotorTaskVariation2009" role="doc-biblioref">Braun et al., 2009</a>; <a href="#ref-kerrSpecificVariedPractice1978" role="doc-biblioref">Kerr &amp; Booth, 1978</a>; <a href="#ref-rollerVariablePracticeLenses2001" role="doc-biblioref">Roller et al., 2001</a>; <a href="#ref-willeyLimitedGeneralizationVaried2018" role="doc-biblioref">Willey &amp; Liu, 2018a</a>)</span>, sports training <span class="citation" data-cites="greenPracticeVariabilityTransfer1995a northEffectConsistentVaried2019">(<a href="#ref-greenPracticeVariabilityTransfer1995a" role="doc-biblioref">Green et al., 1995</a>; <a href="#ref-northEffectConsistentVaried2019" role="doc-biblioref">North et al., 2019</a>)</span>, and training on a complex video game <span class="citation" data-cites="seowTransferEffectsVaried2019">(<a href="#ref-seowTransferEffectsVaried2019" role="doc-biblioref">Seow et al., 2019</a>)</span>. See <span class="citation" data-cites="czyzVariabilityPracticeInformation2021">Czyż (<a href="#ref-czyzVariabilityPracticeInformation2021" role="doc-biblioref">2021</a>)</span> or <span class="citation" data-cites="ravivHowVariabilityShapes2022">Raviv et al. (<a href="#ref-ravivHowVariabilityShapes2022" role="doc-biblioref">2022</a>)</span> for more detailed reviews.</p>
<p>Research on the effects of varied training typically manipulates variability in one of two ways. In the first approach, a high variability group is exposed to a greater number of unique instances during training, while a low variability group receives fewer unique instances with more repetitions. Alternatively, both groups may receive the same number of unique instances, but the high variability group’s instances are more widely distributed or spread out in the relevant psychological space, while the low variability group’s instances are clustered more tightly together. Researchers then compare the training groups in terms of their performance during the training phase, as well as their generalization performance during a testing phase. Researchers will usually compare the performance of the two groups during both the training phase and a subsequent testing phase. The primary theoretical interest is often to assess the influence of training variability on generalization to novel testing items or conditions. However, the test may also include some or all of the items that were used during the training stage, allowing for an assessment of whether the variability manipulation influenced the learning of the trained items themselves, or to make it easy to measure how much performance degrades as a function of how far away testing items are from the training items.</p>
<p>The influence of training variation has received a large amount of attention in the domain of sensorimotor skill learning. Much of this research has been influenced by the work of (<span class="citation" data-cites="schmidtSchemaTheoryDiscrete1975">Schmidt (<a href="#ref-schmidtSchemaTheoryDiscrete1975" role="doc-biblioref">1975</a>)</span>), who proposed a schema-based account of motor learning as an attempt to address the longstanding problem of how novel movements are produced. Schema theory presumes that learners possess general motor programs for a class of movements (e.g.&nbsp;an underhand throw). When called up for use motor programs are parameterized by schema rules which determine how the motor program is parameterized or scaled to the particular demands of the current task. Schema theory predicts that variable training facilitates the formation of more robust schemas, which will result in improved generalization or transfer. Experiments that test this hypothesis are often designed to compare the transfer performance of a constant-trained group against that of a varied-trained group. Both groups train on the same task, but the varied group practices with multiple instances along some task-relevant dimension that remains invariant for the constant group. For example, studies using a projectile throwing task might assign participants to either constant training that practicing throwing from a single location, and a varied group that throws from multiple locations. Following training, both groups are then tested from novel throwing locations <span class="citation" data-cites="pigottMotorSchemaStructure1984 willeyLimitedGeneralizationVaried2018 pachecoLearningSpecificIndividual2018 wulfEffectTypePractice1991">(<a href="#ref-pachecoLearningSpecificIndividual2018" role="doc-biblioref">Pacheco &amp; Newell, 2018</a>; <a href="#ref-pigottMotorSchemaStructure1984" role="doc-biblioref">Pigott &amp; Shapiro, 1984</a>; <a href="#ref-willeyLimitedGeneralizationVaried2018" role="doc-biblioref">Willey &amp; Liu, 2018a</a>; <a href="#ref-wulfEffectTypePractice1991" role="doc-biblioref">Wulf, 1991</a>)</span>.</p>
<p>One of the earliest, and still often cited investigations of Schmidt’s benefits of variability hypothesis was the work of <span class="citation" data-cites="kerrSpecificVariedPractice1978">Kerr &amp; Booth (<a href="#ref-kerrSpecificVariedPractice1978" role="doc-biblioref">1978</a>)</span>. Two groups of children, aged 8 and 12, were assigned to either constant or varied training of a bean bag throwing task. The constant group practiced throwing a bean-bag at a small target placed 3 feet in front of them, and the varied group practiced throwing from a distance of both 2 feet and 4 feet. Participants were blindfolded and unable to see the target while making each throw but would receive feedback by looking at where the beanbag had landed in between each training trial. 12 weeks later, all of the children were given a final test from a distance of 3 feet which was novel for the varied participants and repeated for the constant participants. Participants were also blindfolded for testing and did not receive trial by trial feedback in this stage. However, at the halfway point of the testing stage they were allowed to see the landing location of the 4 beanbags they had thrown, and then completed the final 4 testing throws. In both age groups, participants performed significantly better in the varied condition than the constant condition, though the effect was larger for the younger, 8-year-old children. Although this design does not directly assess the hypothesis of varied training producing superior generalization to constant training (since the constant group is not tested from a novel position), it nevertheless offers a compelling example of the merits of varied practice.</p>
<p>On occasion the Kerr and Booth design may be nested within a larger experimental design. One such study that used a movement timing task, wherein subjects had to move their hand from a starting location, to a target location, attempting to arrive at the target location at specific time following the onset of a cue <span class="citation" data-cites="wrisbergVariabilityPracticeHypothesis1987">(<a href="#ref-wrisbergVariabilityPracticeHypothesis1987" role="doc-biblioref">Wrisberg et al., 1987</a>)</span>. This study utilized 4 different constant groups, and 3 varied groups, with one of the constant groups training under conditions identical to the testing conditions, and which were not trained on by any of the varied groups, e.g.&nbsp;the design of Kerr and Booth. However, in this case the varied group did not outperform the constant group.</p>
<p>Some support for the Kerr and Booth findings was found with a relatively less common experimental task of training participants in hitting a projectile at a target with the use of a racket <span class="citation" data-cites="greenPracticeVariabilityTransfer1995a">(<a href="#ref-greenPracticeVariabilityTransfer1995a" role="doc-biblioref">Green et al., 1995</a>)</span>. Varied participants trained with tennis, squash, badminton, and short-tennis rackets were compared against constant subjects trained with only a tennis racket. One of the testing conditions had subjects repeat the use of the tennis racket, which had been used on all 128 training trials for the constant group, and only 32 training trials for the varied group. Nevertheless, the varied group outperformed the constant group when using the tennis racket at testing, and also performed better in conditions with several novel racket lengths. Of course, this finding is less surprising than that of Kerr &amp; Booth, given that varied subjects did have some prior exposure to the constant groups condition. This highlights an issue rarely discussed in the literature, of how much practice from an additional position might be necessary to induce benefits. Experimenters almost uniformly have varied participants train with an equivalent number of trials from each of their conditions</p>
<p>One of the few studies that has replicated the surprising result of varied outperforming constant, from the constant training condition, did so in the relatively distant domain of verbal manipulation <span class="citation" data-cites="goodeSuperiorityVariableRepeated2008">(<a href="#ref-goodeSuperiorityVariableRepeated2008" role="doc-biblioref">Goode et al., 2008</a>)</span>. All participants trained to solve anagrams of 40 different words ranging in length from 5 to 11 letters, with an anagram of each word repeated 3 times throughout training, for a total of 120 training trials. Although subjects in all conditions were exposed to the same 40 unique words (i.e.&nbsp;the solution to an anagram), participants in the varied group saw 3 different arrangements for each solution-word, such as DOLOF, FOLOD, and OOFLD for the solution word FLOOD, whereas constant subjects would train on three repetitions of LDOOF (spread evenly across training). Two different constant groups were used. Both constant groups trained with three repetitions of the same word scramble, but for constant group A, the testing phase consisted of the identical letter arrangement to that seen during training (e.g.&nbsp;LDOOF), whereas for constant group B, the testing phase consisted of a arrangement they had not seen during training, thus presenting them with a testing situation similar situation to the varied group. At the testing stage, the varied group outperformed both constant groups, a particularly impressive result, given that constant group A had 3 prior exposures to the word arrangement (i.e.&nbsp;the particular permutation of letters) which the varied group had not explicitly seen. However varied subjects in this study did not exhibit the typical decrement in the training phase typical of other varied manipulations in the literature, and actually achieved higher levels of anagram solving accuracy by the end of training than either of the constant groups – solving 2 more anagrams on average than the constant group. This might suggest that for tasks of this nature where the learner can simply get stuck with a particular word scramble, repeated exposure to the identical scramble might be less helpful towards finding the solution than being given a different arrangement of the same letters. This contention is supported by the fact that constant group A, who was tested on the identical arrangement as they experienced during training, performed no better at testing than did constant group B, who had trained on a different arrangement of the same word solution – further suggesting that there may not have been a strong identity advantage in this task.</p>
<p>Pitting varied against constant practice against each other on the home turf of the constant group provides a compelling argument for the benefits of varied training, as well as an interesting challenge for theoretical accounts that posit generalization to occur as some function of distance. However, despite its appeal this particular contrast is relatively uncommon in the literature. It is unclear whether this may be cause for concern over publication bias, or just researchers feeling the design is too risky. A far more common design is to have separate constant groups that each train exclusively from each of the conditions that the varied group encounters <span class="citation" data-cites="catalanoDistantTransferCoincident1984a chuaPracticeVariabilityPromotes2019 newellVariabilityPracticeTransfer1976 moxleySchemaVariabilityPractice1979 mccrackenTestSchemaTheory1977">(<a href="#ref-catalanoDistantTransferCoincident1984a" role="doc-biblioref">Catalano &amp; Kleiner, 1984</a>; <a href="#ref-chuaPracticeVariabilityPromotes2019" role="doc-biblioref">Chua et al., 2019</a>; <a href="#ref-mccrackenTestSchemaTheory1977" role="doc-biblioref">McCracken &amp; Stelmach, 1977</a>; <a href="#ref-moxleySchemaVariabilityPractice1979" role="doc-biblioref">Moxley, 1979</a>; <a href="#ref-newellVariabilityPracticeTransfer1976" role="doc-biblioref">Newell &amp; Shapiro, 1976</a>)</span>, or for a single constant group to train from just one of the conditions experienced by the varied participants <span class="citation" data-cites="pigottMotorSchemaStructure1984 rollerVariablePracticeLenses2001 wrisbergTrainingProductionNovel1984 wrisbergDevelopingCoincidentTiming1983">(<a href="#ref-pigottMotorSchemaStructure1984" role="doc-biblioref">Pigott &amp; Shapiro, 1984</a>; <a href="#ref-rollerVariablePracticeLenses2001" role="doc-biblioref">Roller et al., 2001</a>; <a href="#ref-wrisbergTrainingProductionNovel1984" role="doc-biblioref">Wrisberg &amp; McLean, 1984</a>; <a href="#ref-wrisbergDevelopingCoincidentTiming1983" role="doc-biblioref">Wrisberg &amp; Mead, 1983</a>)</span>. A less common contrast places the constant group training in a region of the task space outside of the range of examples experienced by the varied group, but distinct from the transfer condition <span class="citation" data-cites="wrisbergVariabilityPracticeHypothesis1987 wulfVariabilityPracticeImplicit1997">(<a href="#ref-wrisbergVariabilityPracticeHypothesis1987" role="doc-biblioref">Wrisberg et al., 1987</a>; <a href="#ref-wulfVariabilityPracticeImplicit1997" role="doc-biblioref">Wulf &amp; Schmidt, 1997</a>)</span>.</p>
<p>Of particular relevant to the current essay is the early work of <span class="citation" data-cites="catalanoDistantTransferCoincident1984a">Catalano &amp; Kleiner (<a href="#ref-catalanoDistantTransferCoincident1984a" role="doc-biblioref">1984</a>)</span>, as theirs was one of the earliest studies to investigate the influence of varied vs.&nbsp;constant training on multiple testing locations of graded distance from the training condition. Participants were trained on coincident timing task, in which subjects observe a series of lightbulbs turning on sequentially at a consistent rate and attempt to time a button response with the onset of the final bulb. The constant groups trained with a single velocity of either 5,7,9, or 11 mph, while the varied group trained from all 4 of these velocities. Participants were then assigned to one of four possible generalization conditions, all of which fell outside of the range of the varied training conditions – 1, 3, 13 or 15 mph. As is often the case, the varied group performed worse during the training phase. In the testing phase, the general pattern was for all participants to perform worse as the testing conditions became further away from the training conditions, but since the drop off in performance as a function of distance was far less steep for the varied group, the authors suggested that varied training induced a decremented generalization gradient, such that the varied participants were less affected by the change between training and testing conditions.</p>
<p>A more recent study attempting a slightly more direct replication of the original Kerr &amp; Booth study <span class="citation" data-cites="willeyLongtermMotorLearning2018">(<a href="#ref-willeyLongtermMotorLearning2018" role="doc-biblioref">Willey &amp; Liu, 2018b</a>)</span>, having subjects throw beanbags at a target, with the varied group training from positions (5 and 9 feet) on either side of the constant group (7 feet). However, this study diverged from the original in that the participants were adults; they faced away from the target and threw the beanbag backwards over their bodies; they alternated using their right and left hands every 6 trials; and underwent a relatively extreme amount of training (20 sessions with 60 practice trials each, spread out over 5-7 weeks). Like <span class="citation" data-cites="wrisbergVariabilityPracticeHypothesis1987">Wrisberg et al. (<a href="#ref-wrisbergVariabilityPracticeHypothesis1987" role="doc-biblioref">1987</a>)</span>, this study did not find a varied advantage from the constant training position, though the varied group did perform better at distances novel to both groups.</p>
<p>Of course, the relationship between training variability and transfer is unlikely to be a simple function wherein increased variation is always beneficial. Numerous studies have found null, or in some cases negative effects of training variation <span class="citation" data-cites="deloshExtrapolationSineQua1997 sinkeviciuteRoleInputVariability2019 wrisbergVariabilityPracticeHypothesis1987">(<a href="#ref-deloshExtrapolationSineQua1997" role="doc-biblioref">DeLosh et al., 1997</a>; <a href="#ref-sinkeviciuteRoleInputVariability2019" role="doc-biblioref">Sinkeviciute et al., 2019</a>; <a href="#ref-wrisbergVariabilityPracticeHypothesis1987" role="doc-biblioref">Wrisberg et al., 1987</a>)</span>, and many more have suggested that the benefits of variability may depend on additional factors such as prior task experience, the order of training trials, or the type of transfer being measured <span class="citation" data-cites="bernikerEffectsTrainingBreadth2014 braithwaiteEffectsVariationPrior2015 hahnEffectsCategoryDiversity2005 lavanEffectsHighVariability2019 northEffectConsistentVaried2019 sadakataIndividualAptitudeMandarin2014 zamanPerceptualVariabilityImplications2021">(<a href="#ref-bernikerEffectsTrainingBreadth2014" role="doc-biblioref">Berniker et al., 2014</a>; <a href="#ref-braithwaiteEffectsVariationPrior2015" role="doc-biblioref">Braithwaite &amp; Goldstone, 2015</a>; <a href="#ref-hahnEffectsCategoryDiversity2005" role="doc-biblioref">Hahn et al., 2005</a>; <a href="#ref-lavanEffectsHighVariability2019" role="doc-biblioref">Lavan et al., 2019</a>; <a href="#ref-northEffectConsistentVaried2019" role="doc-biblioref">North et al., 2019</a>; <a href="#ref-sadakataIndividualAptitudeMandarin2014" role="doc-biblioref">Sadakata &amp; McQueen, 2014</a>; <a href="#ref-zamanPerceptualVariabilityImplications2021" role="doc-biblioref">Zaman et al., 2021</a>)</span>.</p>
</section>
<section id="variability-literature-review" class="level2">
<h2 class="anchored" data-anchor-id="variability-literature-review">Variability Literature Review</h2>
<p>An early and influential work on the influence of variability on category learning is that of <span class="citation" data-cites="posnerGenesisAbstractIdeas1968">Posner &amp; Keele (<a href="#ref-posnerGenesisAbstractIdeas1968" role="doc-biblioref">1968</a>)</span>. In an ambitious attempt to address the question of how category information is represented, the authors trained participants to categorize artificial dot patterns, manipulating whether learners were exposed to examples clustered close to the category prototypes (e.g.&nbsp;a low variability condition), or spread further away from the prototype (the varied-training group). It should be noted that both groups in this study were trained with the same number of unique instances and the manipulated difference was how spread out the instances were. The authors claim based on prior experiments using the same stimuli, that the training stimuli for the varied group were at least as far away from the testing stimuli as the training stimuli of the less-varied group. The authors interpreted their findings as evidence for the extraction of an abstraction or schema that is extracted and stored, and then over time becomes more likely to be the reference point from which generalization occurs, given that specific instances are thought to decay at a faster rate than prototypes or schema. The Posner and Keele study has been extremely influential and continues to be cited in contemporary research as clear evidence that schema abstraction underlies the benefits of varied training. It’s also referenced as a key influence in the development of “Schema Theory of Motor Learning” <span class="citation" data-cites="schmidtSchemaTheoryDiscrete1975">(<a href="#ref-schmidtSchemaTheoryDiscrete1975" role="doc-biblioref">Schmidt, 1975</a>)</span>, which in turn influenced decades of investigations on the potential benefits of varied training in motor skill learning. However, the classic Posner &amp; Keele study despite being far more carefully designed than many subsequent studies, and despite being a relative rarity in explicitly discussing and attempting to control for potential confounds of similarity between groups, may nevertheless be emblematic of a common issue in many investigations of the effects of varied training on learning. The problem with Posner &amp; Keele’s conclusion was demonstrated clearly almost 3 decades later <span class="citation" data-cites="palmeriCentralTendenciesExtreme2001">(<a href="#ref-palmeriCentralTendenciesExtreme2001" role="doc-biblioref">Palmeri &amp; Nosofsky, 2001</a>)</span>, when researchers conducting a near replication of the original study also collected similarity judgements following training and performed multidimensional scaling analysis. Rather than being in the middle of the training stimuli as was the case in the physical stimuli space, the psychological representation of the prototype was shown reside at an extreme point, and generalization patterns by participants that would have seemed to warrant the learning of a prototype were then easily accounted for with only the assumption that the participants encoded instances. One of the primary concerns of the present paper is that many of the studies which purport to explain the benefits of variation via prototypes, schemas, or other abstractions, are often overlooking the potential of instance based similarity accounts.</p>
</section>
<section id="motor-skill-learning" class="level2">
<h2 class="anchored" data-anchor-id="motor-skill-learning">Motor skill learning</h2>
<p>Training variation has also been shown to promote transfer in motor learning. Much of this research has been influenced by the work of <span class="citation" data-cites="schmidtSchemaTheoryDiscrete1975">(<a href="#ref-schmidtSchemaTheoryDiscrete1975" role="doc-biblioref">Schmidt, 1975</a>)</span>, who proposed a schema-based account of motor learning as an attempt to address the longstanding problem of how novel movements are produced. Schema theory presumes a priori that learners possess general motor programs for classes of movements, such as an underhand throw. When called up for use, such programs must be parameterized, as well as schema rules that determine how a motor program is parameterized or scaled for a particular movement. Schema theory predicts that varied training results in the formation of a more general schema-rule, which can allow for transfer to novel movements within a given movement class, such as an underhand throw (though it is agnostic to the development of the movement classes themselves). Experiments that test this hypothesis are often designed to compare the transfer performance of a constant-trained group against that of a varied-trained group. Both groups train on the same task, but the varied group practices with multiple instances along some task-relevant dimension that remains invariant for the constant group. For example, investigators might train two groups of participants to throw a projectile at a target, with a constant group that throws from a single location, and a varied group that throws from multiple locations. Both groups are then tested from novel locations.</p>
</section>
<section id="category-learning" class="level2">
<h2 class="anchored" data-anchor-id="category-learning">Category learning</h2>
<p>In the category learning literature, the constant vs.&nbsp;varied comparison is much less suitable. Instead, researchers tend to compare a condition with many repetitions of a few items against condition with fewer repetitions of a wider array of exemplars. Much of the earlier work in this sub-area trained subjects on artificial categories, such as dot patterns <span class="citation" data-cites="homaCategoryBreadthAbstraction1976 posnerGenesisAbstractIdeas1968">(<a href="#ref-homaCategoryBreadthAbstraction1976" role="doc-biblioref">Homa &amp; Vosburgh, 1976</a>; <a href="#ref-posnerGenesisAbstractIdeas1968" role="doc-biblioref">Posner &amp; Keele, 1968</a>)</span>, where more varied or distorted training examples were often shown to produce superior generalization when categorizing novel exemplars. More recently, researchers have also begun to utilize more realistic stimuli in their experiments. <span class="citation" data-cites="wahlheimMetacognitiveJudgmentsRepetition2012">Wahlheim et al. (<a href="#ref-wahlheimMetacognitiveJudgmentsRepetition2012" role="doc-biblioref">2012</a>)</span> conducted one such study. In a within-participants design, participants were trained on bird categories with either high repetitions of a few exemplars, or few repetitions of many exemplars. Across four different experiments, which were conducted to address an unrelated question on metacognitive judgements, the researchers consistently found that participants generalized better to novel species following training with more unique exemplars (i.e.&nbsp;higher variability), while high repetition training produced significantly better performance categorizing the specific species they had trained on. A variability advantage was also found in the relatively complex domain of rock categorization <span class="citation" data-cites="nosofskyModelguidedSearchOptimal2019">(<a href="#ref-nosofskyModelguidedSearchOptimal2019" role="doc-biblioref">Nosofsky et al., 2019</a>)</span>. For 10 different rock categories, participants were trained with either many repetitions of 3 unique examples of each category, or few repetitions of 9 unique examples, with an equal number of total training trials in each group (the design also included 2 other conditions less amenable to considering the impact of variation). The high-variability group, trained with 9 unique examples, showed significantly better generalization performance than the other conditions. Moreover, the pattern of results in this study could be nicely accounted for by an extended version of the Generalized Context Model.</p>
<p>The studies described thus far have studied the benefits of variability by exposing participants to a greater or lesser number of distinct examples during training. A distinct sub-literature within the category learning domain has focused much less on benefits derived from varied training, instead emphasizing how increased variability during the learning of a novel category influences how far the category boundary will then be generalized. The general approach is to train participants on examples from two categories, with the examples from one of the categories being more dispersed than the other. Participants are then tested with novel items located within ambiguous regions of the task space which allow the experimenters to assess whether the difference in variability influences how far participants generalize the category boundaries.</p>
<p><span class="citation" data-cites="cohenCategoryVariabilityExemplar2001">Cohen et al. (<a href="#ref-cohenCategoryVariabilityExemplar2001" role="doc-biblioref">2001</a>)</span> trained subjects on two categories, one with much more variability than the other. In experiment 1, a low variability category composed of 1 instance was compared against a high-variability category of 2 instances in one condition, and 7 instances in another. In experiment 2 both categories were composed of 3 instances, but for the low-variability group the instances were clustered close to each other, whereas the high-variability groups instances were spread much further apart. Participants were tested on an ambiguous novel instance that was located in between the two trained categories. Both experiments provided evidence that participants were much more likely to categorize the novel middle stimulus into a category with greater variation. Moreover, this effect was at odds with the predications of the baseline version of the GCM, thus providing some evidence that training variation may at least sometimes induce effects that cannot be entirely accounted for by exemplar-similarity accounts.</p>
<p>Further observations consonant with the results of <span class="citation" data-cites="cohenCategoryVariabilityExemplar2001">Cohen et al. (<a href="#ref-cohenCategoryVariabilityExemplar2001" role="doc-biblioref">2001</a>)</span> have since been observed in numerous investigations <span class="citation" data-cites="hahnEffectsCategoryDiversity2005 perlmanFurtherAttemptsClarify2012 sakamotoPuttingPsychologyBack2008 hsuEffectsGenerativeDiscriminative2010">(<a href="#ref-hahnEffectsCategoryDiversity2005" role="doc-biblioref">Hahn et al., 2005</a>; <a href="#ref-hsuEffectsGenerativeDiscriminative2010" role="doc-biblioref">Hsu &amp; Griffiths, 2010</a>; <a href="#ref-perlmanFurtherAttemptsClarify2012" role="doc-biblioref">Perlman et al., 2012</a>; <a href="#ref-sakamotoPuttingPsychologyBack2008" role="doc-biblioref">Sakamoto et al., 2008</a>)</span>. The results of <span class="citation" data-cites="sakamotoPuttingPsychologyBack2008">Sakamoto et al. (<a href="#ref-sakamotoPuttingPsychologyBack2008" role="doc-biblioref">2008</a>)</span> are noteworthy. They first reproduced the basic finding of participants being more likely to categorize an unknown middle stimulus into a training category with higher variability. In a second experiment, they held the variability between the two training categories constant and instead manipulated the training sequence, such that the examples of one category appeared in an ordered fashion, with very small changes from one example to the other (the stimuli were lines that varied only in length), whereas examples in the alternate category were shown in a random order and thus included larger jumps in the stimulus space from trial to trial. They found that the middle stimulus was more likely to be categorized into the category that had been learned with a random sequence, which was attributed to an increased perception of variability which resulted from the larger trial to trial discrepancies.</p>
<p>The work of <span class="citation" data-cites="hahnEffectsCategoryDiversity2005">Hahn et al. (<a href="#ref-hahnEffectsCategoryDiversity2005" role="doc-biblioref">2005</a>)</span>, is also of particular interest to the present discussion. Their experimental design was similar to previous studies, but they included a larger set of testing items which were used to assess generalization both between the two training categories as well as novel items located in the outer edges of the training categories. During generalization testing, participants were given the option to respond with “neither”, in addition to responses to the two training categories. The “neither” response was included to test how far away in the stimulus space participants would continue to categorize novel items as belonging to a trained category. Consistent with prior findings, high-variability training resulted in an increased probability of categorizing items in between the training categories as belong to the high variability category. Additionally, participants trained with higher variability also extended the category boundary further out into the periphery than participants trained with a lower variability category were willing to do. The authors then used the standard GCM framework to compare a variety of similarity-based models to account for their results. Of particular interest are their evaluations of a category response bias parameter, and a similarity scaling parameter. A model fit improvement when the response bias parameter is allowed to vary between the high-variability and low-variability trained groups is taken to suggest a simple bias for responding with one of the trained categories over the other. Alternatively, an improvement in fit due to a separate similarity scaling parameter may reflect the groups being differentially sensitive to the distances between stimuli. No improvement in model fit was found by allowing the response-bias parameter to differ between groups, however the model performance did improvement significantly when the similarity scaling parameter was fit separately. The best fitting similarity-scaling parameters were such that the high-variability group was less sensitive to the distances between stimuli, resulting in greater similarity values between their training items and testing items. This model accounted for both the extended generalization gradients of the varied particpants, and also for their poor performance in a recognition condition. Additional model comparisons suggested that this similarity rescaling applied across the entire stimulus space, rather than to the high variability category in particular.</p>
<p>Variability effects have also been examined in the higher-level domain of how learners acquire novel concepts, and then instantiate (rather than merely recognize) that concept in untrained contexts <span class="citation" data-cites="braithwaiteEffectsVariationPrior2015">(<a href="#ref-braithwaiteEffectsVariationPrior2015" role="doc-biblioref">Braithwaite &amp; Goldstone, 2015</a>)</span>. This study trained participants on problems involving the concept of sampling with replacement (SWR). Training consisted of examples that were either highly similar in their semantic context (e.g.&nbsp;all involving people selecting objects) or in which the surface features were varied between examples (e.g.&nbsp;people choosing objects AND objects selected in a sequence). The experimenters also surveyed how much prior knowledge each participant had with SWR. They found that whether variation was beneficial depended on the prior knowledge of the participants – such that participants with some prior knowledge benefited from varied training, whereas participants with minimal prior knowledge performed better after training with similar examples. The authors hypothesized that in order to benefit from varied examples, participants must be able to detect the structure common to the diverse examples, and that participants with prior knowledge are more likely to be sensitive to such structure, and thus to benefit from varied training. To test this hypothesis more directly, the authors conducted a 2nd experiment, wherein they controlled prior knowledge by exposing some subjects to a short graphical or verbal pre-training lesson, designed to increase sensitivity to the training examples. Consistent with their hypothesis, participants exposed to the structural sensitivity pre-training benefited more from varied training than the controls participants who benefited more from training with similar examples.</p>
<p>Variability has also been examined within the realm of language learning. A particularly impressive study is that of <span class="citation" data-cites="perryLearnLocallyThink2010">(<a href="#ref-perryLearnLocallyThink2010" role="doc-biblioref">Perry et al., 2010</a>)</span>. In nine training sessions spread out over nine weeks infants were trained on object labels in a naturalistic play setting. All infants were introduced to three novel objects of the same category, with participants in the tight condition being exposed to three similar exemplars of the category, and participants in the varied condition being exposed to three dissimilar objects of the same category. Importantly, the similarity of the objects was carefully controlled for by having a separate group of adult subjects provide pairwise similarity judgements of the category objects prior to the study onset. Multidimensional scaling was then performed to obtain the coordinates of the objects psychological space, and out of the 10 objects for each category, the 3 most similar objects were selected for the tight group and the three least similar objects for the varied group, with the leftover four objects being retained for testing. By the end of the nine weeks, all of the infants had learned the labels of the training objects. The varied group demonstrated superior ability to correctly generalize the object labels to untrained exemplars of the same category, a pattern consistent with much of the existing literature. More interesting was the superior performance of the varied group on a higher order generalization task – such that they were able to appropriately generalize the bias they had learned during training for attending to the shape of objects to novel solid objects, but not to non-solids. The tight training group, on the other hand, tended to overgeneralize the shape bias, leading the researchers to suggest that the varied training induced a more context-sensitive understanding of when to apply their knowledge.</p>
</section>
<section id="complications-to-the-influence-of-variability" class="level2">
<h2 class="anchored" data-anchor-id="complications-to-the-influence-of-variability">Complications to the influence of variability</h2>
<section id="sequence-effects" class="level3">
<h3 class="anchored" data-anchor-id="sequence-effects">Sequence Effects</h3>
<p>A necessary consequence of varied training is that participants will have the experience of switching from one task condition to another. The number of switches can vary greatly, with the two extremes being varied participants completing all of their training trials in one before switching to the next condition (blocked sequencing), or if they alternate between conditions on a trial by trial basis (random/intermixed/interleaved sequencing). Not long after the initial influx of schema-theory inspired studies testing the benefits of variability hypothesis was shown that the influence of varied training might interact with the type of training sequence chosen by the experimenter <span class="citation" data-cites="sheaContextualInterferenceEffects1979">(<a href="#ref-sheaContextualInterferenceEffects1979" role="doc-biblioref">J. B. Shea &amp; Morgan, 1979</a>)</span>. In this seminal study, both groups of training subjects trained with the same number of trials of three separate movement patterns. A blocked group that completed all of their trials with one sequence before beginning the next sequence, and a random group that trained with all three movement patterns interspersed throughout the course of training. Participants were also randomly assigned to retention testing under either blocked or random sequence conditions, thus resulting in all four training-testing combinations of blocked-blocked; blocked-random; random-blocked; random-random. There was some effect of sequence context, such that both groups performed better when the testing sequence matched their training sequence. However, the main finding of interest was the advantage of random-training, which resulted in superior testing performance than blocked training regardless of whether the testing stage had a blocked or random sequence, an effect observed both immediately after training, and in a follow up test ten days after the end of training.</p>
<p>Prior to the influential <span class="citation" data-cites="sheaContextualInterferenceEffects1979">J. B. Shea &amp; Morgan (<a href="#ref-sheaContextualInterferenceEffects1979" role="doc-biblioref">1979</a>)</span> study, studies investigating the benefits of variability hypothesis had utilized both blocked and random training schedules, often without comment or justification. It was later observed <span class="citation" data-cites="leeInfluencePracticeSchedule1985">(<a href="#ref-leeInfluencePracticeSchedule1985" role="doc-biblioref">Lee et al., 1985</a>)</span> that positive evidence for benefits of varied training seemed more likely to occur for studies that utilized random schedules. The theoretical basis of such studies was invariably an appeal to Schmidt’s schema theory; however schema theory made no clear predictions of an effect of study sequence on retention or generalization, thus prompting the need for alternate accounts. One such account, the elaborative processing account <span class="citation" data-cites="sheaContextEffectsMemory1983">(<a href="#ref-sheaContextEffectsMemory1983" role="doc-biblioref">J. B. Shea &amp; Zimny, 1983</a>)</span>, draws on the earlier work <span class="citation" data-cites="battigFacilitationInterference1966">(<a href="#ref-battigFacilitationInterference1966" role="doc-biblioref">Battig, 1966</a>)</span> and argues that randomly sequencing conditions during training promotes comparison and contrastive processes between those conditions, which result in a deeper understanding of the training task than could arise via blocked sequencing. Supporting evidence for elaborative processing comes in the form of random-sequence trained subjects self-reporting more nuanced mental representations of movement patterns following training <span class="citation" data-cites="sheaContextEffectsMemory1983">(<a href="#ref-sheaContextEffectsMemory1983" role="doc-biblioref">J. B. Shea &amp; Zimny, 1983</a>)</span>, and by manipulating whether subjects are able to perform comparisons during training <span class="citation" data-cites="wrightContributionElaborativeProcessing1992">(<a href="#ref-wrightContributionElaborativeProcessing1992" role="doc-biblioref">Wright et al., 1992</a>)</span>. An alternative, though not incompatible account suggests that the benefits of random-sequencing are a result of such sequences forcing the learner to continually reconstruct the relevant motor task in working memory <span class="citation" data-cites="leeLocusContextualInterference">(<a href="#ref-leeLocusContextualInterference" role="doc-biblioref">Lee &amp; Magill, n.d.</a>)</span>. Blocked training, on the other hand, allows the learner to maintain the same motor task in short term memory without decay for much of the training which facilitates training performance, but hinders ability to retrieve the appropriate motor memory in a later testing context. A much more recent study <span class="citation" data-cites="chuaPracticeVariabilityPromotes2019">(<a href="#ref-chuaPracticeVariabilityPromotes2019" role="doc-biblioref">Chua et al., 2019</a>)</span>, replicates the standard findings of an advantage of varied training over constant training (expt 1, bean-bag throwing task), and of random training over blocked training (expt 2 &amp; 3, bean-bag throwing &amp; golf putting). The novelty of this study is that the experimenters queried subjects about their attentional focus throughout the training stage. In all three experiments varied or random trained-subjects reported significantly greater external attention (e.g.&nbsp;attending to the target distance), and constant or blocked subjects reported more internal attention (e.g.&nbsp;posture or hand position). The authors argue that the benefits of varied/random training may be mediated by changes in attentional focus, however the claims made in the paper seem to go far beyond what can be justified by the analyses reported – e.g.&nbsp;the increased external focus could be a simple byproduct of varied training. A stronger form of evidence that was not provided may have been to use multiple regression analyses to show that the testing advantage of the varied/random groups over the constant/blocked groups could be accounted for by the differences in self-reported attentional focus.</p>
</section>
</section>
<section id="other-task-and-participant-effects" class="level2">
<h2 class="anchored" data-anchor-id="other-task-and-participant-effects">Other task and participant effects</h2>
<p>Of course, the effects of varied training, and different training sequences, are likely to be far more complex than simply more varied training being better than less, or random training being better than blocked. Null effects of both manipulations have been reported <span class="citation" data-cites="magillReviewContextualInterference1990 vanrossumSchmidtSchemaTheory1990">(see <a href="#ref-magillReviewContextualInterference1990" role="doc-biblioref">Magill &amp; Hall, 1990</a>; <a href="#ref-vanrossumSchmidtSchemaTheory1990" role="doc-biblioref">Van Rossum, 1990</a> for reviews)</span>, and a variety of moderators have emerged. In one of the earlier examples of the complex relationship between study sequence and learning <span class="citation" data-cites="delreyEffectsContextualInterference1982">(<a href="#ref-delreyEffectsContextualInterference1982" role="doc-biblioref">Del Rey et al., 1982</a>)</span>, experimenters recruited participants who self-reported either large amounts, or very little experience with athletic activities, and then trained participants on a coincident timing task under with either a single constant training velocity, or with four training velocities under either blocked, or random training sequence conditions - resulting in six experimental conditions: (athlete vs.&nbsp;non-athlete) x (constant vs.&nbsp;blocked vs.&nbsp;random training). Athlete participants had superior performance during training, regardless of sequence condition, and training performance was superior for all subjects in the constant group, followed by blocked training in the middle, and then random training resulting in the worst training performance. Of greater interest is the pattern of testing results for novel transfer conditions. Among the athlete-participants, transfer performance was best for those who received random training, followed by blocked, and then constant training. Non-athletes showed the opposite pattern, with superior performance for those who had constant training. A similar pattern was later observed in a golf-putting training study, wherein participants who had some prior golf experience benefited most from random-sequenced training, and participants with no golf experience benefited most from blocked training <span class="citation" data-cites="guadagnoliRelationshipContextualInterference1999">(<a href="#ref-guadagnoliRelationshipContextualInterference1999" role="doc-biblioref">Guadagnoli et al., 1999</a>)</span>. More recently, the same pattern was observed in the concept learning literature <span class="citation" data-cites="braithwaiteEffectsVariationPrior2015">(<a href="#ref-braithwaiteEffectsVariationPrior2015" role="doc-biblioref">Braithwaite &amp; Goldstone, 2015</a> expt 1.)</span>. This study trained participants on a mathematical concept and found that participants who self-reported some prior experience with the concept improved more from pre-test to post-test after training with varied examples, while participants who reported no prior experience showed greater gains following training with highly similar examples.</p>
<p>In addition to the influence of prior experiences described above, ample evidence also suggests that numerous aspects of the experiment may also interact with the influence of variation. One important study examined the impact of the amount of training completed in a force production task <span class="citation" data-cites="sheaContextualInterferenceContributions1990">(<a href="#ref-sheaContextualInterferenceContributions1990" role="doc-biblioref">C. H. Shea et al., 1990</a>)</span>. This study employed a typical blocked vs.&nbsp;random training procedure, but with the additional manipulation of separate groups receiving 50, 200, or 400 total training trials. For the group that received only 50 training trials retention was best when training had been blocked. However, for the conditions that received 200 or 400 training trials the pattern was reversed, with random training resulting in superior retention than blocked training. These results were taken to suggest that the benefits of randomization may take time to emerge. Another experimental factor shown to interact with training sequence is the complexity of the training task <span class="citation" data-cites="albaretDifferentialEffectsTask1998">(<a href="#ref-albaretDifferentialEffectsTask1998" role="doc-biblioref">Albaret &amp; Thon, 1998</a>)</span>. In addition to random or blocked training, participants in this study were assigned to train on a drawing task at one of three different levels of complexity (reproducing from memory shapes composed of two, three or four components). On a transfer task 48 hours after the completion of training, only participants trained at the lower levels of task complexity (2 or 3 components) showed superior performance to the blocked condition. The authors suggest that the benefits of random sequencing, thought to arise from more elaborate cognitive processing, or the necessity of continually recalling task information from long term into short term memory, are more likely to be obscured as the complexity of the task forces the blocked participants to also engage in such processes.</p>
<p>A final important influence of particular relevance to the practice-sequence literature concerns the exact structure of “random” sequencing. Although the term random is commonly used for convenience, experimenters do not typically leave the order of training entirely up to chance. Rather, the training sequence is often constrained such that each condition must occur a minimum number of times in each quartile of the training phase, thus resulting in an even distribution the conditions throughout training. While the assurance of the conditions being evenly spread throughout training is consistent across studies, other aspects of the sequence structure are a bit more idiosyncratic. Some researchers report setting a maximum number of consecutive repetitions, e.g.&nbsp;no more than 2 consecutive trials of the same condition <span class="citation" data-cites="delreyEffectsContextualInterference1982 sheaContextualInterferenceEffects1979">(<a href="#ref-delreyEffectsContextualInterference1982" role="doc-biblioref">Del Rey et al., 1982</a>; <a href="#ref-sheaContextualInterferenceEffects1979" role="doc-biblioref">J. B. Shea &amp; Morgan, 1979</a>)</span>, or structure the random trials such that the same condition never occurs consecutively <span class="citation" data-cites="wulfEffectTypePractice1991">(<a href="#ref-wulfEffectTypePractice1991" role="doc-biblioref">Wulf, 1991</a>)</span>. Also common is to structure experiments such that random condition really consists of many small blocks, where participants do a few trials of one condition consecutively and then switch to another condition <span class="citation" data-cites="willeyLongtermMotorLearning2018 chuaPracticeVariabilityPromotes2019 wrisbergVariabilityPracticeHypothesis1987">(<a href="#ref-chuaPracticeVariabilityPromotes2019" role="doc-biblioref">Chua et al., 2019</a>; <a href="#ref-willeyLongtermMotorLearning2018" role="doc-biblioref">Willey &amp; Liu, 2018b</a>; <a href="#ref-wrisbergVariabilityPracticeHypothesis1987" role="doc-biblioref">Wrisberg et al., 1987</a>)</span>, resulting in many more switches than would arise if training was perfectly blocked. The question of whether such differences in the structure of random sequencing are consequential has been addressed experimentally a few times, in all cases consisting of a 1) a no-repeat random condition; 2) a blocked random condition (typically 3 or 4 repeats before a switch); and 3) a standard fully-blocked condition. Blocked-random training resulted in better performance than either repeat-random, or fully - blocked training in both a bean-bag throwing <span class="citation" data-cites="pigottMotorSchemaStructure1984">(<a href="#ref-pigottMotorSchemaStructure1984" role="doc-biblioref">Pigott &amp; Shapiro, 1984</a>)</span>, and basketball shot training study <span class="citation" data-cites="landinComparisonThreePractice1997">(<a href="#ref-landinComparisonThreePractice1997" role="doc-biblioref">Landin &amp; Hebert, 1997</a>)</span>, and in a replication plus extension of the seminal <span class="citation" data-cites="sheaContextualInterferenceEffects1979">(<a href="#ref-sheaContextualInterferenceEffects1979" role="doc-biblioref">J. B. Shea &amp; Morgan, 1979</a>)</span> study, blocked-random training was equally effective as no-repeat random training, with both random structures leading to better performance than the fully-blocked training condition. Consequences on different study schedules have also been repeatedly observed in the category learning literature <span class="citation" data-cites="carvalhoSequenceStudyChanges2017 carvalhoPuttingCategoryLearning2014">(<a href="#ref-carvalhoPuttingCategoryLearning2014" role="doc-biblioref">Carvalho &amp; Goldstone, 2014</a>, <a href="#ref-carvalhoSequenceStudyChanges2017" role="doc-biblioref">2017</a>)</span>. This line of research has revealed that the effects of blocking vs.&nbsp;interleaving can depend on the structure of the category being learned, and also that the different schedules can result in the participants requiring different representations. A fruitful line of inquiry in the motor skill learning literature may be to attempt to identify whether structural aspects of the motor task interact with different training sequences in a reliable manner.</p>
<p>Numerous researchers have attempted to provide coherent frameworks to account for the full range of influences of training variation and sequencing described above (along with many other effects not discussed). Such accounts are generally quite similar, invoking ideas of desirable levels of difficulty <span class="citation" data-cites="bjorkNewTheoryDisuse1992 schmidtNewConceptualizationsPractice1992">(<a href="#ref-bjorkNewTheoryDisuse1992" role="doc-biblioref">Bjork &amp; Bjork, 1992</a>; <a href="#ref-schmidtNewConceptualizationsPractice1992" role="doc-biblioref">Schmidt &amp; Bjork, 1992</a>)</span>, or optimal challenge points <span class="citation" data-cites="guadagnoliChallengePointFramework2004">(<a href="#ref-guadagnoliChallengePointFramework2004" role="doc-biblioref">Guadagnoli &amp; Lee, 2004</a>)</span>. They tend to start by describing the dissociation between acquisition performance (performance during training) and testing performance (delayed retention and/or transfer), most strikingly observed as varied/random training participants performing worse than their constant/blocked counterparts during the training stage of the study, but then outperforming the constant/blocked comparisons at a later retention or transfer stage. This observation is then used to justify the idea that the most enduring and generalizable learning occurs by training at an optimal level of training difficulty, with difficulty being some function of the experience of the learner, and the cognitive or visuomotor processing demands of the task. It then follows that the factors that tend to make training more difficult (i.e.&nbsp;increased variability or randomization), are more likely to be beneficial when the learner has some experience, or when the processing demands of the task are not too extreme (which may only occur after some experience with the task). Such frameworks may be helpful heuristics in some cases, but they also seem to be overly flexible such that any null result of some intervention might be accounted for by a suboptimal amount of training trials, or by suggesting the training task was too difficult. The development of computational models that can account for how changes in the parameters of the motor-skill task scale with difficulty, would be a great step forward.</p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-albaretDifferentialEffectsTask1998" class="csl-entry" role="listitem">
Albaret, J.-M., &amp; Thon, B. (1998). Differential effects of task complexity on contextual interference in a drawing task. <em>Acta Psychologica</em>, <em>100</em>(1), 9–24. <a href="https://doi.org/10.1016/S0001-6918(98)00022-5">https://doi.org/10.1016/S0001-6918(98)00022-5</a>
</div>
<div id="ref-barnettWhenWhereWe2002" class="csl-entry" role="listitem">
Barnett, S. M., &amp; Ceci, S. J. (2002). When and where do we apply what we learn?: <span>A</span> taxonomy for far transfer. <em>Psychological Bulletin</em>, <em>128</em>(4), 612–637. <a href="https://doi.org/10.1037//0033-2909.128.4.612">https://doi.org/10.1037//0033-2909.128.4.612</a>
</div>
<div id="ref-battigFacilitationInterference1966" class="csl-entry" role="listitem">
Battig, W. F. (1966). Facilitation and interference. <em>Acquisition of Skill</em>, 215–244.
</div>
<div id="ref-bernikerEffectsTrainingBreadth2014" class="csl-entry" role="listitem">
Berniker, M., Mirzaei, H., &amp; Kording, K. P. (2014). The effects of training breadth on motor generalization. <em>Journal of Neurophysiology</em>, <em>112</em>(11), 2791–2798. <a href="https://doi.org/10.1152/jn.00615.2013">https://doi.org/10.1152/jn.00615.2013</a>
</div>
<div id="ref-bjorkNewTheoryDisuse1992" class="csl-entry" role="listitem">
Bjork, R. A., &amp; Bjork, E. L. (1992). A <span>New Theory</span> of <span>Disuse</span> and an <span>Old Theory</span> of <span>Stimulus Fluctuation</span>. In <em>Learning processes to cognitive processes: <span>Essays</span> in honor of <span>William K</span>. <span>Estes</span></em> (Vol. 2, pp. 35–67).
</div>
<div id="ref-braithwaiteEffectsVariationPrior2015" class="csl-entry" role="listitem">
Braithwaite, D. W., &amp; Goldstone, R. L. (2015). Effects of <span>Variation</span> and <span>Prior Knowledge</span> on <span>Abstract Concept Learning</span>. <em>Cognition and Instruction</em>, <em>33</em>(3), 226–256. <a href="https://doi.org/10.1080/07370008.2015.1067215">https://doi.org/10.1080/07370008.2015.1067215</a>
</div>
<div id="ref-braunMotorTaskVariation2009" class="csl-entry" role="listitem">
Braun, D. A., Aertsen, A., Wolpert, D. M., &amp; Mehring, C. (2009). Motor <span>Task Variation Induces Structural Learning</span>. <em>Current Biology</em>, <em>19</em>(4), 352–357. <a href="https://doi.org/10.1016/j.cub.2009.01.036">https://doi.org/10.1016/j.cub.2009.01.036</a>
</div>
<div id="ref-carvalhoPuttingCategoryLearning2014" class="csl-entry" role="listitem">
Carvalho, P. F., &amp; Goldstone, R. L. (2014). Putting category learning in order: <span>Category</span> structure and temporal arrangement affect the benefit of interleaved over blocked study. <em>Memory &amp; Cognition</em>, <em>42</em>(3), 481–495. <a href="https://doi.org/10.3758/s13421-013-0371-0">https://doi.org/10.3758/s13421-013-0371-0</a>
</div>
<div id="ref-carvalhoSequenceStudyChanges2017" class="csl-entry" role="listitem">
Carvalho, P. F., &amp; Goldstone, R. L. (2017). The sequence of study changes what information is attended to, encoded, and remembered during category learning. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>43</em>(11), 1699–1719. <a href="https://doi.org/10.1037/xlm0000406">https://doi.org/10.1037/xlm0000406</a>
</div>
<div id="ref-catalanoDistantTransferCoincident1984a" class="csl-entry" role="listitem">
Catalano, J. F., &amp; Kleiner, B. M. (1984). Distant <span>Transfer</span> in <span>Coincident Timing</span> as a <span>Function</span> of <span>Variability</span> of <span>Practice</span>. <em>Perceptual and Motor Skills</em>, <em>58</em>(3), 851–856. <a href="https://doi.org/10.2466/pms.1984.58.3.851">https://doi.org/10.2466/pms.1984.58.3.851</a>
</div>
<div id="ref-chuaPracticeVariabilityPromotes2019" class="csl-entry" role="listitem">
Chua, L.-K., Dimapilis, M. K., Iwatsuki, T., Abdollahipour, R., Lewthwaite, R., &amp; Wulf, G. (2019). Practice variability promotes an external focus of attention and enhances motor skill learning. <em>Human Movement Science</em>, <em>64</em>, 307–319. <a href="https://doi.org/10.1016/j.humov.2019.02.015">https://doi.org/10.1016/j.humov.2019.02.015</a>
</div>
<div id="ref-cohenCategoryVariabilityExemplar2001" class="csl-entry" role="listitem">
Cohen, A. L., Nosofsky, R. M., &amp; Zaki, S. R. (2001). Category variability, exemplar similarity, and perceptual classification. <em>Memory &amp; Cognition</em>, <em>29</em>(8), 1165–1175. <a href="https://doi.org/10.3758/BF03206386">https://doi.org/10.3758/BF03206386</a>
</div>
<div id="ref-czyzVariabilityPracticeInformation2021" class="csl-entry" role="listitem">
Czyż, S. H. (2021). Variability of <span>Practice</span>, <span>Information Processing</span>, and <span>Decision Making</span>—<span>How Much Do We Know</span>? <em>Frontiers in Psychology</em>, <em>12</em>. <a href="https://doi.org/10.3389/fpsyg.2021.639131">https://doi.org/10.3389/fpsyg.2021.639131</a>
</div>
<div id="ref-delreyEffectsContextualInterference1982" class="csl-entry" role="listitem">
Del Rey, P., Wughalter, E. H., &amp; Whitehurst, M. (1982). The <span>Effects</span> of <span>Contextual Interference</span> on <span>Females With Varied Experience</span> in <span>Open Sport Skills</span>. <em>Research Quarterly for Exercise and Sport</em>, <em>53</em>(2), 108–115. <a href="https://doi.org/10.1080/02701367.1982.10605236">https://doi.org/10.1080/02701367.1982.10605236</a>
</div>
<div id="ref-deloshExtrapolationSineQua1997" class="csl-entry" role="listitem">
DeLosh, E. L., McDaniel, M. A., &amp; Busemeyer, J. R. (1997). Extrapolation: <span>The Sine Qua Non</span> for <span>Abstraction</span> in <span>Function Learning</span>. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>23</em>(4), 19. <a href="https://doi.org/10.1037/0278-7393.23.4.968">https://doi.org/10.1037/0278-7393.23.4.968</a>
</div>
<div id="ref-dettermanCaseProsecutionTransfer1993" class="csl-entry" role="listitem">
Detterman, D. K. (1993). The case for the prosecution: <span>Transfer</span> as an epiphenomenon. In <em>Transfer on trial: <span>Intelligence</span>, cognition, and instruction</em> (pp. 1–24). Ablex Publishing.
</div>
<div id="ref-fulvioTaskSpecificResponseStrategy2014" class="csl-entry" role="listitem">
Fulvio, J. M., Green, C. S., &amp; Schrater, P. R. (2014). Task-<span>Specific Response Strategy Selection</span> on the <span>Basis</span> of <span>Recent Training Experience</span>. <em>PLOS Computational Biology</em>, <em>10</em>(1), e1003425. <a href="https://doi.org/10.1371/journal.pcbi.1003425">https://doi.org/10.1371/journal.pcbi.1003425</a>
</div>
<div id="ref-georgeStimulusVariabilityTask2021" class="csl-entry" role="listitem">
George, N., &amp; Egner, T. (2021). Stimulus variability and task relevance modulate binding-learning. <em>Attention, Perception, &amp; Psychophysics</em>. <a href="https://doi.org/10.3758/s13414-021-02338-6">https://doi.org/10.3758/s13414-021-02338-6</a>
</div>
<div id="ref-gonzalezDiversityTrainingEnhances2011" class="csl-entry" role="listitem">
Gonzalez, C., &amp; Madhavan, P. (2011). Diversity during training enhances detection of novel stimuli. <em>Journal of Cognitive Psychology</em>, <em>23</em>(3), 342–350. <a href="https://doi.org/10.1080/20445911.2011.507187">https://doi.org/10.1080/20445911.2011.507187</a>
</div>
<div id="ref-goodeSuperiorityVariableRepeated2008" class="csl-entry" role="listitem">
Goode, M. K., Geraci, L., &amp; Roediger, H. L. (2008). Superiority of variable to repeated practice in transfer on anagram solution. <em>Psychonomic Bulletin &amp; Review</em>, <em>15</em>(3), 662–666. <a href="https://doi.org/10.3758/PBR.15.3.662">https://doi.org/10.3758/PBR.15.3.662</a>
</div>
<div id="ref-greenPracticeVariabilityTransfer1995a" class="csl-entry" role="listitem">
Green, D. P., Whitehead, J., &amp; Sugden, D. A. (1995). Practice <span>Variability</span> and <span>Transfer</span> of a <span>Racket Skill</span>. <em>Perceptual and Motor Skills</em>, <em>81</em>(3_suppl), 1275–1281. <a href="https://doi.org/10.2466/pms.1995.81.3f.1275">https://doi.org/10.2466/pms.1995.81.3f.1275</a>
</div>
<div id="ref-guadagnoliRelationshipContextualInterference1999" class="csl-entry" role="listitem">
Guadagnoli, M. A., Holcomb, W. R., &amp; Weber, T. J. (1999). The relationship between contextual interference effects and performer expertise on the learning of a putting task. <em>Journal of Human Movement Studies</em>, <em>37</em>(1), 19–36.
</div>
<div id="ref-guadagnoliChallengePointFramework2004" class="csl-entry" role="listitem">
Guadagnoli, M. A., &amp; Lee, T. D. (2004). Challenge <span>Point</span>: <span>A Framework</span> for <span>Conceptualizing</span> the <span>Effects</span> of <span>Various Practice Conditions</span> in <span>Motor Learning</span>. <em>Journal of Motor Behavior</em>, <em>36</em>(2), 212–224. <a href="https://doi.org/10.3200/JMBR.36.2.212-224">https://doi.org/10.3200/JMBR.36.2.212-224</a>
</div>
<div id="ref-hahnEffectsCategoryDiversity2005" class="csl-entry" role="listitem">
Hahn, U., Bailey, T. M., &amp; Elvin, L. B. C. (2005). Effects of category diversity on learning, memory, and generalization. <em>Memory &amp; Cognition</em>, <em>33</em>(2), 289–302. <a href="https://doi.org/10.3758/BF03195318">https://doi.org/10.3758/BF03195318</a>
</div>
<div id="ref-homaCategoryBreadthAbstraction1976" class="csl-entry" role="listitem">
Homa, D., &amp; Vosburgh, R. (1976). Category breadth and the abstraction of prototypical information. <em>Journal of Experimental Psychology: Human Learning and Memory</em>, <em>2</em>(3), 322–330. <a href="https://doi.org/10.1037/0278-7393.2.3.322">https://doi.org/10.1037/0278-7393.2.3.322</a>
</div>
<div id="ref-hsuEffectsGenerativeDiscriminative2010" class="csl-entry" role="listitem">
Hsu, A. S., &amp; Griffiths, T. L. (2010). Effects of generative and discriminative learning on use of category variability. <em>32nd Annual Conference of the Cognitive Science Society</em>, 7.
</div>
<div id="ref-jonesDensityDistinctivenessEarly2020" class="csl-entry" role="listitem">
Jones, S. D., &amp; Brandt, S. (2020). Density and <span>Distinctiveness</span> in <span>Early Word Learning</span>: <span>Evidence From Neural Network Simulations</span>. <em>Cognitive Science</em>, <em>44</em>(1), e12812. <a href="https://doi.org/10.1111/cogs.12812">https://doi.org/10.1111/cogs.12812</a>
</div>
<div id="ref-kelleyLearningAttendEffects2009" class="csl-entry" role="listitem">
Kelley, T. A., &amp; Yantis, S. (2009). Learning to attend: <span>Effects</span> of practice on information selection. <em>Journal of Vision</em>, <em>9</em>(7), 16. <a href="https://doi.org/10.1167/9.7.16">https://doi.org/10.1167/9.7.16</a>
</div>
<div id="ref-kerrSpecificVariedPractice1978" class="csl-entry" role="listitem">
Kerr, R., &amp; Booth, B. (1978). Specific and varied practice of motor skill. <em>Perceptual and Motor Skills</em>, <em>46</em>(2), 395–401. <a href="https://doi.org/10.1177/003151257804600201">https://doi.org/10.1177/003151257804600201</a>
</div>
<div id="ref-landinComparisonThreePractice1997" class="csl-entry" role="listitem">
Landin, D., &amp; Hebert, E. P. (1997). A <span>Comparison</span> of <span>Three Practice Schedules</span> along the <span>Contextual Interference Continuum</span>. <em>Research Quarterly for Exercise and Sport</em>, <em>68</em>(4), 357–361. <a href="https://doi.org/10.1080/02701367.1997.10608017">https://doi.org/10.1080/02701367.1997.10608017</a>
</div>
<div id="ref-lavanEffectsHighVariability2019" class="csl-entry" role="listitem">
Lavan, N., Knight, S., Hazan, V., &amp; McGettigan, C. (2019). The effects of high variability training on voice identity learning. <em>Cognition</em>, <em>193</em>, 104026. <a href="https://doi.org/10.1016/j.cognition.2019.104026">https://doi.org/10.1016/j.cognition.2019.104026</a>
</div>
<div id="ref-leeEvidentialDiversityIncreases2019" class="csl-entry" role="listitem">
Lee, J. C., Lovibond, P. F., &amp; Hayes, B. K. (2019). Evidential diversity increases generalisation in predictive learning. <em>Quarterly Journal of Experimental Psychology</em>, <em>72</em>(11), 2647–2657. <a href="https://doi.org/10.1177/1747021819857065">https://doi.org/10.1177/1747021819857065</a>
</div>
<div id="ref-leeLocusContextualInterference" class="csl-entry" role="listitem">
Lee, T. D., &amp; Magill, R. A. (n.d.). <em>The <span>Locus</span> of <span>Contextual Interference</span> in <span>Motor-Skill Acquisition</span></em>. 17.
</div>
<div id="ref-leeInfluencePracticeSchedule1985" class="csl-entry" role="listitem">
Lee, T. D., Magill, R. A., &amp; Weeks, D. J. (1985). Influence of <span>Practice Schedule</span> on <span>Testing Schema Theory Predictions</span> in <span>Adults</span>. <em>Journal of Motor Behavior</em>, <em>17</em>(3), 283–299. <a href="https://doi.org/10.1080/00222895.1985.10735350">https://doi.org/10.1080/00222895.1985.10735350</a>
</div>
<div id="ref-maddoxStimulusRangeDiscontinuity2011" class="csl-entry" role="listitem">
Maddox, W. T., &amp; Filoteo, J. V. (2011). Stimulus range and discontinuity effects on information-integration category learning and generalization. <em>Attention, Perception, &amp; Psychophysics</em>, <em>73</em>(4), 1279–1295. <a href="https://doi.org/10.3758/s13414-011-0101-2">https://doi.org/10.3758/s13414-011-0101-2</a>
</div>
<div id="ref-magillReviewContextualInterference1990" class="csl-entry" role="listitem">
Magill, R. A., &amp; Hall, K. G. (1990). A review of the contextual interference effect in motor skill acquisition. <em>Human Movement Science</em>, <em>9</em>(3-5), 241–289. <a href="https://doi.org/10.1016/0167-9457(90)90005-X">https://doi.org/10.1016/0167-9457(90)90005-X</a>
</div>
<div id="ref-mccrackenTestSchemaTheory1977" class="csl-entry" role="listitem">
McCracken, H. D., &amp; Stelmach, G. E. (1977). A <span>Test</span> of the <span>Schema Theory</span> of <span>Discrete Motor Learning</span>. <em>Journal of Motor Behavior</em>, <em>9</em>(3), 193–201. <a href="https://doi.org/10.1080/00222895.1977.10735109">https://doi.org/10.1080/00222895.1977.10735109</a>
</div>
<div id="ref-moxleySchemaVariabilityPractice1979" class="csl-entry" role="listitem">
Moxley, S. E. (1979). Schema: <span>The Variability</span> of <span>Practice Hypothesis</span>. <em>Journal of Motor Behavior</em>, <em>11</em>(1), 65–70. <a href="https://doi.org/10.1080/00222895.1979.10735173">https://doi.org/10.1080/00222895.1979.10735173</a>
</div>
<div id="ref-newellVariabilityPracticeTransfer1976" class="csl-entry" role="listitem">
Newell, K. M., &amp; Shapiro, D. C. (1976). Variability of <span>Practice</span> and <span>Transfer</span> of <span>Training</span>: <span>Some Evidence Toward</span> a <span>Schema View</span> of <span>Motor Learning</span>. <em>Journal of Motor Behavior</em>, <em>8</em>(3), 233–243. <a href="https://doi.org/10.1080/00222895.1976.10735077">https://doi.org/10.1080/00222895.1976.10735077</a>
</div>
<div id="ref-northEffectConsistentVaried2019" class="csl-entry" role="listitem">
North, J. S., Bezodis, N. E., Murphy, C. P., Runswick, O. R., Pocock, C., &amp; Roca, A. (2019). The effect of consistent and varied follow-through practice schedules on learning a table tennis backhand. <em>Journal of Sports Sciences</em>, <em>37</em>(6), 613–620. <a href="https://doi.org/10.1080/02640414.2018.1522683">https://doi.org/10.1080/02640414.2018.1522683</a>
</div>
<div id="ref-nosofskyModelguidedSearchOptimal2019" class="csl-entry" role="listitem">
Nosofsky, R. M., Sanders, C. A., Zhu, X., &amp; McDaniel, M. A. (2019). Model-guided search for optimal natural-science-category training exemplars: <span>A</span> work in progress. <em>Psychonomic Bulletin &amp; Review</em>, <em>26</em>(1), 48–76. <a href="https://doi.org/10.3758/s13423-018-1508-8">https://doi.org/10.3758/s13423-018-1508-8</a>
</div>
<div id="ref-pachecoLearningSpecificIndividual2018" class="csl-entry" role="listitem">
Pacheco, M. M., &amp; Newell, K. M. (2018). Learning a specific, individual and generalizable coordination function: Evaluating the variability of practice hypothesis in motor learning. <em>Experimental Brain Research</em>, <em>236</em>(12), 3307–3318. <a href="https://doi.org/10.1007/s00221-018-5383-3">https://doi.org/10.1007/s00221-018-5383-3</a>
</div>
<div id="ref-palmeriCentralTendenciesExtreme2001" class="csl-entry" role="listitem">
Palmeri, T. J., &amp; Nosofsky, R. M. (2001). Central <span>Tendencies</span>, <span>Extreme Points</span>, and <span>Prototype Enhancement Effects</span> in <span>Ill-Defined Perceptual Categorization</span>. <em>The Quarterly Journal of Experimental Psychology Section A</em>, <em>54</em>(1), 197–235. <a href="https://doi.org/10.1080/02724980042000084">https://doi.org/10.1080/02724980042000084</a>
</div>
<div id="ref-perlmanFurtherAttemptsClarify2012" class="csl-entry" role="listitem">
Perlman, A., Hahn, U., Edwards, D. J., &amp; Pothos, E. M. (2012). Further attempts to clarify the importance of category variability for categorisation. <em>Journal of Cognitive Psychology</em>, <em>24</em>(2), 203–220. <a href="https://doi.org/10.1080/20445911.2011.613818">https://doi.org/10.1080/20445911.2011.613818</a>
</div>
<div id="ref-perryLearnLocallyThink2010" class="csl-entry" role="listitem">
Perry, L. K., Samuelson, L. K., Malloy, L. M., &amp; Schiffer, R. N. (2010). Learn <span>Locally</span>, <span>Think Globally</span>: <span>Exemplar Variability Supports Higher-Order Generalization</span> and <span>Word Learning</span>. <em>Psychological Science</em>, <em>21</em>(12), 1894–1902. <a href="https://doi.org/10.1177/0956797610389189">https://doi.org/10.1177/0956797610389189</a>
</div>
<div id="ref-pigottMotorSchemaStructure1984" class="csl-entry" role="listitem">
Pigott, R. E., &amp; Shapiro, D. C. (1984). Motor <span>Schema</span>: <span>The Structure</span> of the <span>Variability Session</span>. <em>Research Quarterly for Exercise and Sport</em>, <em>55</em>(1), 41–45. <a href="https://doi.org/10.1080/02701367.1984.10605353">https://doi.org/10.1080/02701367.1984.10605353</a>
</div>
<div id="ref-posnerGenesisAbstractIdeas1968" class="csl-entry" role="listitem">
Posner, M. I., &amp; Keele, S. W. (1968). On the genesis of abstract ideas. <em>Journal of Experimental Psychology</em>, <em>77</em>(3), 353–363. <a href="https://doi.org/10.1037/h0025953">https://doi.org/10.1037/h0025953</a>
</div>
<div id="ref-ravivHowVariabilityShapes2022" class="csl-entry" role="listitem">
Raviv, L., Lupyan, G., &amp; Green, S. C. (2022). How variability shapes learning and generalization. <em>Trends in Cognitive Sciences</em>, S1364661322000651. <a href="https://doi.org/10.1016/j.tics.2022.03.007">https://doi.org/10.1016/j.tics.2022.03.007</a>
</div>
<div id="ref-rollerVariablePracticeLenses2001" class="csl-entry" role="listitem">
Roller, C. A., Cohen, H. S., Kimball, K. T., &amp; Bloomberg, J. J. (2001). Variable practice with lenses improves visuo-motor plasticity. <em>Cognitive Brain Research</em>, <em>12</em>(2), 341–352. <a href="https://doi.org/10.1016/S0926-6410(01)00077-5">https://doi.org/10.1016/S0926-6410(01)00077-5</a>
</div>
<div id="ref-sabahWhenLessMore2019" class="csl-entry" role="listitem">
Sabah, K., Dolk, T., Meiran, N., &amp; Dreisbach, G. (2019). When less is more: Costs and benefits of varied vs. Fixed content and structure in short-term task switching training. <em>Psychological Research</em>, <em>83</em>(7), 1531–1542. <a href="https://doi.org/10.1007/s00426-018-1006-7">https://doi.org/10.1007/s00426-018-1006-7</a>
</div>
<div id="ref-sadakataIndividualAptitudeMandarin2014" class="csl-entry" role="listitem">
Sadakata, M., &amp; McQueen, J. M. (2014). Individual aptitude in <span>Mandarin</span> lexical tone perception predicts effectiveness of high-variability training. <em>Frontiers in Psychology</em>, <em>5</em>, 1318. <a href="https://doi.org/10.3389/fpsyg.2014.01318">https://doi.org/10.3389/fpsyg.2014.01318</a>
</div>
<div id="ref-sakamotoPuttingPsychologyBack2008" class="csl-entry" role="listitem">
Sakamoto, Y., Jones, M., &amp; Love, B. C. (2008). Putting the psychology back into psychological models: <span>Mechanistic</span> versus rational approaches. <em>Memory &amp; Cognition</em>, <em>36</em>(6), 1057–1065. <a href="https://doi.org/10.3758/MC.36.6.1057">https://doi.org/10.3758/MC.36.6.1057</a>
</div>
<div id="ref-schmidtSchemaTheoryDiscrete1975" class="csl-entry" role="listitem">
Schmidt, R. A. (1975). A schema theory of discrete motor skill learning. <em>Psychological Review</em>, <em>82</em>(4), 225–260. <a href="https://doi.org/10.1037/h0076770">https://doi.org/10.1037/h0076770</a>
</div>
<div id="ref-schmidtNewConceptualizationsPractice1992" class="csl-entry" role="listitem">
Schmidt, R. A., &amp; Bjork, R. A. (1992). New conceptualizations of practice: <span>Common</span> principles in three paradigms suggest new concepts for training. <em>Psychological Science</em>, <em>3</em>(4), 207–217.
</div>
<div id="ref-seowTransferEffectsVaried2019" class="csl-entry" role="listitem">
Seow, R. Y. T., Betts, S., &amp; Anderson, J. R. (2019). Transfer effects of varied practice and adaptation to changes in complex skill acquisition. <em>Proceedings of the 17th International Conference on Cognitive Modelling</em>, 222–227.
</div>
<div id="ref-sheaContextualInterferenceContributions1990" class="csl-entry" role="listitem">
Shea, C. H., Kohl, R., &amp; Indermill, C. (1990). Contextual interference: <span>Contributions</span> of practice. <em>Acta Psychologica</em>, <em>73</em>(2), 145–157. <a href="https://doi.org/10.1016/0001-6918(90)90076-R">https://doi.org/10.1016/0001-6918(90)90076-R</a>
</div>
<div id="ref-sheaContextualInterferenceEffects1979" class="csl-entry" role="listitem">
Shea, J. B., &amp; Morgan, R. L. (1979). Contextual interference effects on the acquisition, retention, and transfer of a motor skill. <em>Journal of Experimental Psychology: Human Learning and Memory</em>, <em>5</em>(2), 179.
</div>
<div id="ref-sheaContextEffectsMemory1983" class="csl-entry" role="listitem">
Shea, J. B., &amp; Zimny, S. T. (1983). Context <span>Effects</span> in <span>Memory</span> and <span>Learning Movement Information</span>. In <em>Advances in <span>Psychology</span></em> (Vol. 12, pp. 345–366). Elsevier. <a href="https://doi.org/10.1016/S0166-4115(08)61998-6">https://doi.org/10.1016/S0166-4115(08)61998-6</a>
</div>
<div id="ref-sinkeviciuteRoleInputVariability2019" class="csl-entry" role="listitem">
Sinkeviciute, R., Brown, H., Brekelmans, G., &amp; Wonnacott, E. (2019). The role of input variability and learner age in second language vocabulary learning. <em>Studies in Second Language Acquisition</em>, <em>41</em>(04), 795–820. <a href="https://doi.org/10.1017/S0272263119000263">https://doi.org/10.1017/S0272263119000263</a>
</div>
<div id="ref-twomeyAllRightNoises2018" class="csl-entry" role="listitem">
Twomey, K. E., Ma, L., &amp; Westermann, G. (2018). All the <span>Right Noises</span>: <span>Background Variability Helps Early Word Learning</span>. <em>Cognitive Science</em>, <em>42</em>(S2), 413–438. <a href="https://doi.org/10.1111/cogs.12539">https://doi.org/10.1111/cogs.12539</a>
</div>
<div id="ref-vanrossumSchmidtSchemaTheory1990" class="csl-entry" role="listitem">
Van Rossum, J. H. A. (1990). Schmidt’s schema theory: The empirical base of the variability of practice hypothesis. <em>Human Movement Science</em>, <em>9</em>(3-5), 387–435. <a href="https://doi.org/10.1016/0167-9457(90)90010-B">https://doi.org/10.1016/0167-9457(90)90010-B</a>
</div>
<div id="ref-wahlheimMetacognitiveJudgmentsRepetition2012" class="csl-entry" role="listitem">
Wahlheim, C. N., Finn, B., &amp; Jacoby, L. L. (2012). Metacognitive judgments of repetition and variability effects in natural concept learning: Evidence for variability neglect. <em>Memory &amp; Cognition</em>, <em>40</em>(5), 703–716. <a href="https://doi.org/10.3758/s13421-011-0180-2">https://doi.org/10.3758/s13421-011-0180-2</a>
</div>
<div id="ref-willeyLimitedGeneralizationVaried2018" class="csl-entry" role="listitem">
Willey, C. R., &amp; Liu, Z. (2018a). Limited generalization with varied, as compared to specific, practice in short-term motor learning. <em>Acta Psychologica</em>, <em>182</em>, 39–45. <a href="https://doi.org/10.1016/j.actpsy.2017.11.008">https://doi.org/10.1016/j.actpsy.2017.11.008</a>
</div>
<div id="ref-willeyLongtermMotorLearning2018" class="csl-entry" role="listitem">
Willey, C. R., &amp; Liu, Z. (2018b). Long-term motor learning: <span>Effects</span> of varied and specific practice. <em>Vision Research</em>, <em>152</em>, 10–16. <a href="https://doi.org/10.1016/j.visres.2017.03.012">https://doi.org/10.1016/j.visres.2017.03.012</a>
</div>
<div id="ref-wonnacottInputEffectsAcquisition2012" class="csl-entry" role="listitem">
Wonnacott, E., Boyd, J. K., Thomson, J., &amp; Goldberg, A. E. (2012). Input effects on the acquisition of a novel phrasal construction in 5year olds. <em>Journal of Memory and Language</em>, <em>66</em>(3), 458–478. <a href="https://doi.org/10.1016/j.jml.2011.11.004">https://doi.org/10.1016/j.jml.2011.11.004</a>
</div>
<div id="ref-wrightContributionElaborativeProcessing1992" class="csl-entry" role="listitem">
Wright, D. L., Li, Y., &amp; Whitacre, C. (1992). The <span>Contribution</span> of <span>Elaborative Processing</span> to the <span>Contextual Interference Effect</span>. <em>Research Quarterly for Exercise and Sport</em>, <em>63</em>(1), 30–37. <a href="https://doi.org/10.1080/02701367.1992.10607554">https://doi.org/10.1080/02701367.1992.10607554</a>
</div>
<div id="ref-wrisbergTrainingProductionNovel1984" class="csl-entry" role="listitem">
Wrisberg, C. A., &amp; McLean, E. (1984). Training for the production of novel timing movements: <span>Contextual</span> considerations. <em>Psychological Research</em>, <em>46</em>(1-2), 169–176. <a href="https://doi.org/10.1007/BF00308601">https://doi.org/10.1007/BF00308601</a>
</div>
<div id="ref-wrisbergDevelopingCoincidentTiming1983" class="csl-entry" role="listitem">
Wrisberg, C. A., &amp; Mead, B. J. (1983). Developing <span>Coincident Timing Skill</span> in <span>Children</span>: <span>A Comparison</span> of <span>Training Methods</span>. <em>Research Quarterly for Exercise and Sport</em>, <em>54</em>(1), 67–74. <a href="https://doi.org/10.1080/02701367.1983.10605274">https://doi.org/10.1080/02701367.1983.10605274</a>
</div>
<div id="ref-wrisbergVariabilityPracticeHypothesis1987" class="csl-entry" role="listitem">
Wrisberg, C. A., Winter, T. P., &amp; Kuhlman, J. S. (1987). The <span>Variability</span> of <span>Practice Hypothesis</span>: <span>Further Tests</span> and <span>Methodological Discussion</span>. <em>Research Quarterly for Exercise and Sport</em>, <em>58</em>(4), 369–374. <a href="https://doi.org/10.1080/02701367.1987.10608114">https://doi.org/10.1080/02701367.1987.10608114</a>
</div>
<div id="ref-wulfEffectTypePractice1991" class="csl-entry" role="listitem">
Wulf, G. (1991). The effect of type of practice on motor learning in children. <em>Applied Cognitive Psychology</em>, <em>5</em>(2), 123–134. <a href="https://doi.org/10.1002/acp.2350050206">https://doi.org/10.1002/acp.2350050206</a>
</div>
<div id="ref-wulfVariabilityPracticeImplicit1997" class="csl-entry" role="listitem">
Wulf, G., &amp; Schmidt, R. A. (1997). <em>Variability of <span>Practice</span> and <span>Implicit Motor Learning</span></em>.
</div>
<div id="ref-zamanPerceptualVariabilityImplications2021" class="csl-entry" role="listitem">
Zaman, J., Chalkia, A., Zenses, A.-K., Bilgin, A. S., Beckers, T., Vervliet, B., &amp; Boddez, Y. (2021). Perceptual variability: <span>Implications</span> for learning and generalization. <em>Psychonomic Bulletin &amp; Review</em>, <em>28</em>(1), 1–19. <a href="https://doi.org/10.3758/s13423-020-01780-1">https://doi.org/10.3758/s13423-020-01780-1</a>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/tegorman13\.github\.io\/Dissertation\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
  </div>
  <div class="nav-page nav-page-next">
      <a href="../Sections/IGAS.html" class="pagination-link" aria-label="IGAS Project">
        <span class="nav-page-text">IGAS Project</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>