<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.28">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Dissertation – hold_temp</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../Assets/Style/calloutTG.css">
</head>

<body class="nav-sidebar docked fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">
      Dissertation
      </li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Dissertation</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tegorman13/Dissertation" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dissertation</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../paper.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dissertation Manuscript</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Sections/full.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Full Dissertation</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Sections/Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Sections/IGAS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">IGAS Project</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Sections/HTW.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">HTW Project</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Sections/Discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">General Discussion</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">




<p>Schema theory and typical study design</p>
<p>Kerr &amp; Booth pattern Wrisberg - kerr &amp; booth contrasts plus other comparisons Green 1995 - partial support of Kerr &amp; Booth - varied group gets less experience from testing scenario Goode analogy study - reps Kerr &amp; Booth</p>
<p>More common designs - lots of citations</p>
<p>catalano 1984 - description Wiley 2018 - failed replication of Kerr &amp; Booth</p>
<p>One such study that used a movement timing task, wherein subjects had to move their hand from a starting location, to a target location, attempting to arrive at the target location at specific time following the onset of a cue <span class="citation" data-cites="wrisbergVariabilityPracticeHypothesis1987">(<a href="#ref-wrisbergVariabilityPracticeHypothesis1987" role="doc-biblioref">Wrisberg et al., 1987</a>)</span>. This study utilized 4 different constant groups, and 3 varied groups, with one of the constant groups training under conditions identical to the testing conditions, and which were not trained on by any of the varied groups, e.g.&nbsp;the design of Kerr and Booth. However, in this case the varied group did not outperform the constant group.</p>
<p>A consequence of varied training is that the trial to trial sequences will tend to to consist of fewer repeats, and more switches between task condition (i.e.&nbsp;throwing locations; category exemplars; target velocitys), or in the case where variability is being manipulated by the dispersion of training items, the trial to trial sequences of varied participants will tend to consist of larger jumps in the stimulus space.</p>
<p>The number of switches can vary greatly, with the two extremes being varied participants completing all of their training trials in one block before switching to the next condition (blocked sequencing), or if they alternate between conditions on a trial by trial basis (random/intermixed/interleaved sequencing).</p>
<p><span class="citation" data-cites="sheaContextualInterferenceEffects1979">(<a href="#ref-sheaContextualInterferenceEffects1979" role="doc-biblioref">Shea &amp; Morgan, 1979</a>)</span>. In this seminal study, both groups of training subjects trained with the same number of trials of three separate movement patterns. A blocked group that completed all of their trials with one sequence before beginning the next sequence, and a random group that trained with all three movement patterns interspersed throughout the course of training. Participants were also randomly assigned to retention testing under either blocked or random sequence conditions, thus resulting in all four training-testing combinations of blocked-blocked; blocked-random; random-blocked; random-random. There was some effect of sequence context, such that both groups performed better when the testing sequence matched their training sequence. However, the main finding of interest was the advantage of random-training, which resulted in superior testing performance than blocked training regardless of whether the testing stage had a blocked or random sequence, an effect observed both immediately after training, and in a follow up test ten days after the end of training. A more recent study <span class="citation" data-cites="chuaPracticeVariabilityPromotes2019">(<a href="#ref-chuaPracticeVariabilityPromotes2019" role="doc-biblioref">Chua et al., 2019</a>)</span>, found a similar pattern of results in both a varied vs.&nbsp;constant training manipulation (expt 1, bean-bag throwing task), and of random training vs.&nbsp;blocked training manipulation (expt 2 &amp; 3, bean-bag throwing &amp; golf putting). The novelty of this study is that the experimenters queried subjects about their attentional focus throughout the training stage. In all three experiments varied or random trained-subjects reported significantly greater external attention (e.g.&nbsp;attending to the target distance), and constant or blocked subjects reported more internal attention (e.g.&nbsp;posture or hand position). The authors argue that the benefits of varied/random training may thusly be mediated by changes in attentional focus.</p>
<section id="sequence-effects" class="level3">
<h3 class="anchored" data-anchor-id="sequence-effects">Sequence Effects</h3>
<p>A necessary consequence of varied training is that participants will have the experience of switching from one task condition to another. The number of switches can vary greatly, with the two extremes being varied participants completing all of their training trials in one before switching to the next condition (blocked sequencing), or if they alternate between conditions on a trial by trial basis (random/intermixed/interleaved sequencing). Not long after the initial influx of schema-theory inspired studies testing the benefits of variability hypothesis was shown that the influence of varied training might interact with the type of training sequence chosen by the experimenter <span class="citation" data-cites="sheaContextualInterferenceEffects1979">(<a href="#ref-sheaContextualInterferenceEffects1979" role="doc-biblioref">Shea &amp; Morgan, 1979</a>)</span>. In this seminal study, both groups of training subjects trained with the same number of trials of three separate movement patterns. A blocked group that completed all of their trials with one sequence before beginning the next sequence, and a random group that trained with all three movement patterns interspersed throughout the course of training. Participants were also randomly assigned to retention testing under either blocked or random sequence conditions, thus resulting in all four training-testing combinations of blocked-blocked; blocked-random; random-blocked; random-random. There was some effect of sequence context, such that both groups performed better when the testing sequence matched their training sequence. However, the main finding of interest was the advantage of random-training, which resulted in superior testing performance than blocked training regardless of whether the testing stage had a blocked or random sequence, an effect observed both immediately after training, and in a follow up test ten days after the end of training.</p>
<p>Prior to the influential <span class="citation" data-cites="sheaContextualInterferenceEffects1979">Shea &amp; Morgan (<a href="#ref-sheaContextualInterferenceEffects1979" role="doc-biblioref">1979</a>)</span> study, studies investigating the benefits of variability hypothesis had utilized both blocked and random training schedules, often without comment or justification. It was later observed <span class="citation" data-cites="leeInfluencePracticeSchedule1985">(<a href="#ref-leeInfluencePracticeSchedule1985" role="doc-biblioref">Lee et al., 1985</a>)</span> that positive evidence for benefits of varied training seemed more likely to occur for studies that utilized random schedules. The theoretical basis of such studies was invariably an appeal to Schmidt’s schema theory; however schema theory made no clear predictions of an effect of study sequence on retention or generalization, thus prompting the need for alternate accounts. One such account, the elaborative processing account <span class="citation" data-cites="sheaContextEffectsMemory1983">(<a href="#ref-sheaContextEffectsMemory1983" role="doc-biblioref">Shea &amp; Zimny, 1983</a>)</span>, draws on the earlier work <span class="citation" data-cites="battigFacilitationInterference1966">(<a href="#ref-battigFacilitationInterference1966" role="doc-biblioref">Battig, 1966</a>)</span> and argues that randomly sequencing conditions during training promotes comparison and contrastive processes between those conditions, which result in a deeper understanding of the training task than could arise via blocked sequencing. Supporting evidence for elaborative processing comes in the form of random-sequence trained subjects self-reporting more nuanced mental representations of movement patterns following training <span class="citation" data-cites="sheaContextEffectsMemory1983">(<a href="#ref-sheaContextEffectsMemory1983" role="doc-biblioref">Shea &amp; Zimny, 1983</a>)</span>, and by manipulating whether subjects are able to perform comparisons during training <span class="citation" data-cites="wrightContributionElaborativeProcessing1992">(<a href="#ref-wrightContributionElaborativeProcessing1992" role="doc-biblioref">Wright et al., 1992</a>)</span>. An alternative, though not incompatible account suggests that the benefits of random-sequencing are a result of such sequences forcing the learner to continually reconstruct the relevant motor task in working memory <span class="citation" data-cites="leeLocusContextualInterference">(<a href="#ref-leeLocusContextualInterference" role="doc-biblioref">Lee &amp; Magill, n.d.</a>)</span>. Blocked training, on the other hand, allows the learner to maintain the same motor task in short term memory without decay for much of the training which facilitates training performance, but hinders ability to retrieve the appropriate motor memory in a later testing context. A much more recent study <span class="citation" data-cites="chuaPracticeVariabilityPromotes2019">(<a href="#ref-chuaPracticeVariabilityPromotes2019" role="doc-biblioref">Chua et al., 2019</a>)</span>, replicates the standard findings of an advantage of varied training over constant training (expt 1, bean-bag throwing task), and of random training over blocked training (expt 2 &amp; 3, bean-bag throwing &amp; golf putting). The novelty of this study is that the experimenters queried subjects about their attentional focus throughout the training stage. In all three experiments varied or random trained-subjects reported significantly greater external attention (e.g.&nbsp;attending to the target distance), and constant or blocked subjects reported more internal attention (e.g.&nbsp;posture or hand position). The authors argue that the benefits of varied/random training may be mediated by changes in attentional focus, however the claims made in the paper seem to go far beyond what can be justified by the analyses reported – e.g.&nbsp;the increased external focus could be a simple byproduct of varied training. A stronger form of evidence that was not provided may have been to use multiple regression analyses to show that the testing advantage of the varied/random groups over the constant/blocked groups could be accounted for by the differences in self-reported attentional focus.</p>
<p>In North 2019 - biggest effect for varied-random. North, J. S., Bezodis, N. E., Murphy, C. P., Runswick, O. R., Pocock, C., &amp; Roca, A. (2019). The effect of consistent and varied follow-through practice schedules on learning a table tennis backhand. Journal of Sports Sciences, 37(6), 613–620. https://doi.org/10.1080/02640414.2018.1522683</p>
</section>
<section id="the-study-of-variability" class="level2">
<h2 class="anchored" data-anchor-id="the-study-of-variability">The study of variability</h2>
<p>Studies investigating the “benefits of variability” hypothesis usually assign participants to either a constant or varied group for the training stage of the experiment. Then, subjects in both groups complete an identical testing stage which often consists items/conditions seen during training, and novel items/conditions.</p>
<p>If the varied group performs better in the testing stage, this is taken for evidence of the benefits of variability hypothesis. Even within this relatively straightforward between-groups design, researchers must navigate several crucial methodological choices, highlighted below:</p>
<ol type="1">
<li><p>Variables Subject to Variation. In multidimensional tasks, researchers have the option to vary numerous variables. The experimenters must decide the specific dimension(s) across which variation will occur. For instance, in a projectile throwing accuracy task – researchers might vary the distance from the target, the size of the target, the weight of the projectile. They might also vary a contextual variable not directly relevant to the task, but which will still be encoded by the subject on a trial by trial basis, e.g.&nbsp;the background color.</p></li>
<li><p>Magnitude of Variation, relative to the control condition. The simplest comparison would be to compare a constant group who trains with 1 example/condition, against a varied group that trains from 2 examples/conditions. However, it is not uncommon in the literature for the varied condition to train from 3 or 4 conditions. For example, <span class="citation" data-cites="catalanoDistantTransferCoincident1984a">Catalano &amp; Kleiner (<a href="#ref-catalanoDistantTransferCoincident1984a" role="doc-biblioref">1984</a>)</span> train varied subjects from 4 different velocities in their coincident timing task, and <span class="citation" data-cites="goodeSuperiorityVariableRepeated2008">(<a href="#ref-goodeSuperiorityVariableRepeated2008" role="doc-biblioref">Goode et al., 2008</a>)</span> have varied subjects’ practice with 3 different variants (i.e.&nbsp;different letter scrambles of the same word) of an anagram for a given word, while their constant participants view the same variant 3 different times. Alternatively, rather than a constant vs.&nbsp;varied comparison, subjects in all conditions might experience a variety of training items, but with one group experiencing a greater number of unique items <span class="citation" data-cites="nosofskyModelguidedSearchOptimal2018">(<a href="#ref-nosofskyModelguidedSearchOptimal2018" role="doc-biblioref"><strong>nosofskyModelguidedSearchOptimal2018?</strong></a>)</span>.</p></li>
<li><p>Locations within Task-Space. For tasks in which the stimuli or conditions fall within a continuous metric space, the experimenter must decide whether the varied instances are relatively close together (e.g.&nbsp;throwing a ball from a distance of 4 feet and 5 feet), or far apart (throwing from 4 feet and 20 feet). Spreading the varied training items further apart may be beneficial in terms of providing a more representative sample of the task space to the learner, however large distances may also result in significant differences in difficulty between the training examples, which can be a common confound in variability studies.</p></li>
<li><p>Proximity of Testing to Training Conditions. Intuitively, the fairest form of comparison is to include testing conditions that are of an equivalent distance from both the varied and constant groups. However researchers might also attempt to demonstrate the benefits of variation as being sufficiently powerful to outperform constant training, even in cases where the constant group trained from a closer proximity to the testing conditions, or whose training conditions are identical to the testing conditions <span class="citation" data-cites="goodeSuperiorityVariableRepeated2008 kerrSpecificVariedPractice1978">(<a href="#ref-goodeSuperiorityVariableRepeated2008" role="doc-biblioref">Goode et al., 2008</a>; <a href="#ref-kerrSpecificVariedPractice1978" role="doc-biblioref">Kerr &amp; Booth, 1978</a>)</span>.</p></li>
</ol>
<p>Training Condtions - how many, how different, how far apart</p>
<p>(note that the studies described above manipulated the variability of the training examples, rather than the variability of the categories)</p>
<p>Moreover, this effect was at odds with the predications of the baseline version of the GCM, thus providing some evidence that training variation may at least sometimes induce effects that cannot be entirely accounted for by exemplar-similarity accounts.</p>
</section>
<section id="schmidt" class="level2">
<h2 class="anchored" data-anchor-id="schmidt">Schmidt</h2>
<p>A noteworthy early study that explored the benefits of variability, as postulated by Schmidt, was conducted by Kerr &amp; Booth (1978). In their experiment, two groups of children, ages 8 and 12, were tasked with a bean bag throwing exercise. The constant training group practiced aiming at a target 3 feet away, while the varied training group practiced from distances of both 2 and 4 feet. During this training phase, participants were blindfolded to prevent visual targeting, though they could check where the beanbag landed after each attempt for feedback. Twelve weeks later, all participants were tested at the novel distance of 3 feet, which was familiar to the constant group but new to the varied group. Again blindfolded, they received feedback only after the first half of their throws during the final test. Notably, both age groups exhibited significantly better performance in the varied condition, with a more pronounced effect in the younger cohort. Although this study design indirectly supports the hypothesis that varied training promotes better generalization than constant training, it robustly demonstrates the efficacy of varied practice without directly testing novel positions for the constant group.</p>
</section>
<section id="literature-review" class="level2">
<h2 class="anchored" data-anchor-id="literature-review">Literature Review</h2>
<p>An early and influential work on the influence of variability on category learning is that of Posner &amp; Keele (1968). In an ambitious attempt to address the question of how category information is represented, the authors trained participants to categorize artificial dot patterns, manipulating whether learners were exposed to examples clustered close to the category prototypes (e.g.&nbsp;a low variability condition), or spread further away from the prototype (the varied-training group). It should be noted that both groups in this study were trained with the same number of unique instances and the manipulated difference was how spread out the instances were. The authors claim based on prior experiments using the same stimuli, that the training stimuli for the varied group were at least as far away from the testing stimuli as the training stimuli of the less-varied group. The authors interpreted their findings as evidence for the extraction of an abstraction or schema that is extracted and stored, and then over time becomes more likely to be the reference point from which generalization occurs, given that specific instances are thought to decay at a faster rate than prototypes or schema. The Posner and Keele study has been extremely influential and continues to be cited in contemporary research as clear evidence that schema abstraction underlies the benefits of varied training. It’s also referenced as a key influence in the development of “Schema Theory of Motor Learning” (Schmidt, 1975), which in turn influenced decades of investigations on the potential benefits of varied training in motor skill learning. However, the classic Posner &amp; Keele study despite being far more carefully designed than many subsequent studies, and despite being a relative rarity in explicitly discussing and attempting to control for potential confounds of similarity between groups, may nevertheless be emblematic of a common issue in many investigations of the effects of varied training on learning. The problem with Posner &amp; Keele’s conclusion was demonstrated clearly almost 3 decades later (Palmeri &amp; Nosofsky, 2001), when researchers conducting a near replication of the original study also collected similarity judgements following training and performed multidimensional scaling analysis. Rather than being in the middle of the training stimuli as was the case in the physical stimuli space, the psychological representation of the prototype was shown reside at an extreme point, and generalization patterns by participants that would have seemed to warrant the learning of a prototype were then easily accounted for with only the assumption that the participants encoded instances. One of the primary concerns of the present paper is that many of the studies which purport to explain the benefits of variation via prototypes, schemas, or other abstractions, are often overlooking the potential of instance based similarity accounts.</p>
<p>Numerous researchers have attempted to provide coherent frameworks to account for the full range of influences of training variation and sequencing described above (along with many other effects not discussed). Such accounts are generally quite similar, invoking ideas of desirable levels of difficulty <span class="citation" data-cites="bjorkNewTheoryDisuse1992 schmidtNewConceptualizationsPractice1992">(<a href="#ref-bjorkNewTheoryDisuse1992" role="doc-biblioref">Bjork &amp; Bjork, 1992</a>; <a href="#ref-schmidtNewConceptualizationsPractice1992" role="doc-biblioref">Schmidt &amp; Bjork, 1992</a>)</span>, or optimal challenge points <span class="citation" data-cites="guadagnoliChallengePointFramework2004">(<a href="#ref-guadagnoliChallengePointFramework2004" role="doc-biblioref">Guadagnoli &amp; Lee, 2004</a>)</span>. They tend to start by describing the dissociation between acquisition performance (performance during training) and testing performance (delayed retention and/or transfer), most strikingly observed as varied/random training participants performing worse than their constant/blocked counterparts during the training stage of the study, but then outperforming the constant/blocked comparisons at a later retention or transfer stage. This observation is then used to justify the idea that the most enduring and generalizable learning occurs by training at an optimal level of training difficulty, with difficulty being some function of the experience of the learner, and the cognitive or visuomotor processing demands of the task. It then follows that the factors that tend to make training more difficult (i.e.&nbsp;increased variability or randomization), are more likely to be beneficial when the learner has some experience, or when the processing demands of the task are not too extreme (which may only occur after some experience with the task). Such frameworks may be helpful heuristics in some cases, but they also seem to be overly flexible such that any null result of some intervention might be accounted for by a suboptimal amount of training trials, or by suggesting the training task was too difficult. The development of computational models that can account for how changes in the parameters of the motor-skill task scale with difficulty, would be a great step forward.</p>
<p>; <span class="citation" data-cites="wulfPrinciplesDerivedStudy2002">Wulf &amp; Shea (<a href="#ref-wulfPrinciplesDerivedStudy2002" role="doc-biblioref">2002</a>)</span></p>
<p>Through this combination of controlled experiments and computational modeling, the present work provides an extensive investigation into if, how, and when variability facilitates transfer</p>
<p>Together, these projects contribute to a deeper understanding of the role of training variability in cognitive development, offering insights that could inform educational and training practices across a variety of domains. The findings and methodological approaches detailed in this dissertation not only advance theoretical knowledge but also provide practical implications for designing more effective learning environments.</p>
<p>By taking a multi-pronged approach that combines empirical investigations across multiple experimental paradigms with computational modeling, this dissertation provides a comprehensive examination of the complex and sometimes opposing effects of training variability on learning and generalization. The contrasting results obtained from the HTT and HTW tasks underscore the importance of considering task characteristics when designing experiments to assess the influence of training manipulations. Furthermore, the computational modeling components of this work offer novel theoretical accounts for both the beneficial and detrimental effects of training variability observed in our experiments. Collectively, this dissertation highlights the value of integrating empirical and modeling approaches to uncover the cognitive mechanisms that support learning and generalization across a variety of domains.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-battigFacilitationInterference1966" class="csl-entry" role="listitem">
Battig, W. F. (1966). Facilitation and interference. <em>Acquisition of Skill</em>, 215–244.
</div>
<div id="ref-bjorkNewTheoryDisuse1992" class="csl-entry" role="listitem">
Bjork, R. A., &amp; Bjork, E. L. (1992). A <span>New Theory</span> of <span>Disuse</span> and an <span>Old Theory</span> of <span>Stimulus Fluctuation</span>. In <em>Learning processes to cognitive processes: <span>Essays</span> in honor of <span>William K</span>. <span>Estes</span></em> (Vol. 2, pp. 35–67).
</div>
<div id="ref-catalanoDistantTransferCoincident1984a" class="csl-entry" role="listitem">
Catalano, J. F., &amp; Kleiner, B. M. (1984). Distant <span>Transfer</span> in <span>Coincident Timing</span> as a <span>Function</span> of <span>Variability</span> of <span>Practice</span>. <em>Perceptual and Motor Skills</em>, <em>58</em>(3), 851–856. <a href="https://doi.org/10.2466/pms.1984.58.3.851">https://doi.org/10.2466/pms.1984.58.3.851</a>
</div>
<div id="ref-chuaPracticeVariabilityPromotes2019" class="csl-entry" role="listitem">
Chua, L.-K., Dimapilis, M. K., Iwatsuki, T., Abdollahipour, R., Lewthwaite, R., &amp; Wulf, G. (2019). Practice variability promotes an external focus of attention and enhances motor skill learning. <em>Human Movement Science</em>, <em>64</em>, 307–319. <a href="https://doi.org/10.1016/j.humov.2019.02.015">https://doi.org/10.1016/j.humov.2019.02.015</a>
</div>
<div id="ref-goodeSuperiorityVariableRepeated2008" class="csl-entry" role="listitem">
Goode, M. K., Geraci, L., &amp; Roediger, H. L. (2008). Superiority of variable to repeated practice in transfer on anagram solution. <em>Psychonomic Bulletin &amp; Review</em>, <em>15</em>(3), 662–666. <a href="https://doi.org/10.3758/PBR.15.3.662">https://doi.org/10.3758/PBR.15.3.662</a>
</div>
<div id="ref-guadagnoliChallengePointFramework2004" class="csl-entry" role="listitem">
Guadagnoli, M. A., &amp; Lee, T. D. (2004). Challenge <span>Point</span>: <span>A Framework</span> for <span>Conceptualizing</span> the <span>Effects</span> of <span>Various Practice Conditions</span> in <span>Motor Learning</span>. <em>Journal of Motor Behavior</em>, <em>36</em>(2), 212–224. <a href="https://doi.org/10.3200/JMBR.36.2.212-224">https://doi.org/10.3200/JMBR.36.2.212-224</a>
</div>
<div id="ref-kerrSpecificVariedPractice1978" class="csl-entry" role="listitem">
Kerr, R., &amp; Booth, B. (1978). Specific and varied practice of motor skill. <em>Perceptual and Motor Skills</em>, <em>46</em>(2), 395–401. <a href="https://doi.org/10.1177/003151257804600201">https://doi.org/10.1177/003151257804600201</a>
</div>
<div id="ref-leeLocusContextualInterference" class="csl-entry" role="listitem">
Lee, T. D., &amp; Magill, R. A. (n.d.). <em>The <span>Locus</span> of <span>Contextual Interference</span> in <span>Motor-Skill Acquisition</span></em>. 17.
</div>
<div id="ref-leeInfluencePracticeSchedule1985" class="csl-entry" role="listitem">
Lee, T. D., Magill, R. A., &amp; Weeks, D. J. (1985). Influence of <span>Practice Schedule</span> on <span>Testing Schema Theory Predictions</span> in <span>Adults</span>. <em>Journal of Motor Behavior</em>, <em>17</em>(3), 283–299. <a href="https://doi.org/10.1080/00222895.1985.10735350">https://doi.org/10.1080/00222895.1985.10735350</a>
</div>
<div id="ref-schmidtNewConceptualizationsPractice1992" class="csl-entry" role="listitem">
Schmidt, R. A., &amp; Bjork, R. A. (1992). New conceptualizations of practice: <span>Common</span> principles in three paradigms suggest new concepts for training. <em>Psychological Science</em>, <em>3</em>(4), 207–217.
</div>
<div id="ref-sheaContextualInterferenceEffects1979" class="csl-entry" role="listitem">
Shea, J. B., &amp; Morgan, R. L. (1979). Contextual interference effects on the acquisition, retention, and transfer of a motor skill. <em>Journal of Experimental Psychology: Human Learning and Memory</em>, <em>5</em>(2), 179.
</div>
<div id="ref-sheaContextEffectsMemory1983" class="csl-entry" role="listitem">
Shea, J. B., &amp; Zimny, S. T. (1983). Context <span>Effects</span> in <span>Memory</span> and <span>Learning Movement Information</span>. In <em>Advances in <span>Psychology</span></em> (Vol. 12, pp. 345–366). Elsevier. <a href="https://doi.org/10.1016/S0166-4115(08)61998-6">https://doi.org/10.1016/S0166-4115(08)61998-6</a>
</div>
<div id="ref-wrightContributionElaborativeProcessing1992" class="csl-entry" role="listitem">
Wright, D. L., Li, Y., &amp; Whitacre, C. (1992). The <span>Contribution</span> of <span>Elaborative Processing</span> to the <span>Contextual Interference Effect</span>. <em>Research Quarterly for Exercise and Sport</em>, <em>63</em>(1), 30–37. <a href="https://doi.org/10.1080/02701367.1992.10607554">https://doi.org/10.1080/02701367.1992.10607554</a>
</div>
<div id="ref-wrisbergVariabilityPracticeHypothesis1987" class="csl-entry" role="listitem">
Wrisberg, C. A., Winter, T. P., &amp; Kuhlman, J. S. (1987). The <span>Variability</span> of <span>Practice Hypothesis</span>: <span>Further Tests</span> and <span>Methodological Discussion</span>. <em>Research Quarterly for Exercise and Sport</em>, <em>58</em>(4), 369–374. <a href="https://doi.org/10.1080/02701367.1987.10608114">https://doi.org/10.1080/02701367.1987.10608114</a>
</div>
<div id="ref-wulfPrinciplesDerivedStudy2002" class="csl-entry" role="listitem">
Wulf, G., &amp; Shea, C. H. (2002). Principles derived from the study of simple skills do not generalize to complex skill learning. <em>Psychonomic Bulletin &amp; Review</em>, <em>9</em>(2), 185–211.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/tegorman13\.github\.io\/Dissertation\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>