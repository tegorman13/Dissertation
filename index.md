## Title Page

[@kruschkeModelsAttentionalLearning2011]

[@mezzadriHowFitTransfer2023]

@ciccioneCanHumansPerform2021a

[@mezzadriOrderdependentTransferModel2022a]

[@busemeyerLearningFunctionalRelations1997]

[@mindaLearningCategoriesMaking2004]

[@collsiooNumericalInformationAlways2023]

[@onnisVariabilitySpiceLearning2004]

[@bartlettBenignOverfittingLinear2020]

[@apfelbaumStatisticalLearningReading2013]

[@estesClassificationCognition1994]

[@albaretDifferentialEffectsTask1998]

[@benjaminWhatMakesDistributed2010]

@rodriguesRulesplusexceptionTasksProblem2007

@nosofskyExemplarbasedAccountsMultiplesystem2000

[@ritchieLearningFacesVariability2017]

[@ritchieLearningFacesVariability2017]

[@brunsteinPreparingNoveltyDiverse2011]


[@linvilleExemplarAbstractionModels1993]

[@gershmanStructureLearningPrinciples2023]

At least to me, it's not obvious that a purely 'exemplar-based similarity' learning agent would not not be able to show considerable gains in the learning phase, even without any stimulus repetitions [@huExemplarmodelAccountCategorization2021]. Exemplar-based similarity models have frequently been used to account for human learning in rule-based categories, even for categories that are defined entirely via rules
[@nosofskyExemplarbasedAccountsMultiplesystem2000; @rodriguesRulesplusexceptionTasksProblem2007; 
@thibautDoesPracticeCategory2018; 
@chubalaApplyingExemplarModel2016].
Such models have also been repeatedly used to account for human generalization behavior in categorizaiton tasks [@ahaConceptLearningFlexible1992; @hahnEffectsCategoryDiversity2005; @sakamotoTrackingVariabilityLearning2006; @lambertsFlexibleTuningSimilarity1994]. Some of the assumptions in the paper also seem at odds with previous work suggesting that the use of an exemplar-based strategy may become more likely as participants gain more experience with the task [@johansenAreThereRepresentational2002; @raijmakersCostsBenefitsAutomatization2014]. 


Notions of similarity have long played a central role in many prominent
models of generalization of learning, as well as in the longstanding
theoretical issue of whether learners abstract an aggregate, summary
representation, or if they simply store individual instances. Early
models of learning often assumed that discrete experiences with some
task or category were not stored individually in memory, but instead
promoted the formation of a summary representation, often referred to as
a prototype or schema, and that exposure to novel examples would then
prompt the retrieval of whichever preexisting prototype was most similar
[@posnerGenesisAbstractIdeas1968]. Prototype
models were later challenged by the success of instance-based or
exemplar models -- which were shown to provide an account of
generalization as good or better than prototype models, with the
advantage of not assuming the explicit construction of an internal
prototype [@estesClassificationCognition1994;
@hintzmanMINERVASimulationModel1984;
@medinContextTheoryClassification1978;
@nosofskyAttentionSimilarityIdentificationcategorization1986 ].
Instance-based models assume that learners encode each experience with a
task as a separate instance/exemplar/trace, and that each encoded trace
is in turn compared against novel stimuli. As the number of stored
instances increases, so does the likelihood that some previously stored
instance will be retrieved to aid in the performance of a novel task.
Stored instances are retrieved in the context of novel stimuli or tasks
if they are sufficiently similar, thus suggesting that the process of
computing similarity is of central importance to generalization.


[@liveseyRevisitingPeakShift2019]

[@burknerBrmsPackageBayesian2017]